<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post on Web Archive</title>
    <link>https://elastic-fermat-3dc26c.netlify.com/categories/post/</link>
    <description>Recent content in Post on Web Archive</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://elastic-fermat-3dc26c.netlify.com/categories/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linear Regression</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_linear_regression/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_linear_regression/</guid>
      <description>Source https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
It is used to estimate real values (cost of houses, number of calls, total sales etc.) based on continuous variable(s). Here, we establish relationship between independent and dependent variables by fitting a best line. This best fit line is known as regression line and represented by a linear equation
$$Y= a *X + b$$
The best way to understand linear regression is to relive this experience of childhood.</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-02_logistic_regression/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-02_logistic_regression/</guid>
      <description>Don’t get confused by its name! It is a classification not a regression algorithm. It is used to estimate discrete values (binary values like 0/1, yes/no, true/false ) based on given set of independent variable(s). In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function. Hence, it is also known as logit regression. Since, it predicts the probability, its output values lies between 0 and 1 (as expected).</description>
    </item>
    
    <item>
      <title>Machine Learning Overview</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_machine_learning/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_machine_learning/</guid>
      <description>Broadly, there are three types of Machine Learning Algorithms..
1. Supervised Learning How it works: This algorithm consist of a target or outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data.</description>
    </item>
    
    <item>
      <title>Applied Predictive Modelling</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/book/applied-predictive-modelling/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/book/applied-predictive-modelling/</guid>
      <description>Source
Chapter 1 Introduction Prediction Versus Interpretation, Key Ingredients of Predictive Models; Terminology; Example Data Sets and Typical Data Scenarios; Overview; Notation (15 pages, 3 figures)
Part I: General Strategies Chapter 2 A Short Tour of the Predictive Modeling Process Case Study: Predicting Fuel Economy; Themes; Summary (8 pages, 6 figures, R packages used)
Chapter 3 Data Pre-Processing Case Study: Cell Segmentation in High-Content Screening; Data Transformations for Individual Predictors; Data Transformations for Multiple Predictors; Dealing with Missing Values; Removing Variables; Adding Variables; Binning Variables; Computing; Exercises (32 pages, 11 figures, R packages used)</description>
    </item>
    
    <item>
      <title>Online Reads</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/book/online-reads/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/book/online-reads/</guid>
      <description> persönlicher Blog: harlecin.netlify.com Hackernews: news.ycombinator.com R-Bloggers: r-bloggers.com Data Machina: getrevue.co/profile/datamachina Reddit: reddit.com/r/MachineLearning  </description>
    </item>
    
    <item>
      <title>Conway&#39;s Law</title>
      <link>https://elastic-fermat-3dc26c.netlify.com/book/conways-law/</link>
      <pubDate>Mon, 06 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://elastic-fermat-3dc26c.netlify.com/book/conways-law/</guid>
      <description>Many organizations have become adept at identifying what they need from software development projects, based on a keen understanding of their business goals. Even so, they’re often surprised to find out that the end results don’t achieve the transformative impact they were expecting. Their mistake? Overlooking the importance of Conway’s Law.
In 1967, Melvin Conway coined a phrase at the end of his publication ‘How do committees invent?’ that was subsequently made popular by Fred Brooks in his book The Mythical Man-Month, where he dubbed it &amp;lsquo;Conway’s Law&amp;rsquo;, which states:</description>
    </item>
    
  </channel>
</rss>