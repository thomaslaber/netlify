[
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/python-cheatsheet/",
	"title": "Python Cheatsheet",
	"tags": ["python"],
	"description": "",
	"content": " Source: Download text file or Fork me on GitHub \nMain if __name__ == \u0026#39;__main__\u0026#39;:\rmain() List \u0026lt;list\u0026gt; = \u0026lt;list\u0026gt;[from_inclusive : to_exclusive : step_size] \u0026lt;list\u0026gt;.append(\u0026lt;el\u0026gt;)\r\u0026lt;list\u0026gt;.extend(\u0026lt;collection\u0026gt;)\r\u0026lt;list\u0026gt; += [\u0026lt;el\u0026gt;]\r\u0026lt;list\u0026gt; += \u0026lt;collection\u0026gt; \u0026lt;list\u0026gt;.sort()\r\u0026lt;list\u0026gt;.reverse()\r\u0026lt;list\u0026gt; = sorted(\u0026lt;collection\u0026gt;)\r\u0026lt;iter\u0026gt; = reversed(\u0026lt;list\u0026gt;) sum_of_elements = sum(\u0026lt;collection\u0026gt;)\relementwise_sum = [sum(pair) for pair in zip(list_a, list_b)]\rsorted_by_second = sorted(\u0026lt;collection\u0026gt;, key=lambda el: el[1])\rsorted_by_both = sorted(\u0026lt;collection\u0026gt;, key=lambda el: (el[1], el[0]))\rflatter_list = list(itertools.chain.from_iterable(\u0026lt;list\u0026gt;))\rproduct_of_elems = functools.reduce(lambda out, x: out * x, \u0026lt;collection\u0026gt;)\rlist_of_chars = list(\u0026lt;str\u0026gt;) index = \u0026lt;list\u0026gt;.index(\u0026lt;el\u0026gt;) # Returns first index of item.  \u0026lt;list\u0026gt;.insert(index, \u0026lt;el\u0026gt;) # Inserts item at index and moves the rest to the right.\r \u0026lt;el\u0026gt; = \u0026lt;list\u0026gt;.pop([index]) # Removes and returns item at index or from the end.\r \u0026lt;list\u0026gt;.remove(\u0026lt;el\u0026gt;) # Removes first occurrence of item or raises ValueError.\r \u0026lt;list\u0026gt;.clear() # Removes all items.  Dictionary \u0026lt;view\u0026gt; = \u0026lt;dict\u0026gt;.keys()\r\u0026lt;view\u0026gt; = \u0026lt;dict\u0026gt;.values()\r\u0026lt;view\u0026gt; = \u0026lt;dict\u0026gt;.items() value = \u0026lt;dict\u0026gt;.get(key, default=None) # Returns default if key does not exist.\r value = \u0026lt;dict\u0026gt;.setdefault(key, default=None) # Same, but also adds default to dict.\r \u0026lt;dict\u0026gt; = collections.defaultdict(\u0026lt;type\u0026gt;) # Creates a dict with default value of type.\r \u0026lt;dict\u0026gt; = collections.defaultdict(lambda: 1) # Creates a dict with default value 1. \u0026lt;dict\u0026gt;.update(\u0026lt;dict\u0026gt;) # Or: dict_a = {**dict_a, **dict_b}.\r \u0026lt;dict\u0026gt; = dict(\u0026lt;collection\u0026gt;) # Creates a dict from coll. of key-value pairs.\r \u0026lt;dict\u0026gt; = dict(zip(keys, values)) # Creates a dict from two collections.\r \u0026lt;dict\u0026gt; = dict.fromkeys(keys [, value]) # Creates a dict from collection of keys. value = \u0026lt;dict\u0026gt;.pop(key) # Removes item from dictionary.\r {k: v for k, v in \u0026lt;dict\u0026gt;.items() if k in keys} # Filters dictionary by keys. Counter \u0026gt;\u0026gt;\u0026gt; from collections import Counter\r\u0026gt;\u0026gt;\u0026gt; colors = [\u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;]\r\u0026gt;\u0026gt;\u0026gt; counter = Counter(colors)\rCounter({\u0026#39;blue\u0026#39;: 3, \u0026#39;red\u0026#39;: 2, \u0026#39;yellow\u0026#39;: 1})\r\u0026gt;\u0026gt;\u0026gt; counter.most_common()[0]\r(\u0026#39;blue\u0026#39;, 3) Set \u0026lt;set\u0026gt; = set() \u0026lt;set\u0026gt;.add(\u0026lt;el\u0026gt;)\r\u0026lt;set\u0026gt;.update(\u0026lt;collection\u0026gt;)\r\u0026lt;set\u0026gt; |= {\u0026lt;el\u0026gt;}\r\u0026lt;set\u0026gt; |= \u0026lt;set\u0026gt; \u0026lt;set\u0026gt; = \u0026lt;set\u0026gt;.union(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; | \u0026lt;set\u0026gt;\r \u0026lt;set\u0026gt; = \u0026lt;set\u0026gt;.intersection(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; \u0026amp; \u0026lt;set\u0026gt;\r \u0026lt;set\u0026gt; = \u0026lt;set\u0026gt;.difference(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; - \u0026lt;set\u0026gt;\r \u0026lt;set\u0026gt; = \u0026lt;set\u0026gt;.symmetric_difference(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; ^ \u0026lt;set\u0026gt;\r \u0026lt;bool\u0026gt; = \u0026lt;set\u0026gt;.issubset(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; \u0026lt;= \u0026lt;set\u0026gt;\r \u0026lt;bool\u0026gt; = \u0026lt;set\u0026gt;.issuperset(\u0026lt;coll.\u0026gt;) # Or: \u0026lt;set\u0026gt; \u0026gt;= \u0026lt;set\u0026gt; \u0026lt;set\u0026gt;.remove(\u0026lt;el\u0026gt;) # Throws error.\r \u0026lt;set\u0026gt;.discard(\u0026lt;el\u0026gt;) # Doesn\u0026#39;t throw error. Frozenset Is hashable, meaning it can be used as a key in dictionary or as an element in set. \u0026lt;frozenset\u0026gt; = frozenset(\u0026lt;collection\u0026gt;)\nRange \u0026lt;range\u0026gt; = range(to_exclusive)\r\u0026lt;range\u0026gt; = range(from_inclusive, to_exclusive)\r\u0026lt;range\u0026gt; = range(from_inclusive, to_exclusive, Â±step_size) from_inclusive = \u0026lt;range\u0026gt;.start\rto_exclusive = \u0026lt;range\u0026gt;.stop Enumerate for i, el in enumerate(\u0026lt;collection\u0026gt; [, i_start]):\r... Named Tuple  Tuple is an immutable and hashable list. Named tuple is its subclass with named elements.  \u0026gt;\u0026gt;\u0026gt; from collections import namedtuple\r\u0026gt;\u0026gt;\u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; p = Point(1, y=2)\rPoint(x=1, y=2)\r\u0026gt;\u0026gt;\u0026gt; p[0]\r1\r\u0026gt;\u0026gt;\u0026gt; p.x\r1\r\u0026gt;\u0026gt;\u0026gt; getattr(p, \u0026#39;y\u0026#39;)\r2\r\u0026gt;\u0026gt;\u0026gt; p._fields # Or: Point._fields\r (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) Iterator In this cheatsheet '\u0026lt;collection\u0026gt;' can also mean an iterator.\nfrom itertools import count, repeat, cycle, chain, islice \u0026lt;iter\u0026gt; = iter(\u0026lt;collection\u0026gt;)\r\u0026lt;iter\u0026gt; = iter(\u0026lt;function\u0026gt;, to_exclusive) # Sequence of return values until \u0026#39;to_exclusive\u0026#39;.\r \u0026lt;el\u0026gt; = next(\u0026lt;iter\u0026gt; [, default]) # Raises StopIteration or returns \u0026#39;default\u0026#39; on end. \u0026lt;iter\u0026gt; = count(start=0, step=1) # Returns incremented value endlessly.\r \u0026lt;iter\u0026gt; = repeat(\u0026lt;el\u0026gt; [, times]) # Returns element endlessly or \u0026#39;times\u0026#39; times.\r \u0026lt;iter\u0026gt; = cycle(\u0026lt;collection\u0026gt;) # Repeats the sequence indefinitely. \u0026lt;iter\u0026gt; = chain(\u0026lt;collection\u0026gt;, \u0026lt;collection\u0026gt;) # Empties collections in order.\r \u0026lt;iter\u0026gt; = chain.from_iterable(\u0026lt;collection\u0026gt;) # Empties collections inside a collection in order. \u0026lt;iter\u0026gt; = islice(\u0026lt;collection\u0026gt;, to_exclusive)\r\u0026lt;iter\u0026gt; = islice(\u0026lt;collection\u0026gt;, from_inclusive, to_exclusive)\r\u0026lt;iter\u0026gt; = islice(\u0026lt;collection\u0026gt;, from_inclusive, to_exclusive, step_size) Generator Convenient way to implement the iterator protocol.\ndef count(start, step):\rwhile True:\ryield start\rstart += step \u0026gt;\u0026gt;\u0026gt; counter = count(10, 2)\r\u0026gt;\u0026gt;\u0026gt; next(counter), next(counter), next(counter)\r(10, 12, 14) Type \u0026lt;type\u0026gt; = type(\u0026lt;el\u0026gt;) # \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; / \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; / ... from numbers import Integral, Rational, Real, Complex, Number\r\u0026lt;bool\u0026gt; = isinstance(\u0026lt;el\u0026gt;, Number) \u0026lt;bool\u0026gt; = callable(\u0026lt;el\u0026gt;) String \u0026lt;str\u0026gt; = \u0026lt;str\u0026gt;.strip() # Strips all whitespace characters from both ends.\r \u0026lt;str\u0026gt; = \u0026lt;str\u0026gt;.strip(\u0026#39;\u0026lt;chars\u0026gt;\u0026#39;) # Strips all passed characters from both ends. \u0026lt;list\u0026gt; = \u0026lt;str\u0026gt;.split() # Splits on any whitespace character.\r \u0026lt;list\u0026gt; = \u0026lt;str\u0026gt;.split(sep=None, maxsplit=-1) # Splits on \u0026#39;sep\u0026#39; str at most \u0026#39;maxsplit\u0026#39; times.\r \u0026lt;str\u0026gt; = \u0026lt;str\u0026gt;.join(\u0026lt;collection\u0026gt;) # Joins elements using string as separator. \u0026lt;str\u0026gt; = \u0026lt;str\u0026gt;.replace(old, new [, count]) # Replaces \u0026#39;old\u0026#39; with \u0026#39;new\u0026#39; at most \u0026#39;count\u0026#39; times.\r \u0026lt;bool\u0026gt; = \u0026lt;str\u0026gt;.startswith(\u0026lt;sub_str\u0026gt;) # Pass tuple of strings for multiple options.\r \u0026lt;bool\u0026gt; = \u0026lt;str\u0026gt;.endswith(\u0026lt;sub_str\u0026gt;) # Pass tuple of strings for multiple options.\r \u0026lt;int\u0026gt; = \u0026lt;str\u0026gt;.index(\u0026lt;sub_str\u0026gt;) # Returns start index of first match. \u0026lt;bool\u0026gt; = \u0026lt;str\u0026gt;.isnumeric() # True if str contains only numeric characters.\r \u0026lt;list\u0026gt; = textwrap.wrap(\u0026lt;str\u0026gt;, width) # Nicely breaks string into lines. Char \u0026lt;str\u0026gt; = chr(\u0026lt;int\u0026gt;) # Converts int to unicode char.\r \u0026lt;int\u0026gt; = ord(\u0026lt;str\u0026gt;) # Converts unicode char to int. \u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;0\u0026#39;), ord(\u0026#39;9\u0026#39;)\r(48, 57)\r\u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;A\u0026#39;), ord(\u0026#39;Z\u0026#39;)\r(65, 90)\r\u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;a\u0026#39;), ord(\u0026#39;z\u0026#39;)\r(97, 122) Regex import re\r\u0026lt;str\u0026gt; = re.sub(\u0026lt;regex\u0026gt;, new, text, count=0) # Substitutes all occurrences.\r \u0026lt;list\u0026gt; = re.findall(\u0026lt;regex\u0026gt;, text) # Returns all occurrences.\r \u0026lt;list\u0026gt; = re.split(\u0026lt;regex\u0026gt;, text, maxsplit=0) # Use brackets in regex to keep the matches.\r \u0026lt;Match\u0026gt; = re.search(\u0026lt;regex\u0026gt;, text) # Searches for first occurrence of pattern.\r \u0026lt;Match\u0026gt; = re.match(\u0026lt;regex\u0026gt;, text) # Searches only at the beginning of the text.\r \u0026lt;iter\u0026gt; = re.finditer(\u0026lt;regex\u0026gt;, text) # Returns all occurrences as match objects.  Parameter 'flags=re.IGNORECASE' can be used with all functions. Parameter 'flags=re.DOTALL' makes dot also accept newline.\n Use r'\\1' or '\\\\1' for backreference.\n Use '?' to make operator non-greedy.\n  Match Object \u0026lt;str\u0026gt; = \u0026lt;Match\u0026gt;.group() # Whole match.\r \u0026lt;str\u0026gt; = \u0026lt;Match\u0026gt;.group(1) # Part in first bracket.\r \u0026lt;tuple\u0026gt; = \u0026lt;Match\u0026gt;.groups() # All bracketed parts.\r \u0026lt;int\u0026gt; = \u0026lt;Match\u0026gt;.start() # Start index of a match.\r \u0026lt;int\u0026gt; = \u0026lt;Match\u0026gt;.end() # Exclusive end index of a match. Special Sequences Expressions below hold true for strings that contain only ASCII characters. Use capital letters for negation. \u0026#39;\\d\u0026#39; == \u0026#39;[0-9]\u0026#39; # Digit\r \u0026#39;\\s\u0026#39; == \u0026#39;[ \\t\\n\\r\\f\\v]\u0026#39; # Whitespace\r \u0026#39;\\w\u0026#39; == \u0026#39;[a-zA-Z0-9_]\u0026#39; # Alphanumeric\nFormat \u0026lt;str\u0026gt; = f\u0026#39;{\u0026lt;el_1\u0026gt;}, {\u0026lt;el_2\u0026gt;}\u0026#39;\r\u0026lt;str\u0026gt; = \u0026#39;{}, {}\u0026#39;.format(\u0026lt;el_1\u0026gt;, \u0026lt;el_2\u0026gt;) \u0026gt;\u0026gt;\u0026gt; Person = collections.namedtuple(\u0026#39;Person\u0026#39;, \u0026#39;name height\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; person = Person(\u0026#39;Jean-Luc\u0026#39;, 187)\r\u0026gt;\u0026gt;\u0026gt; f\u0026#39;{person.height}\u0026#39;\r\u0026#39;187\u0026#39;\r\u0026gt;\u0026gt;\u0026gt; \u0026#39;{p.height}\u0026#39;.format(p=person)\r\u0026#39;187\u0026#39; General Options {\u0026lt;el\u0026gt;:\u0026lt;10} # \u0026#39;\u0026lt;el\u0026gt; \u0026#39;\r {\u0026lt;el\u0026gt;:\u0026gt;10} # \u0026#39; \u0026lt;el\u0026gt;\u0026#39;\r {\u0026lt;el\u0026gt;:^10} # \u0026#39; \u0026lt;el\u0026gt; \u0026#39;\r {\u0026lt;el\u0026gt;:-\u0026gt;10} # \u0026#39;------\u0026lt;el\u0026gt;\u0026#39;\r {\u0026lt;el\u0026gt;:\u0026gt;0} # \u0026#39;\u0026lt;el\u0026gt;\u0026#39; String Options '!r' calls object\u0026rsquo;s repr() method, instead of format(), to get a string. {\u0026#39;abcde\u0026#39;!r:\u0026lt;10} # \u0026#34;\u0026#39;abcde\u0026#39; \u0026#34;\n{\u0026#39;abcde\u0026#39;:.3} # \u0026#39;abc\u0026#39;\r {\u0026#39;abcde\u0026#39;:10.3} # \u0026#39;abc \u0026#39; Number Options {1.23456:.3f} # \u0026#39;1.235\u0026#39;\r {1.23456:10.3f} # \u0026#39; 1.235\u0026#39; { 123456:10,} # \u0026#39; 123,456\u0026#39;\r { 123456:10_} # \u0026#39; 123_456\u0026#39;\r { 123456:+10} # \u0026#39; +123456\u0026#39;\r {-123456:=10} # \u0026#39;- 123456\u0026#39;\r { 123456: } # \u0026#39; 123456\u0026#39;\r {-123456: } # \u0026#39;-123456\u0026#39; {65:c} # \u0026#39;A\u0026#39;\r {3:08b} # \u0026#39;00000011\u0026#39; -\u0026gt; Binary with leading zeros.\r {3:0\u0026lt;8b} # \u0026#39;11000000\u0026#39; -\u0026gt; Binary with trailing zeros. Float presentation types: * 'f' - Fixed point: .\u0026lt;precision\u0026gt;f * '%' - Percent: .\u0026lt;precision\u0026gt;% * 'e' - Exponent\nInteger presentation types: * 'c' - character * 'b' - binary * 'x' - hex * 'X' - HEX\nNumbers Basic Functions \u0026lt;num\u0026gt; = pow(\u0026lt;num\u0026gt;, \u0026lt;num\u0026gt;) # Or: \u0026lt;num\u0026gt; ** \u0026lt;num\u0026gt;\r \u0026lt;real\u0026gt; = abs(\u0026lt;num\u0026gt;)\r\u0026lt;int\u0026gt; = round(\u0026lt;real\u0026gt;)\r\u0026lt;real\u0026gt; = round(\u0026lt;real\u0026gt;, Â±ndigits) Math from math import e, pi\rfrom math import cos, acos, sin, asin, tan, atan, degrees, radians\rfrom math import log, log10, log2\rfrom math import inf, nan, isinf, isnan Statistics from statistics import mean, median, variance, pvariance, pstdev Random from random import random, randint, choice, shuffle\r\u0026lt;float\u0026gt; = random()\r\u0026lt;int\u0026gt; = randint(from_inclusive, to_inclusive)\r\u0026lt;el\u0026gt; = choice(\u0026lt;list\u0026gt;)\rshuffle(\u0026lt;list\u0026gt;) Combinatorics  Every function returns an iterator. If you want to print the iterator, you need to pass it to the list() function!  from itertools import product, combinations, combinations_with_replacement, permutations \u0026gt;\u0026gt;\u0026gt; product([0, 1], repeat=3)\r[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)] \u0026gt;\u0026gt;\u0026gt; product(\u0026#39;ab\u0026#39;, \u0026#39;12\u0026#39;)\r[(\u0026#39;a\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;2\u0026#39;),\r(\u0026#39;b\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;2\u0026#39;)] \u0026gt;\u0026gt;\u0026gt; combinations(\u0026#39;abc\u0026#39;, 2)\r[(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)] \u0026gt;\u0026gt;\u0026gt; combinations_with_replacement(\u0026#39;abc\u0026#39;, 2)\r[(\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;), (\u0026#39;c\u0026#39;, \u0026#39;c\u0026#39;)] \u0026gt;\u0026gt;\u0026gt; permutations(\u0026#39;abc\u0026#39;, 2)\r[(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;), (\u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;), (\u0026#39;c\u0026#39;, \u0026#39;b\u0026#39;)] Datetime from datetime import datetime\rnow = datetime.now()\rnow.month # 3\r now.strftime(\u0026#39;%Y%m%d\u0026#39;) # \u0026#39;20180315\u0026#39;\r now.strftime(\u0026#39;%Y%m%d%H%M%S\u0026#39;) # \u0026#39;20180315002834\u0026#39;\r \u0026lt;datetime\u0026gt; = datetime.strptime(\u0026#39;2015-05-12 00:39\u0026#39;, \u0026#39;%Y-%m-%d%H:%M\u0026#39;) Arguments Inside Function Call \u0026lt;function\u0026gt;(\u0026lt;positional_args\u0026gt;) # f(0, 0)\r \u0026lt;function\u0026gt;(\u0026lt;keyword_args\u0026gt;) # f(x=0, y=0)\r \u0026lt;function\u0026gt;(\u0026lt;positional_args\u0026gt;, \u0026lt;keyword_args\u0026gt;) # f(0, y=0) Inside Function Definition def f(\u0026lt;nondefault_args\u0026gt;): # def f(x, y)\r def f(\u0026lt;default_args\u0026gt;): # def f(x=0, y=0)\r def f(\u0026lt;nondefault_args\u0026gt;, \u0026lt;default_args\u0026gt;): # def f(x, y=0) Splat Operator Inside Function Call Splat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments. args = (1, 2)\rkwargs = {\u0026#39;x\u0026#39;: 3, \u0026#39;y\u0026#39;: 4, \u0026#39;z\u0026#39;: 5}\rfunc(*args, **kwargs) \nIs the same as: func(1, 2, x=3, y=4, z=5)\nInside Function Definition Splat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary. def add(*a):\rreturn sum(a)\n\u0026gt;\u0026gt;\u0026gt; add(1, 2, 3)\r6 Legal argument combinations: def f(*args): # f(1, 2, 3)\r def f(x, *args): # f(1, 2, 3)\r def f(*args, z): # f(1, 2, z=3)\r def f(x, *args, z): # f(1, 2, z=3)\ndef f(**kwargs): # f(x=1, y=2, z=3)\r def f(x, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) def f(*args, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)\r def f(x, *args, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)\r def f(*args, y, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3)\r def f(x, *args, z, **kwargs): # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) Other Uses \u0026lt;list\u0026gt; = [*\u0026lt;collection\u0026gt; [, ...]]\r\u0026lt;set\u0026gt; = {*\u0026lt;collection\u0026gt; [, ...]}\r\u0026lt;tuple\u0026gt; = (*\u0026lt;collection\u0026gt;, [...])\r\u0026lt;dict\u0026gt; = {**\u0026lt;dict\u0026gt; [, ...]} head, *body, tail = \u0026lt;collection\u0026gt; Inline Lambda \u0026lt;function\u0026gt; = lambda: \u0026lt;return_value\u0026gt;\r\u0026lt;function\u0026gt; = lambda \u0026lt;argument_1\u0026gt;, \u0026lt;argument_2\u0026gt;: \u0026lt;return_value\u0026gt; Comprehension \u0026lt;list\u0026gt; = [i+1 for i in range(10)] # [1, 2, ..., 10]\r \u0026lt;set\u0026gt; = {i for i in range(10) if i \u0026gt; 5} # {6, 7, 8, 9}\r \u0026lt;iter\u0026gt; = (i+5 for i in range(10)) # (5, 6, ..., 14)\r \u0026lt;dict\u0026gt; = {i: i*2 for i in range(10)} # {0: 0, 1: 2, ..., 9: 18} out = [i+j for i in range(10) for j in range(10)] Is the same as: out = []\rfor i in range(10):\rfor j in range(10):\rout.append(i+j)\nMap, Filter, Reduce from functools import reduce\r\u0026lt;iter\u0026gt; = map(lambda x: x + 1, range(10)) # (1, 2, ..., 10)\r \u0026lt;iter\u0026gt; = filter(lambda x: x \u0026gt; 5, range(10)) # (6, 7, 8, 9)\r \u0026lt;int\u0026gt; = reduce(lambda out, x: out + x, range(10)) # 45 Any, All \u0026lt;bool\u0026gt; = any(\u0026lt;collection\u0026gt;) # False if empty.\r \u0026lt;bool\u0026gt; = all(el[1] for el in \u0026lt;collection\u0026gt;) # True if empty. If - Else \u0026lt;expression_if_true\u0026gt; if \u0026lt;condition\u0026gt; else \u0026lt;expression_if_false\u0026gt; \u0026gt;\u0026gt;\u0026gt; [a if a else \u0026#39;zero\u0026#39; for a in (0, 1, 0, 3)]\r[\u0026#39;zero\u0026#39;, 1, \u0026#39;zero\u0026#39;, 3] Namedtuple, Enum, Class from collections import namedtuple\rPoint = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y\u0026#39;)\rpoint = Point(0, 0) from enum import Enum\rDirection = Enum(\u0026#39;Direction\u0026#39;, \u0026#39;n e s w\u0026#39;)\rCutlery = Enum(\u0026#39;Cutlery\u0026#39;, {\u0026#39;fork\u0026#39;: 1, \u0026#39;knife\u0026#39;: 2, \u0026#39;spoon\u0026#39;: 3}) # Warning: Objects will share the objects that are initialized in the dictionary!\r Creature = type(\u0026#39;Creature\u0026#39;, (), {\u0026#39;p\u0026#39;: Point(0, 0), \u0026#39;d\u0026#39;: Direction.n})\rcreature = Creature() Closure We have a closure in Python when: * A nested function references a value of its enclosing function and then * the enclosing function returns the nested function.\ndef get_multiplier(a):\rdef out(b):\rreturn a * b\rreturn out \u0026gt;\u0026gt;\u0026gt; multiply_by_3 = get_multiplier(3)\r\u0026gt;\u0026gt;\u0026gt; multiply_by_3(10)\r30  If multiple nested functions within enclosing function reference the same value, that value gets shared. To dynamically access function\u0026rsquo;s first free variable use '\u0026lt;function\u0026gt;.__closure__[0].cell_contents'.  Partial from functools import partial\r\u0026lt;function\u0026gt; = partial(\u0026lt;function\u0026gt; [, \u0026lt;arg_1\u0026gt;, \u0026lt;arg_2\u0026gt;, ...]) \u0026gt;\u0026gt;\u0026gt; multiply_by_3 = partial(operator.mul, 3)\r\u0026gt;\u0026gt;\u0026gt; multiply_by_3(10)\r30 Nonlocal If variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a \u0026lsquo;global\u0026rsquo; or \u0026lsquo;nonlocal\u0026rsquo;.\ndef get_counter():\ri = 0\rdef out():\rnonlocal i\ri += 1\rreturn i\rreturn out \u0026gt;\u0026gt;\u0026gt; counter = get_counter()\r\u0026gt;\u0026gt;\u0026gt; counter(), counter(), counter()\r(1, 2, 3) Decorator A decorator takes a function, adds some functionality and returns it.\n@decorator_name\rdef function_that_gets_passed_to_decorator():\r... Debugger Example Decorator that prints function\u0026rsquo;s name every time it gets called.\nfrom functools import wraps\rdef debug(func):\r@wraps(func)\rdef out(*args, **kwargs):\rprint(func.__name__)\rreturn func(*args, **kwargs)\rreturn out\r@debug\rdef add(x, y):\rreturn x + y * Wraps is a helper decorator that copies metadata of function add() to function out(). * Without it 'add.__name__' would return 'out'.\nLRU Cache Decorator that caches function\u0026rsquo;s return values. All function\u0026rsquo;s arguments must be hashable.\nfrom functools import lru_cache\r@lru_cache(maxsize=None)\rdef fib(n):\rreturn n if n \u0026lt; 2 else fib(n-2) + fib(n-1)  Recursion depth is limited to 1000 by default. To increase it use 'sys.setrecursionlimit(\u0026lt;depth\u0026gt;)'.  Parametrized Decorator from functools import wraps\rdef debug(print_result=False):\rdef decorator(func):\r@wraps(func)\rdef out(*args, **kwargs):\rresult = func(*args, **kwargs)\rprint(func.__name__, result if print_result else \u0026#39;\u0026#39;)\rreturn result\rreturn out\rreturn decorator\r@debug(print_result=True)\rdef add(x, y):\rreturn x + y Class class \u0026lt;name\u0026gt;:\rdef __init__(self, a):\rself.a = a\rdef __repr__(self):\rclass_name = self.__class__.__name__\rreturn f\u0026#39;{class_name}({self.a!r})\u0026#39;\rdef __str__(self):\rreturn str(self.a)\r@classmethod\rdef get_class_name(cls):\rreturn cls.__name__ Constructor Overloading class \u0026lt;name\u0026gt;:\rdef __init__(self, a=None):\rself.a = a Inheritance class Person:\rdef __init__(self, name, age):\rself.name = name\rself.age = age\rclass Employee(Person):\rdef __init__(self, name, age, staff_num):\rsuper().__init__(name, age)\rself.staff_num = staff_num Comparable  If eq() method is not overridden, it returns 'id(self) == id(other)', which is the same as 'self is other'. That means all objects compare not equal by default.  class MyComparable:\rdef __init__(self, a):\rself.a = a\rdef __eq__(self, other):\rif isinstance(other, type(self)):\rreturn self.a == other.a\rreturn False  Hashable  Hashable object needs both hash() and eq() methods and its hash value should never change. Hashable objects that compare equal must have the same hash value, meaning default hash() that returns 'id(self)' will not do. That is why Python automatically makes classes unhashable if you only implement eq().  class MyHashable:\rdef __init__(self, a):\rself.__a = copy.deepcopy(a)\r@property\rdef a(self):\rreturn self.__a\rdef __eq__(self, other):\rif isinstance(other, type(self)):\rreturn self.a == other.a\rreturn False def __hash__(self):\rreturn hash(self.a) Sequence  Methods do not depend on each other, so they can be skipped if not needed. Any object with defined getitem() is considered iterable, even if it lacks iter(). class MySequence:\rdef __init__(self, a):\rself.a = a\rdef __len__(self):\rreturn len(self.a)\rdef __getitem__(self, i):\rreturn self.a[i]\rdef __iter__(self):\rfor el in self.a:\ryield el  Callable class Counter:\rdef __init__(self):\rself.i = 0\rdef __call__(self):\rself.i += 1\rreturn self.i \u0026gt;\u0026gt;\u0026gt; counter = Counter()\r\u0026gt;\u0026gt;\u0026gt; counter(), counter(), counter()\r(1, 2, 3) Withable class MyOpen():\rdef __init__(self, filename):\rself.filename = filename\rdef __enter__(self):\rself.file = open(self.filename)\rreturn self.file\rdef __exit__(self, *args):\rself.file.close() \u0026gt;\u0026gt;\u0026gt; with open(\u0026#39;test.txt\u0026#39;, \u0026#39;w\u0026#39;) as file:\r... file.write(\u0026#39;Hello World!\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; with MyOpen(\u0026#39;test.txt\u0026#39;) as file:\r... print(file.read())\rHello World! Copy from copy import copy, deepcopy\r\u0026lt;object\u0026gt; = copy(\u0026lt;object\u0026gt;)\r\u0026lt;object\u0026gt; = deepcopy(\u0026lt;object\u0026gt;) Enum from enum import Enum, auto\rclass \u0026lt;enum_name\u0026gt;(Enum):\r\u0026lt;member_name_1\u0026gt; = \u0026lt;value_1\u0026gt; \u0026lt;member_name_2\u0026gt; = \u0026lt;value_2_a\u0026gt;, \u0026lt;value_2_b\u0026gt;\r\u0026lt;member_name_3\u0026gt; = auto()\r@classmethod\rdef get_member_names(cls):\rreturn [a.name for a in cls.__members__.values()] \u0026lt;member\u0026gt; = \u0026lt;enum\u0026gt;.\u0026lt;member_name\u0026gt;\r\u0026lt;member\u0026gt; = \u0026lt;enum\u0026gt;[\u0026#39;\u0026lt;member_name\u0026gt;\u0026#39;]\r\u0026lt;member\u0026gt; = \u0026lt;enum\u0026gt;(\u0026lt;value\u0026gt;)\rname = \u0026lt;member\u0026gt;.name\rvalue = \u0026lt;member\u0026gt;.value list_of_members = list(\u0026lt;enum\u0026gt;)\rmember_names = [a.name for a in \u0026lt;enum\u0026gt;]\rmember_values = [a.value for a in \u0026lt;enum\u0026gt;]\rrandom_member = random.choice(list(\u0026lt;enum\u0026gt;)) Inline Cutlery = Enum(\u0026#39;Cutlery\u0026#39;, [\u0026#39;fork\u0026#39;, \u0026#39;knife\u0026#39;, \u0026#39;spoon\u0026#39;])\rCutlery = Enum(\u0026#39;Cutlery\u0026#39;, \u0026#39;fork knife spoon\u0026#39;)\rCutlery = Enum(\u0026#39;Cutlery\u0026#39;, {\u0026#39;fork\u0026#39;: 1, \u0026#39;knife\u0026#39;: 2, \u0026#39;spoon\u0026#39;: 3}) Functions can not be values, so they must be wrapped: from functools import partial\rLogicOp = Enum(\u0026#39;LogicOp\u0026#39;, {\u0026#39;AND\u0026#39;: partial(lambda l, r: l and r),\r\u0026#39;OR\u0026#39; : partial(lambda l, r: l or r)})\nExceptions while True:\rtry:\rx = int(input(\u0026#39;Please enter a number: \u0026#39;))\rexcept ValueError:\rprint(\u0026#39;Oops! That was no valid number. Try again...\u0026#39;)\relse:\rprint(\u0026#39;Thank you.\u0026#39;)\rbreak Raising Exception raise ValueError(\u0026#39;A very specific message!\u0026#39;) Finally \u0026gt;\u0026gt;\u0026gt; try:\r... raise KeyboardInterrupt\r... finally:\r... print(\u0026#39;Goodbye, world!\u0026#39;)\rGoodbye, world!\rTraceback (most recent call last):\rFile \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 2, in \u0026lt;module\u0026gt;\rKeyboardInterrupt Print print(\u0026lt;el_1\u0026gt;, ..., sep=\u0026#39; \u0026#39;, end=\u0026#39;\\n\u0026#39;, file=sys.stdout, flush=False)  Use 'file=sys.stderr' for errors.  Pretty Print \u0026gt;\u0026gt;\u0026gt; from pprint import pprint\r\u0026gt;\u0026gt;\u0026gt; pprint(dir())\r[\u0026#39;__annotations__\u0026#39;,\r\u0026#39;__builtins__\u0026#39;,\r\u0026#39;__doc__\u0026#39;, ...] Input  Reads a line from user input or pipe if present. Trailing newline gets stripped. Prompt string is printed to the standard output before reading input.  \u0026lt;str\u0026gt; = input(prompt=None) Prints lines until EOF: while True:\rtry:\rprint(input())\rexcept EOFError:\rbreak\nCommand Line Arguments import sys\rscript_name = sys.argv[0]\rarguments = sys.argv[1:] Argparse from argparse import ArgumentParser, FileType\rp = ArgumentParser(description=\u0026lt;str\u0026gt;)\rp.add_argument(\u0026#39;-\u0026lt;short_name\u0026gt;\u0026#39;, \u0026#39;--\u0026lt;name\u0026gt;\u0026#39;, action=\u0026#39;store_true\u0026#39;) # Flag\r p.add_argument(\u0026#39;-\u0026lt;short_name\u0026gt;\u0026#39;, \u0026#39;--\u0026lt;name\u0026gt;\u0026#39;, type=\u0026lt;type\u0026gt;) # Option\r p.add_argument(\u0026#39;\u0026lt;name\u0026gt;\u0026#39;, type=\u0026lt;type\u0026gt;, nargs=1) # Argument\r p.add_argument(\u0026#39;\u0026lt;name\u0026gt;\u0026#39;, type=\u0026lt;type\u0026gt;, nargs=\u0026#39;+\u0026#39;) # Arguments\r args = p.parse_args()\rvalue = args.\u0026lt;name\u0026gt;  Use 'help=\u0026lt;str\u0026gt;' for argument description. Use 'type=FileType(\u0026lt;mode\u0026gt;)' for files.  Open Opens file and returns a corresponding file object.\n\u0026lt;file\u0026gt; = open(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=None) Modes  'r' - Read (default). 'w' - Write (truncate). 'x' - Write or fail if the file already exists. 'a' - Append. 'w+' - Read and write (truncate). 'r+' - Read and write from the start. 'a+' - Read and write from the end. 't' - Text mode (default). 'b' - Binary mode.  Seek \u0026lt;file\u0026gt;.seek(0) # Move to the start of the file.\r \u0026lt;file\u0026gt;.seek(offset) # Move \u0026#39;offset\u0026#39; chars/bytes from the start.\r \u0026lt;file\u0026gt;.seek(offset, \u0026lt;anchor\u0026gt;) # Anchor: 0 start, 1 current pos., 2 end. Read Text from File def read_file(filename):\rwith open(filename, encoding=\u0026#39;utf-8\u0026#39;) as file:\rreturn file.readlines() Write Text to File def write_to_file(filename, text):\rwith open(filename, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file:\rfile.write(text) Path from os import path, listdir\r\u0026lt;bool\u0026gt; = path.exists(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;)\r\u0026lt;bool\u0026gt; = path.isfile(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;)\r\u0026lt;bool\u0026gt; = path.isdir(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;)\r\u0026lt;list\u0026gt; = listdir(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;) \u0026gt;\u0026gt;\u0026gt; from glob import glob\r\u0026gt;\u0026gt;\u0026gt; glob(\u0026#39;../*.gif\u0026#39;)\r[\u0026#39;1.gif\u0026#39;, \u0026#39;card.gif\u0026#39;] Pathlib from pathlib import Path\rcwd = Path()\r\u0026lt;Path\u0026gt; = Path(\u0026#39;\u0026lt;path\u0026gt;\u0026#39; [, \u0026#39;\u0026lt;path\u0026gt;\u0026#39;, \u0026lt;Path\u0026gt;, ...])\r\u0026lt;Path\u0026gt; = \u0026lt;Path\u0026gt; / \u0026#39;\u0026lt;dir\u0026gt;\u0026#39; / \u0026#39;\u0026lt;file\u0026gt;\u0026#39; \u0026lt;bool\u0026gt; = \u0026lt;Path\u0026gt;.exists()\r\u0026lt;bool\u0026gt; = \u0026lt;Path\u0026gt;.is_file()\r\u0026lt;bool\u0026gt; = \u0026lt;Path\u0026gt;.is_dir()\r\u0026lt;iter\u0026gt; = \u0026lt;Path\u0026gt;.iterdir()\r\u0026lt;iter\u0026gt; = \u0026lt;Path\u0026gt;.glob(\u0026#39;\u0026lt;pattern\u0026gt;\u0026#39;) \u0026lt;str\u0026gt; = str(\u0026lt;Path\u0026gt;) # Returns path as string.\r \u0026lt;tup.\u0026gt; = \u0026lt;Path\u0026gt;.parts # Returns all components as strings.\r \u0026lt;Path\u0026gt; = \u0026lt;Path\u0026gt;.resolve() # Returns absolute path without symlinks. \u0026lt;str\u0026gt; = \u0026lt;Path\u0026gt;.name # Final component.\r \u0026lt;str\u0026gt; = \u0026lt;Path\u0026gt;.stem # Final component without extension.\r \u0026lt;str\u0026gt; = \u0026lt;Path\u0026gt;.suffix # Final component\u0026#39;s extension.\r \u0026lt;Path\u0026gt; = \u0026lt;Path\u0026gt;.parent # Path without final component. Command Execution import os\r\u0026lt;str\u0026gt; = os.popen(\u0026lt;command\u0026gt;).read() Subprocess \u0026gt;\u0026gt;\u0026gt; import subprocess\r\u0026gt;\u0026gt;\u0026gt; a = subprocess.run([\u0026#39;ls\u0026#39;, \u0026#39;-a\u0026#39;], stdout=subprocess.PIPE)\r\u0026gt;\u0026gt;\u0026gt; a.stdout\rb\u0026#39;.\\n..\\nfile1.txt\\nfile2.txt\\n\u0026#39;\r\u0026gt;\u0026gt;\u0026gt; a.returncode\r0 CSV import csv Read Rows from CSV File def read_csv_file(filename):\rwith open(filename, encoding=\u0026#39;utf-8\u0026#39;) as file:\rreturn csv.reader(file, delimiter=\u0026#39;;\u0026#39;) Write Rows to CSV File def write_to_csv_file(filename, rows):\rwith open(filename, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file:\rwriter = csv.writer(file, delimiter=\u0026#39;;\u0026#39;)\rwriter.writerows(rows) JSON import json\r\u0026lt;str\u0026gt; = json.dumps(\u0026lt;object\u0026gt;, ensure_ascii=True, indent=None)\r\u0026lt;object\u0026gt; = json.loads(\u0026lt;str\u0026gt;) Read Object from JSON File def read_json_file(filename):\rwith open(filename, encoding=\u0026#39;utf-8\u0026#39;) as file:\rreturn json.load(file) Write Object to JSON File def write_to_json_file(filename, an_object):\rwith open(filename, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file:\rjson.dump(an_object, file, ensure_ascii=False, indent=2) Pickle import pickle\r\u0026lt;bytes\u0026gt; = pickle.dumps(\u0026lt;object\u0026gt;)\r\u0026lt;object\u0026gt; = pickle.loads(\u0026lt;bytes\u0026gt;) Read Object from File def read_pickle_file(filename):\rwith open(filename, \u0026#39;rb\u0026#39;) as file:\rreturn pickle.load(file) Write Object to File def write_to_pickle_file(filename, an_object):\rwith open(filename, \u0026#39;wb\u0026#39;) as file:\rpickle.dump(an_object, file) SQLite import sqlite3\rdb = sqlite3.connect(\u0026#39;\u0026lt;path\u0026gt;\u0026#39;)\r...\rdb.close() Read cursor = db.execute(\u0026#39;\u0026lt;query\u0026gt;\u0026#39;)\rif cursor:\r\u0026lt;tuple\u0026gt; = cursor.fetchone() # First row.\r \u0026lt;list\u0026gt; = cursor.fetchall() # Remaining rows. Write db.execute(\u0026#39;\u0026lt;query\u0026gt;\u0026#39;)\rdb.commit() Bytes Bytes object is an immutable sequence of single bytes. Mutable version is called \u0026lsquo;bytearray\u0026rsquo;.\n\u0026lt;bytes\u0026gt; = b\u0026#39;\u0026lt;str\u0026gt;\u0026#39;\r\u0026lt;int\u0026gt; = \u0026lt;bytes\u0026gt;[\u0026lt;index\u0026gt;]\r\u0026lt;bytes\u0026gt; = \u0026lt;bytes\u0026gt;[\u0026lt;slice\u0026gt;]\r\u0026lt;ints\u0026gt; = list(\u0026lt;bytes\u0026gt;)\r\u0026lt;bytes\u0026gt; = b\u0026#39;\u0026#39;.join(\u0026lt;coll_of_bytes\u0026gt;) Encode \u0026lt;bytes\u0026gt; = \u0026lt;str\u0026gt;.encode(encoding=\u0026#39;utf-8\u0026#39;)\r\u0026lt;bytes\u0026gt; = \u0026lt;int\u0026gt;.to_bytes(\u0026lt;length\u0026gt;, byteorder=\u0026#39;big|little\u0026#39;, signed=False)\r\u0026lt;bytes\u0026gt; = bytes.fromhex(\u0026#39;\u0026lt;hex\u0026gt;\u0026#39;) Decode \u0026lt;str\u0026gt; = \u0026lt;bytes\u0026gt;.decode(encoding=\u0026#39;utf-8\u0026#39;) \u0026lt;int\u0026gt; = int.from_bytes(\u0026lt;bytes\u0026gt;, byteorder=\u0026#39;big|little\u0026#39;, signed=False)\r\u0026lt;hex\u0026gt; = \u0026lt;bytes\u0026gt;.hex() Read Bytes from File def read_bytes(filename):\rwith open(filename, \u0026#39;rb\u0026#39;) as file:\rreturn file.read() Write Bytes to File def write_bytes(filename, bytes_obj):\rwith open(filename, \u0026#39;wb\u0026#39;) as file:\rfile.write(bytes_obj) Struct  Module that performs conversions between Python values and a C struct, represented as a Python bytes object. Machineâs native type sizes and byte order are used by default.  from struct import pack, unpack, iter_unpack, calcsize\r\u0026lt;bytes\u0026gt; = pack(\u0026#39;\u0026lt;format\u0026gt;\u0026#39;, \u0026lt;value_1\u0026gt; [, \u0026lt;value_2\u0026gt;, ...])\r\u0026lt;tuple\u0026gt; = unpack(\u0026#39;\u0026lt;format\u0026gt;\u0026#39;, \u0026lt;bytes\u0026gt;)\r\u0026lt;tuples\u0026gt; = iter_unpack(\u0026#39;\u0026lt;format\u0026gt;\u0026#39;, \u0026lt;bytes\u0026gt;) Example \u0026gt;\u0026gt;\u0026gt; pack(\u0026#39;\u0026gt;hhl\u0026#39;, 1, 2, 3)\rb\u0026#39;\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03\u0026#39;\r\u0026gt;\u0026gt;\u0026gt; unpack(\u0026#39;\u0026gt;hhl\u0026#39;, b\u0026#39;\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03\u0026#39;)\r(1, 2, 3)\r\u0026gt;\u0026gt;\u0026gt; calcsize(\u0026#39;\u0026gt;hhl\u0026#39;)\r8 Format For standard sizes start format string with: * '=' - native byte order * '\u0026lt;' - little-endian * '\u0026gt;' - big-endian\nUse capital letter for unsigned type. Standard sizes are in brackets: * 'x' - pad byte * 'c' - char (1) * 'h' - short (2) * 'i' - int (4) * 'l' - long (4) * 'q' - long long (8) * 'f' - float (4) * 'd' - double (8)\nArray List that can hold only elements of predefined type. Available types are listed above.\nfrom array import array\r\u0026lt;array\u0026gt; = array(\u0026#39;\u0026lt;typecode\u0026gt;\u0026#39; [, \u0026lt;collection\u0026gt;]) Memory View Used for accessing the internal data of an object that supports the buffer protocol.\n\u0026lt;memoryview\u0026gt; = memoryview(\u0026lt;bytes\u0026gt; / \u0026lt;bytearray\u0026gt; / \u0026lt;array\u0026gt;) \u0026lt;memoryview\u0026gt;.release() Deque Thread-safe list with efficient appends and pops from either side. Pronounced \u0026ldquo;deck\u0026rdquo;.\nfrom collections import deque\r\u0026lt;deque\u0026gt; = deque(\u0026lt;collection\u0026gt;, maxlen=None) \u0026lt;deque\u0026gt;.appendleft(\u0026lt;el\u0026gt;)\r\u0026lt;el\u0026gt; = \u0026lt;deque\u0026gt;.popleft() \u0026lt;deque\u0026gt;.extendleft(\u0026lt;collection\u0026gt;) # Collection gets reversed.\r \u0026lt;deque\u0026gt;.rotate(n=1) # Rotates elements to the right. Threading from threading import Thread, RLock Thread thread = Thread(target=\u0026lt;function\u0026gt;, args=(\u0026lt;first_arg\u0026gt;, ))\rthread.start()\r...\rthread.join() Lock lock = RLock()\rlock.acquire()\r...\rlock.release() Introspection Inspecting code at runtime.\nVariables \u0026lt;list\u0026gt; = dir() # Names of in-scope variables.\r \u0026lt;dict\u0026gt; = locals() # Dict of local variables. Also vars().\r \u0026lt;dict\u0026gt; = globals() # Dict of global variables. Attributes \u0026lt;dict\u0026gt; = vars(\u0026lt;object\u0026gt;)\r\u0026lt;bool\u0026gt; = hasattr(\u0026lt;object\u0026gt;, \u0026#39;\u0026lt;attr_name\u0026gt;\u0026#39;)\rvalue = getattr(\u0026lt;object\u0026gt;, \u0026#39;\u0026lt;attr_name\u0026gt;\u0026#39;)\rsetattr(\u0026lt;object\u0026gt;, \u0026#39;\u0026lt;attr_name\u0026gt;\u0026#39;, value) Parameters from inspect import signature\rsig = signature(\u0026lt;function\u0026gt;)\rno_of_params = len(sig.parameters)\rparam_names = list(sig.parameters.keys()) Metaprograming Code that generates code.\nType Type is the root class. If only passed the object it returns its type (class). Otherwise it creates a new class.\n\u0026lt;class\u0026gt; = type(\u0026lt;class_name\u0026gt;, \u0026lt;parents_tuple\u0026gt;, \u0026lt;attributes_dict\u0026gt;) \u0026gt;\u0026gt;\u0026gt; Z = type(\u0026#39;Z\u0026#39;, (), {\u0026#39;a\u0026#39;: \u0026#39;abcde\u0026#39;, \u0026#39;b\u0026#39;: 12345})\r\u0026gt;\u0026gt;\u0026gt; z = Z() Meta Class Class that creates class.\ndef my_meta_class(name, parents, attrs):\rattrs[\u0026#39;a\u0026#39;] = \u0026#39;abcde\u0026#39;\rreturn type(name, parents, attrs) Or: class MyMetaClass(type):\rdef __new__(cls, name, parents, attrs):\rattrs[\u0026#39;a\u0026#39;] = \u0026#39;abcde\u0026#39;\rreturn type.__new__(cls, name, parents, attrs)\nMetaclass Attribute When class is created it checks if it has metaclass defined. If not, it recursively checks if any of his parents has it defined and eventually comes to type.\nclass MyClass(metaclass=MyMetaClass):\rb = 12345 \u0026gt;\u0026gt;\u0026gt; MyClass.a, MyClass.b\r(\u0026#39;abcde\u0026#39;, 12345) Operator from operator import add, sub, mul, truediv, floordiv, mod, pow, neg, abs\rfrom operator import eq, ne, lt, le, gt, ge\rfrom operator import not_, and_, or_\rfrom operator import itemgetter, attrgetter, methodcaller import operator as op\rproduct_of_elems = functools.reduce(op.mul, \u0026lt;collection\u0026gt;)\rsorted_by_second = sorted(\u0026lt;collection\u0026gt;, key=op.itemgetter(1))\rsorted_by_both = sorted(\u0026lt;collection\u0026gt;, key=op.itemgetter(1, 0))\rLogicOp = enum.Enum(\u0026#39;LogicOp\u0026#39;, {\u0026#39;AND\u0026#39;: op.and_, \u0026#39;OR\u0026#39; : op.or_})\rlast_el = op.methodcaller(\u0026#39;pop\u0026#39;)(\u0026lt;list\u0026gt;) Eval Basic \u0026gt;\u0026gt;\u0026gt; from ast import literal_eval\r\u0026gt;\u0026gt;\u0026gt; literal_eval(\u0026#39;1 + 2\u0026#39;)\r3\r\u0026gt;\u0026gt;\u0026gt; literal_eval(\u0026#39;[1, 2, 3]\u0026#39;)\r[1, 2, 3]\r\u0026gt;\u0026gt;\u0026gt; literal_eval(\u0026#39;abs(1)\u0026#39;)\rValueError: malformed node or string Using Abstract Syntax Trees import ast\rfrom ast import Num, BinOp, UnaryOp\rimport operator as op\rLEGAL_OPERATORS = {ast.Add: op.add, # \u0026lt;el\u0026gt; + \u0026lt;el\u0026gt;\r ast.Sub: op.sub, # \u0026lt;el\u0026gt; - \u0026lt;el\u0026gt;\r ast.Mult: op.mul, # \u0026lt;el\u0026gt; * \u0026lt;el\u0026gt;\r ast.Div: op.truediv, # \u0026lt;el\u0026gt; / \u0026lt;el\u0026gt;\r ast.Pow: op.pow, # \u0026lt;el\u0026gt; ** \u0026lt;el\u0026gt;\r ast.BitXor: op.xor, # \u0026lt;el\u0026gt; ^ \u0026lt;el\u0026gt;\r ast.USub: op.neg} # - \u0026lt;el\u0026gt;\r def evaluate(expression):\rroot = ast.parse(expression, mode=\u0026#39;eval\u0026#39;)\rreturn eval_node(root.body)\rdef eval_node(node):\rnode_type = type(node)\rif node_type == Num:\rreturn node.n\rif node_type not in [BinOp, UnaryOp]:\rraise TypeError(node)\roperator_type = type(node.op)\rif operator_type not in LEGAL_OPERATORS:\rraise TypeError(f\u0026#39;Illegal operator {node.op}\u0026#39;)\roperator = LEGAL_OPERATORS[operator_type]\rif node_type == BinOp:\rleft, right = eval_node(node.left), eval_node(node.right)\rreturn operator(left, right)\relif node_type == UnaryOp:\roperand = eval_node(node.operand)\rreturn operator(operand) \u0026gt;\u0026gt;\u0026gt; evaluate(\u0026#39;2 ^ 6\u0026#39;)\r4\r\u0026gt;\u0026gt;\u0026gt; evaluate(\u0026#39;2 ** 6\u0026#39;)\r64\r\u0026gt;\u0026gt;\u0026gt; evaluate(\u0026#39;1 + 2 * 3 ** (4 ^ 5) / (6 + -7)\u0026#39;)\r-5.0 Coroutine  Similar to generator, but generator pulls data through the pipe with iteration, while coroutine pushes data into the pipeline with send().\n Coroutines provide more powerful data routing possibilities than iterators.\n If you built a collection of simple data processing components, you can glue them together into complex arrangements of pipes, branches, merging, etc.\n  Helper Decorator  All coroutines must be \u0026ldquo;primed\u0026rdquo; by first calling next().\n Remembering to call next() is easy to forget.\n Solved by wrapping coroutines with a decorator:\n  def coroutine(func):\rdef out(*args, **kwargs):\rcr = func(*args, **kwargs)\rnext(cr)\rreturn cr\rreturn out Pipeline Example def reader(target):\rfor i in range(10):\rtarget.send(i)\rtarget.close()\r@coroutine\rdef adder(target):\rwhile True:\ritem = (yield)\rtarget.send(item + 100)\r@coroutine\rdef printer():\rwhile True:\ritem = (yield)\rprint(item)\rreader(adder(printer())) # 100, 101, ..., 109 \nLibraries Progress Bar # $ pip3 install tqdm\r from tqdm import tqdm\rfrom time import sleep\rfor i in tqdm([1, 2, 3]):\rsleep(0.2)\rfor i in tqdm(range(100)):\rsleep(0.02) Plot # $ pip3 install matplotlib\r from matplotlib import pyplot\rpyplot.plot(\u0026lt;data_1\u0026gt; [, \u0026lt;data_2\u0026gt;, ...])\rpyplot.savefig(\u0026lt;filename\u0026gt;, transparent=True)\rpyplot.show() Table Prints CSV file as ASCII table: # $ pip3 install tabulate\r from tabulate import tabulate\rimport csv\rwith open(\u0026lt;filename\u0026gt;, encoding=\u0026#39;utf-8\u0026#39;) as file:\rlines = csv.reader(file, delimiter=\u0026#39;;\u0026#39;)\rheaders = [header.title() for header in next(lines)]\rtable = tabulate(lines, headers)\rprint(table)\nCurses from curses import wrapper\rdef main():\rwrapper(draw)\rdef draw(screen):\rscreen.clear()\rscreen.addstr(0, 0, \u0026#39;Press ESC to quit.\u0026#39;)\rwhile screen.getch() != 27:\rpass\rdef get_border(screen):\rfrom collections import namedtuple\rP = namedtuple(\u0026#39;P\u0026#39;, \u0026#39;x y\u0026#39;)\rheight, width = screen.getmaxyx()\rreturn P(width-1, height-1) Scraping # $ pip3 install requests beautifulsoup4\r \u0026gt;\u0026gt;\u0026gt; import requests\r\u0026gt;\u0026gt;\u0026gt; from bs4 import BeautifulSoup\r\u0026gt;\u0026gt;\u0026gt; url = \u0026#39;https://en.wikipedia.org/wiki/Python_(programming_language)\u0026#39;\r\u0026gt;\u0026gt;\u0026gt; page = requests.get(url)\r\u0026gt;\u0026gt;\u0026gt; doc = BeautifulSoup(page.text, \u0026#39;html.parser\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; table = doc.find(\u0026#39;table\u0026#39;, class_=\u0026#39;infobox vevent\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; rows = table.find_all(\u0026#39;tr\u0026#39;)\r\u0026gt;\u0026gt;\u0026gt; link = rows[11].find(\u0026#39;a\u0026#39;)[\u0026#39;href\u0026#39;]\r\u0026gt;\u0026gt;\u0026gt; ver = rows[6].find(\u0026#39;div\u0026#39;).text.split()[0]\r\u0026gt;\u0026gt;\u0026gt; link, ver\r(\u0026#39;https://www.python.org/\u0026#39;, \u0026#39;3.7.2\u0026#39;) Web # $ pip3 install bottle\r from bottle import run, route, post, template, request, response\rimport json Run run(host=\u0026#39;localhost\u0026#39;, port=8080)\rrun(host=\u0026#39;0.0.0.0\u0026#39;, port=80, server=\u0026#39;cherrypy\u0026#39;) Static Request @route(\u0026#39;/img/\u0026lt;image\u0026gt;\u0026#39;)\rdef send_image(image):\rreturn static_file(image, \u0026#39;images/\u0026#39;, mimetype=\u0026#39;image/png\u0026#39;) Dynamic Request @route(\u0026#39;/\u0026lt;sport\u0026gt;\u0026#39;)\rdef send_page(sport):\rreturn template(\u0026#39;\u0026lt;h1\u0026gt;{{title}}\u0026lt;/h1\u0026gt;\u0026#39;, title=sport) REST Request @post(\u0026#39;/odds/\u0026lt;sport\u0026gt;\u0026#39;)\rdef odds_handler(sport):\rteam = request.forms.get(\u0026#39;team\u0026#39;)\rhome_odds, away_odds = 2.44, 3.29\rresponse.headers[\u0026#39;Content-Type\u0026#39;] = \u0026#39;application/json\u0026#39;\rresponse.headers[\u0026#39;Cache-Control\u0026#39;] = \u0026#39;no-cache\u0026#39;\rreturn json.dumps([team, home_odds, away_odds]) Test: # $ pip3 install requests\r \u0026gt;\u0026gt;\u0026gt; import requests\r\u0026gt;\u0026gt;\u0026gt; url = \u0026#39;http://localhost:8080/odds/football\u0026#39;\r\u0026gt;\u0026gt;\u0026gt; data = {\u0026#39;team\u0026#39;: \u0026#39;arsenal f.c.\u0026#39;}\r\u0026gt;\u0026gt;\u0026gt; response = requests.post(url, data=data)\r\u0026gt;\u0026gt;\u0026gt; response.json()\r[\u0026#39;arsenal f.c.\u0026#39;, 2.44, 3.29]\nProfile Basic from time import time\rstart_time = time() # Seconds since Epoch.\r ...\rduration = time() - start_time High Performance from time import perf_counter as pc\rstart_time = pc() # Seconds since restart.\r ...\rduration = pc() - start_time Timing a Snippet from timeit import timeit\rtimeit(\u0026#39;\u0026#34;-\u0026#34;.join(str(a) for a in range(100))\u0026#39;, number=10000, globals=globals(), setup=\u0026#39;pass\u0026#39;) Line Profiler # $ pip3 install line_profiler\r @profile\rdef main():\ra = [*range(10000)]\rb = {*range(10000)}\rmain() Usage: $ kernprof -lv test.py\rLine # Hits Time Per Hit % Time Line Contents\r==============================================================\r1 @profile\r2 def main():\r3 1 1128.0 1128.0 27.4 a = [*range(10000)]\r4 1 2994.0 2994.0 72.6 b = {*range(10000)}\nCall Graph Generates a PNG image of a call graph with highlighted bottlenecks:\n# $ pip3 install pycallgraph\r from pycallgraph import output, PyCallGraph\rfrom datetime import datetime\rtime_str = datetime.now().strftime(\u0026#39;%Y%m%d%H%M%S\u0026#39;)\rfilename = f\u0026#39;profile-{time_str}.png\u0026#39;\rdrawer = output.GraphvizOutput(output_file=filename)\rwith PyCallGraph(output=drawer):\r\u0026lt;code_to_be_profiled\u0026gt; NumPy Array manipulation mini language. Can run up to one hundred times faster than equivalent Python code.\n# $ pip3 install numpy\r import numpy as np \u0026lt;array\u0026gt; = np.array(\u0026lt;list\u0026gt;)\r\u0026lt;array\u0026gt; = np.arange(from_inclusive, to_exclusive, Â±step_size)\r\u0026lt;array\u0026gt; = np.ones(\u0026lt;shape\u0026gt;)\r\u0026lt;array\u0026gt; = np.random.randint(from_inclusive, to_exclusive, \u0026lt;shape\u0026gt;) \u0026lt;array\u0026gt;.shape = \u0026lt;shape\u0026gt;\r\u0026lt;view\u0026gt; = \u0026lt;array\u0026gt;.reshape(\u0026lt;shape\u0026gt;)\r\u0026lt;view\u0026gt; = np.broadcast_to(\u0026lt;array\u0026gt;, \u0026lt;shape\u0026gt;) \u0026lt;array\u0026gt; = \u0026lt;array\u0026gt;.sum(axis)\rindexes = \u0026lt;array\u0026gt;.argmin(axis)  Shape is a tuple of dimension sizes. Axis is an index of dimension that gets collapsed. Leftmost dimension has index 0.  Indexing \u0026lt;el\u0026gt; = \u0026lt;2d_array\u0026gt;[0, 0] # First element.\r\u0026lt;1d_view\u0026gt; = \u0026lt;2d_array\u0026gt;[0] # First row.\r\u0026lt;1d_view\u0026gt; = \u0026lt;2d_array\u0026gt;[:, 0] # First column. Also [..., 0].\r\u0026lt;3d_view\u0026gt; = \u0026lt;2d_array\u0026gt;[None, :, :] # Expanded by dimension of size 1. \u0026lt;1d_array\u0026gt; = \u0026lt;2d_array\u0026gt;[\u0026lt;1d_row_indexes\u0026gt;, \u0026lt;1d_column_indexes\u0026gt;]\r\u0026lt;2d_array\u0026gt; = \u0026lt;2d_array\u0026gt;[\u0026lt;2d_row_indexes\u0026gt;, \u0026lt;2d_column_indexes\u0026gt;] \u0026lt;2d_bools\u0026gt; = \u0026lt;2d_array\u0026gt; \u0026gt; 0\r\u0026lt;1d_array\u0026gt; = \u0026lt;2d_array\u0026gt;[\u0026lt;2d_bools\u0026gt;]  If row and column indexes differ in shape, they are combined with broadcasting.  Broadcasting Broadcasting is a set of rules by which NumPy functions operate on arrays of different sizes and/or dimensions.\nleft = [[0.1], [0.6], [0.8]] # Shape: (3, 1)\r right = [ 0.1 , 0.6 , 0.8 ] # Shape: (3) 1. If array shapes differ in length, left-pad the smaller shape with ones: left = [[0.1], [0.6], [0.8]] # Shape: (3, 1)\r right = [[0.1 , 0.6 , 0.8]] # Shape: (1, 3) \u0026lt;- !\n2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements: left = [[0.1, 0.1, 0.1], [0.6, 0.6, 0.6], [0.8, 0.8, 0.8]] # Shape: (3, 3) \u0026lt;- !\r right = [[0.1, 0.6, 0.8], [0.1, 0.6, 0.8], [0.1, 0.6, 0.8]] # Shape: (3, 3) \u0026lt;- !\n3. If neither non-matching dimension has size 1, rise an error.\nExample For each point returns index of its nearest point ([0.1, 0.6, 0.8] =\u0026gt; [1, 2, 1]):\n\u0026gt;\u0026gt;\u0026gt; points = np.array([0.1, 0.6, 0.8])\r[ 0.1, 0.6, 0.8]\r\u0026gt;\u0026gt;\u0026gt; wrapped_points = points.reshape(3, 1)\r[[ 0.1],\r[ 0.6],\r[ 0.8]]\r\u0026gt;\u0026gt;\u0026gt; distances = wrapped_points - points\r[[ 0. , -0.5, -0.7],\r[ 0.5, 0. , -0.2],\r[ 0.7, 0.2, 0. ]]\r\u0026gt;\u0026gt;\u0026gt; distances = np.abs(distances)\r[[ 0. , 0.5, 0.7],\r[ 0.5, 0. , 0.2],\r[ 0.7, 0.2, 0. ]]\r\u0026gt;\u0026gt;\u0026gt; i = np.arange(3)\r[0, 1, 2]\r\u0026gt;\u0026gt;\u0026gt; distances[i, i] = np.inf\r[[ inf, 0.5, 0.7],\r[ 0.5, inf, 0.2],\r[ 0.7, 0.2, inf]]\r\u0026gt;\u0026gt;\u0026gt; distances.argmin(1)\r[1, 2, 1] Image # $ pip3 install pillow\r from PIL import Image Creates PNG image of rainbow gradient: width = 100\rheight = 100\rsize = width * height\rpixels = [255 * i/size for i in range(size)]\rimg = Image.new(\u0026#39;HSV\u0026#39;, (width, height))\rimg.putdata([(int(a), 255, 255) for a in pixels])\rimg.convert(mode=\u0026#39;RGB\u0026#39;).save(\u0026#39;test.png\u0026#39;)\nAdds noise to a PNG image: from random import randint\radd_noise = lambda value: max(0, min(255, value + randint(-20, 20)))\rimg = Image.open(\u0026#39;test.png\u0026#39;).convert(mode=\u0026#39;HSV\u0026#39;)\rimg.putdata([(add_noise(h), s, v) for h, s, v in img.getdata()])\rimg.convert(mode=\u0026#39;RGB\u0026#39;).save(\u0026#39;test.png\u0026#39;)\nModes  '1' - 1-bit pixels, black and white, stored with one pixel per byte. 'L' - 8-bit pixels, greyscale. 'RGB' - 3x8-bit pixels, true color. 'RGBA' - 4x8-bit pixels, true color with transparency mask. 'HSV' - 3x8-bit pixels, Hue, Saturation, Value color space.  Audio import wave\rfrom struct import pack, iter_unpack Read Frames from WAV File def read_wav_file(filename):\rwith wave.open(filename, \u0026#39;rb\u0026#39;) as wf:\rframes = wf.readframes(wf.getnframes())\rreturn [a[0] for a in iter_unpack(\u0026#39;\u0026lt;h\u0026#39;, frames)] Write Frames to WAV File def write_to_wav_file(filename, frames_int, mono=True):\rframes_short = (pack(\u0026#39;\u0026lt;h\u0026#39;, a) for a in frames_int)\rwith wave.open(filename, \u0026#39;wb\u0026#39;) as wf:\rwf.setnchannels(1 if mono else 2)\rwf.setsampwidth(2)\rwf.setframerate(44100)\rwf.writeframes(b\u0026#39;\u0026#39;.join(frames_short)) Examples Saves a sine wave to a mono WAV file: from math import pi, sin\rframes_f = (sin(i * 2 * pi * 440 / 44100) for i in range(100000))\rframes_i = (int(a * 30000) for a in frames_f)\rwrite_to_wav_file(\u0026#39;test.wav\u0026#39;, frames_i)\nAdds noise to a mono WAV file: from random import randint\radd_noise = lambda value: max(-32768, min(32767, value + randint(-500, 500)))\rframes_i = (add_noise(a) for a in read_wav_file(\u0026#39;test.wav\u0026#39;))\rwrite_to_wav_file(\u0026#39;test.wav\u0026#39;, frames_i)\nPlays Popcorn: # $ pip3 install simpleaudio\r import simpleaudio, math, struct\rfrom itertools import chain, repeat\rF = 44100\rP1 = \u0026#39;71âª,69,,71âª,66,,62âª,66,,59âª,,,\u0026#39;\rP2 = \u0026#39;71âª,73,,74âª,73,,74,,71,,73âª,71,,73,,69,,71âª,69,,71,,67,,71âª,,,\u0026#39;\rget_pause = lambda seconds: repeat(0, int(seconds * F))\rsin_f = lambda i, hz: math.sin(i * 2 * math.pi * hz / F)\rget_wave = lambda hz, seconds: (sin_f(i, hz) for i in range(int(seconds * F)))\rget_hz = lambda key: 8.176 * 2 ** (int(key) / 12)\rparse_n = lambda note: (get_hz(note[:2]), 0.25 if \u0026#39;âª\u0026#39; in note else 0.125)\rget_note = lambda note: get_wave(*parse_n(note)) if note else get_pause(0.125)\rframes_i = chain.from_iterable(get_note(n) for n in f\u0026#39;{P1}{P1}{P2}\u0026#39;.split(\u0026#39;,\u0026#39;))\rframes_b = b\u0026#39;\u0026#39;.join(struct.pack(\u0026#39;\u0026lt;h\u0026#39;, int(a * 30000)) for a in frames_i)\rsimpleaudio.play_buffer(frames_b, 1, 2, F)\nBasic Script Template #!/usr/bin/env python3\r # Usage: .py\r from collections import namedtuple\rfrom enum import Enum\rimport re\rimport sys\rdef main():\rpass\r## UTIL\r def read_file(filename):\rwith open(filename, encoding=\u0026#39;utf-8\u0026#39;) as file:\rreturn file.readlines()\rif __name__ == \u0026#39;__main__\u0026#39;:\rmain() "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/book/2018-09-13_laws/",
	"title": "Laws",
	"tags": ["anekdote"],
	"description": "",
	"content": " Murphy\u0026rsquo;s Law Probably one of the most famous of all laws, mostly because it is not only applicable to Software Development.\nIf something can go wrong, it will.  First derivation: If it works, you probably didn\u0026rsquo;t write it. Second derivation: Cursing is the only language all programmers speak fluently. Conclusion: A computer will do what you write, not what you want.\nDefensive programming, version control, doom scenario\u0026rsquo;s (for those damned zombie-server-attacks), TDD, MDD, etc. are all are good practices for defending against this law.\nBrook\u0026rsquo;s Law Most developers will -either knowingly or unknowingly- have experience with Brook\u0026rsquo;s law, which states:\nAdding manpower to a late software project makes it later.  If a project is running late, simply adding manpower will most likely have disastrous results. Looking and reviewing the level of programming efficiency, the software methodology, the technical architecture, etc. will almost always have better outcomes. Or not, which probably means Hofstadter\u0026rsquo;s Law is also in play.\nHofstadter\u0026rsquo;s Law The Hofstadter\u0026rsquo;s law was written by Douglas Hofstadter and named after him.\nThe rule states:\nIt always takes longer than you expect, even when you take into account Hofstadter's Law.  The \u0026ldquo;law\u0026rdquo; is a statement regarding the difficulty of accurately estimating the time it will take to complete tasks of substantial complexity. The recursive nature of the law is a reflection of the widely experienced difficulty of estimating complex tasks despite all best efforts, including knowing that the task is complex.\nThat\u0026rsquo;s why you must always have a buffer before you give any sort of estimation. If you want to know more on how to provide better estimations, read my post on the subject: Estimation Wizardry.\nConwayâs Law Any piece of software reflects the organizational structure that produced it.  Or even more clearly:\nOrganizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.  In many organizations teams are divided according to their functional skills. So you\u0026rsquo;ll have teams of front-end developers, backend-developers and database developers. Simply stated, it\u0026rsquo;s hard for someone to change something if the thing he/she wants to change is owned by someone else.\nIt is much better, and more and more implemented as such, to deploy teams around a bounded context. Architectures such as microservices structure their teams around service boundaries rather than siloed technical architecture partitions.\nSo, structure teams to look like your target architecture, and it will be easier to achieve it. That\u0026rsquo;s how you defend against Conways\u0026rsquo;s law.\nPostel\u0026rsquo;s Law aka Robustness principle Be conservative in what you send, be liberal in what you accept  Jon Postel originally articulated this as a principle for making TCP implementations robust. This principle is also embodied by HTML which many attribute as a cause of its success and failure, depending on who you ask.\nIn today\u0026rsquo;s highly charged political environment, Postel\u0026rsquo;s law is a uniter.\nPareto Principle aka The 80-20 rule For many phenomena, 80% of consequences stem from 20% of the causes.  This is the principle behind the painful truth that 80% of the bugs in the code arise from 20% of the code. Otherwise stated, 80% of the work done in a company is performed by 20% of the staff. The problem is you don\u0026rsquo;t always have a clear idea of which 20%.\nThe Peter Principle A pretty depressing and at times frustrating law, certainly if you happen to have firsthand experience.\nIn a hierarchy, every employee tends to rise to his level of incompetence.  Kerchkhoff\u0026rsquo;s Principle In cryptography, a system should be secure even if everything about the system, except for a small piece of information - the key - is public knowledge.  This is the main principle underlying public key cryptography.\nLinus\u0026rsquo;s Law Named after Linus Torvalds, the creator of Linux, this law states:\nGiven enough eyeballs, all bugs are shallow.  This law was described using the famous The Cathedral and the Bazaar essay, explaining the contrast between two different free software development models:\nThe Cathedral model, in which source code is available with each software release, but code developed between releases is restricted to an exclusive group of software developers. The Bazaar model, in which the code is developed over the Internet in view of the public.  The conclusion? The more widely available the source code is for public testing, scrutiny, and experimentation, the more rapidly all forms of bugs will be discovered.\nMoore\u0026rsquo;s Law The power of computers per unit cost doubles every 24 month.  The most popular version states:\nThe number of transistors on an integrated circuit will double in about 18 months.  Or\nThe processing speed of computers will double every two years!  Wirth\u0026rsquo;s law Software gets slower faster than hardware gets faster.  Take that Moore\u0026rsquo;s Law!\nNinety-ninety rule The first 90% of the code takes 10% of the time. The remaining 10% takes the other 90% of the time  So true. Anyone who does not agree with this?\nKnuth\u0026rsquo;s optimization principle Premature optimization is the root of all evil.  First you write code, then you identify bottlenecks, then you fix!\nNorvig\u0026rsquo;s Law Any technology that surpasses 50% penetration will never double again (in any number of months).  source: https://www.timsommer.be/famous-laws-of-software-development/\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/post/2018-09-13_laws/",
	"title": "Laws",
	"tags": ["anekdote"],
	"description": "",
	"content": " Murphy\u0026rsquo;s Law Probably one of the most famous of all laws, mostly because it is not only applicable to Software Development.\nIf something can go wrong, it will.  First derivation: If it works, you probably didn\u0026rsquo;t write it. Second derivation: Cursing is the only language all programmers speak fluently. Conclusion: A computer will do what you write, not what you want.\nDefensive programming, version control, doom scenario\u0026rsquo;s (for those damned zombie-server-attacks), TDD, MDD, etc. are all are good practices for defending against this law.\nBrook\u0026rsquo;s Law Most developers will -either knowingly or unknowingly- have experience with Brook\u0026rsquo;s law, which states:\nAdding manpower to a late software project makes it later.  If a project is running late, simply adding manpower will most likely have disastrous results. Looking and reviewing the level of programming efficiency, the software methodology, the technical architecture, etc. will almost always have better outcomes. Or not, which probably means Hofstadter\u0026rsquo;s Law is also in play.\nHofstadter\u0026rsquo;s Law The Hofstadter\u0026rsquo;s law was written by Douglas Hofstadter and named after him.\nThe rule states:\nIt always takes longer than you expect, even when you take into account Hofstadter's Law.  The \u0026ldquo;law\u0026rdquo; is a statement regarding the difficulty of accurately estimating the time it will take to complete tasks of substantial complexity. The recursive nature of the law is a reflection of the widely experienced difficulty of estimating complex tasks despite all best efforts, including knowing that the task is complex.\nThat\u0026rsquo;s why you must always have a buffer before you give any sort of estimation. If you want to know more on how to provide better estimations, read my post on the subject: Estimation Wizardry.\nConwayâs Law Any piece of software reflects the organizational structure that produced it.  Or even more clearly:\nOrganizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.  In many organizations teams are divided according to their functional skills. So you\u0026rsquo;ll have teams of front-end developers, backend-developers and database developers. Simply stated, it\u0026rsquo;s hard for someone to change something if the thing he/she wants to change is owned by someone else.\nIt is much better, and more and more implemented as such, to deploy teams around a bounded context. Architectures such as microservices structure their teams around service boundaries rather than siloed technical architecture partitions.\nSo, structure teams to look like your target architecture, and it will be easier to achieve it. That\u0026rsquo;s how you defend against Conways\u0026rsquo;s law.\nPostel\u0026rsquo;s Law aka Robustness principle Be conservative in what you send, be liberal in what you accept  Jon Postel originally articulated this as a principle for making TCP implementations robust. This principle is also embodied by HTML which many attribute as a cause of its success and failure, depending on who you ask.\nIn today\u0026rsquo;s highly charged political environment, Postel\u0026rsquo;s law is a uniter.\nPareto Principle aka The 80-20 rule For many phenomena, 80% of consequences stem from 20% of the causes.  This is the principle behind the painful truth that 80% of the bugs in the code arise from 20% of the code. Otherwise stated, 80% of the work done in a company is performed by 20% of the staff. The problem is you don\u0026rsquo;t always have a clear idea of which 20%.\nThe Peter Principle A pretty depressing and at times frustrating law, certainly if you happen to have firsthand experience.\nIn a hierarchy, every employee tends to rise to his level of incompetence.  Kerchkhoff\u0026rsquo;s Principle In cryptography, a system should be secure even if everything about the system, except for a small piece of information - the key - is public knowledge.  This is the main principle underlying public key cryptography.\nLinus\u0026rsquo;s Law Named after Linus Torvalds, the creator of Linux, this law states:\nGiven enough eyeballs, all bugs are shallow.  This law was described using the famous The Cathedral and the Bazaar essay, explaining the contrast between two different free software development models:\nThe Cathedral model, in which source code is available with each software release, but code developed between releases is restricted to an exclusive group of software developers. The Bazaar model, in which the code is developed over the Internet in view of the public.  The conclusion? The more widely available the source code is for public testing, scrutiny, and experimentation, the more rapidly all forms of bugs will be discovered.\nMoore\u0026rsquo;s Law The power of computers per unit cost doubles every 24 month.  The most popular version states:\nThe number of transistors on an integrated circuit will double in about 18 months.  Or\nThe processing speed of computers will double every two years!  Wirth\u0026rsquo;s law Software gets slower faster than hardware gets faster.  Take that Moore\u0026rsquo;s Law!\nNinety-ninety rule The first 90% of the code takes 10% of the time. The remaining 10% takes the other 90% of the time  So true. Anyone who does not agree with this?\nKnuth\u0026rsquo;s optimization principle Premature optimization is the root of all evil.  First you write code, then you identify bottlenecks, then you fix!\nNorvig\u0026rsquo;s Law Any technology that surpasses 50% penetration will never double again (in any number of months).  source: https://www.timsommer.be/famous-laws-of-software-development/\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/power-bi/",
	"title": "Power BI",
	"tags": ["visualization"],
	"description": "",
	"content": " Columns vs Measures Calculated columns (and tables) are:\n Evaluated for each row in your table, immediately after you hit \u0026lsquo;Enter\u0026rsquo; to complete the formula Saved back into the model so take up space  Calculated Measures are:\n Evaluated when you use it in a visual, when the visual is rendered Not saved anywhere (well, actually there\u0026rsquo;s a cache in the report layer but it\u0026rsquo;s not part of the file when you hit Save)  Generally, measures are more useful, but the trade-offs are the performance hit (report runtime vs. pre-processed), storage space, and the type of expressions you can use. For example calculated columns are often used when you want to filter on the result rather than just as a calculated result.\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/sql-server/",
	"title": "SQL Server",
	"tags": ["visualization"],
	"description": "",
	"content": " Columnstore A columnstore index can provide a very high level of data compression, typically by 10 times, to significantly reduce your data warehouse storage cost. For analytics, a columnstore index offers an order of magnitude better performance than a btree index. Columnstore indexes are the preferred data storage format for data warehousing and analytics workloads. Starting with SQL Server 2016 (13.x), you can use columnstore indexes for real-time analytics on your operational workload.\nReasons why columnstore indexes are so fast  Columns store values from the same domain and commonly have similar values, which result in high compression rates. I/O bottlenecks in your system are minimized or eliminated, and memory footprint is reduced significantly. High compression rates improve query performance by using a smaller in-memory footprint. In turn, query performance can improve because SQL Server can perform more query and data operations in memory. Batch execution improves query performance, typically by two to four times, by processing multiple rows together. Queries often select only a few columns from a table, which reduces total I/O from the physical media.  Recommended use cases:  Use a clustered columnstore index to store fact tables and large dimension tables for data warehousing workloads. This method improves query performance and data compression by up to 10 times. Use a nonclustered columnstore index to perform analysis in real time on an OLTP workload.  Terminology  Columnstore  A columnstore is data that\u0026rsquo;s logically organized as a table with rows and columns, and physically stored in a column-wise data format.  Rowstore  A rowstore is data that\u0026rsquo;s logically organized as a table with rows and columns, and physically stored in a row-wise data format. This format is the traditional way to store relational table data. In SQL Server, rowstore refers to a table where the underlying data storage format is a heap, a clustered index, or a memory-optimized table.  source: https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-2017\nClustered vs Non-Clustered Index There are two types of Indexes in SQL Server:\n Clustered Index Non-Clustered Index  Clustered Index A clustered index defines the order in which data is physically stored in a table. Table data can be sorted in only way, therefore, there can be only one clustered index per table. In SQL Server, the primary key constraint automatically creates a clustered index on that particular column.\nNon-Clustered Indexes A non-clustered index doesnât sort the physical data inside the table. In fact, a non-clustered index is stored at one place and table data is stored in another place. This is similar to a textbook where the book content is located in one place and the index is located in another. This allows for more than one non-clustered index per table.\nDifferences  There can be only one clustered index per table. However, you can create multiple non-clustered indexes on a single table. Clustered indexes only sort tables. Therefore, they do not consume extra storage. Non-clustered indexes are stored in a separate place from the actual table claiming more storage space. Clustered indexes are faster than non-clustered indexes since they donât involve any extra lookup step.  Source: https://www.sqlshack.com/what-is-the-difference-between-clustered-and-non-clustered-indexes-in-sql-server/\nActual Execution Plan Figure 3: Organization of teams driven by business capabilities\nFigure 3: Organization of teams driven by business capabilities\nAdd user to Managed Instance create user DataScienceCore from external provider "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/microsoft-big-data-overview/",
	"title": "Microsoft Big Data Overview",
	"tags": ["devops"],
	"description": "",
	"content": " https://academy.microsoft.com/en-us/professional-program/tracks/big-data/\nBlock 1 â Data Fundamentals Learn data science basics. Explore topics like data queries, data analysis, data visualization and how statistics informs data science practices. Please choose from Course 2a or Course 2b to complete the unit.\n Course 1: Microsoft Professional Program: Introduction to Big Data Course 2a: Analyzing and Visualizing Data with Power BI Course 2b: Analyzing and Visualizing Data with Excel Course 3: Introduction to NoSQL Data Solutions Course 4: Querying Data with Transact-SQL  Unit 2 â Big Data Processing In this unit, you will learn how to use Azure services and open source technologies to implement batch processing and real-time processing of big data. Please choose a path focused on Azure or Hadoop in Azure HDInsight and take Course 6a and 7a or Course 6b and 7b to complete the unit.\n Course 5: Delivering a Data Warehouse in the Cloud Course 6a: Processing Big Data with Azure Data Lake Analytics Course 6b: Processing Big Data with Hadoop in Azure HDInsight\n Course 7a: Processing Real-Time Data Streams in Azure Course 7b: Implementing Real-Time Analytics with Hadoop in Azure HDInsight  Unit 3 â Big Data Analysis Solutions In this unit you will learn how to build workflow solutions that automate regular data processing and movement tasks, and apply predictive analytics to big data. Please continue with the programming language you selected in Unit 2. Select Course 9a, Course 9b, or Course 9c to complete the unit.\n Course 8: Orchestrating Big Data with Azure Data Factory Course 9a: Developing Big Data Solutions with Azure Machine Learning Course 9b: Analyzing Big Data with Microsoft R Course 9c: Implementing Predictive Analytics with Spark in Azure HDInsight  Unit 4 - Capstone Project In this final capstone project, you will apply everything you have learned to take on a big data processing challenge.\n Course 10: Microsoft Professional Capstone : Big Data  "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/docker-basics/",
	"title": "Docker Basics",
	"tags": ["docker"],
	"description": "",
	"content": " Docker is a tool which helps developers build and ship high quality applications, faster, anywhere. Source\nWhy Docker With Docker, developers can build any app in any language using any toolchain. Dockerized apps are completely portable and can run anywhere.\nDevelopers can get going by just spinning any container out of list on Docker Hub. Docker manages and tracks changes and dependencies, making it easier for sysadmins to understand how the apps that developers build work. And with Docker Hub, developers can automate their build pipeline and share artifacts with collaborators through public or private repositories.\nIf you are a complete Docker newbie, you should probably follow the series of tutorials now.\nFirst command after installation\ndocker run hello-world  That\u0026rsquo;s it, you have a running Docker container.\nIf you are a complete Docker newbie, you should probably follow the series of tutorials now.\nContainers Docker implements a high-level API to provide lightweight containers that run processes in isolation.\nLifecycle  docker create creates a container but does not start it. docker rename allows the container to be renamed. docker run creates and starts a container in one operation. docker rm deletes a container. docker update updates a container\u0026rsquo;s resource limits.  Normally if you run a container without options it will start and stop immediately, if you want keep it running you can use the command, docker run -td container_id this will use the option -t that will allocate a pseudo-TTY session and -d that will detach automatically the container (run container in background and print container ID)\nIf you want a transient container, docker run --rm will remove the container after it stops.\nAnother useful option is docker run --name customname docker_image because when you specify the --name inside the run command this will allow you to start and stop a container by calling it with the name the you specified when you created it.\nStarting and Stopping  docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \u0026ldquo;freezing\u0026rdquo; it in place. docker unpause will unpause a running container. docker wait blocks until running container stops. docker kill sends a SIGKILL to a running container. docker attach will connect to a running container.  If you want to integrate a container with a host process manager, start the daemon with -r=false then use docker start -a.\nIf you want to expose container ports through the host, see the exposing ports section.\nRestart policies on crashed docker instances are covered here.\nInfo  docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10). docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers\u0026rsquo; resource usage statistics. docker diff shows changed files in the container\u0026rsquo;s FS.  docker ps -a shows running and stopped containers.\ndocker stats --all shows a running list of containers.\nImport/Export\n docker cp copies files or folders between a container and the local filesystem. docker export turns container filesystem into tarball archive stream to STDOUT.  Executing Commands  docker exec to execute a command in container.  To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash.\nImages Images are just templates for docker containers.\nLifecycle  docker images shows all images. docker import creates an image from a tarball. docker build creates image from Dockerfile. docker commit creates image from a container, pausing it temporarily if it is running. docker rmi removes an image. docker load loads an image from a tar archive as STDIN, including images and tags (as of 0.7). docker save saves an image to a tar archive stream to STDOUT with all parent layers, tags \u0026amp; versions (as of 0.7).  Info  docker history shows history of image. docker tag tags an image to a name (local or registry).  Cleaning up While you can use the docker rmi command to remove specific images, there\u0026rsquo;s a tool called docker-gc that will clean up images that are no longer used by any containers in a safe manner.\nLoad/Save image\nLoad an image from file:\ndocker load \u0026lt; my_image.tar.gz  Save an existing image:\ndocker save my_image:my_tag | gzip \u0026gt; my_image.tar.gz  Import/Export container\nImport a container as an image from file:\ncat my_container.tar.gz | docker import - my_image:my_tag  Export an existing container:\ndocker export my_container | gzip \u0026gt; my_container.tar.gz  Difference between loading a saved image and importing an exported container as an image\nLoading an image using the load command creates a new image including its history.\nImporting a container as an image using the import command creates a new image excluding the history which results in a smaller image size compared to loading an image.\nNetworks Docker has a networks to configure docker containers to talk to each other without using ports. See working with networks for more details.\nLifecycle\n docker network create docker network rm  Info\n docker network ls docker network inspect  Connection\n docker network connect docker network disconnect  You can specify a specific IP address for a container:\n# create a new bridge network with your subnet and gateway for your ip block docker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic # run a nginx container with a specific ip in that block $ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx # curl the ip from any other place (assuming this is a public ip block duh) $ curl 203.0.113.2  Registry \u0026amp; Repository A repository is a hosted collection of tagged images that together create the file system for a container.\nA registry is a host \u0026ndash; a server that stores repositories and provides an HTTP API for managing the uploading and downloading of repositories.\nDocker.com hosts its own index to a central registry which contains a large number of repositories. Having said that, the central docker registry does not do a good job of verifying images and should be avoided if you\u0026rsquo;re worried about security.\n docker login to login to a registry. docker logout to logout from a registry. docker search searches registry for image. docker pull pulls an image from registry to local machine. docker push pushes an image to the registry from local machine.  Run local registry\nYou can run a local registry by using the docker distribution project and looking at the local deploy instructions.\nAlso see the mailing list.\nDockerfile The configuration file. Sets up a Docker container when you run docker build on it. Vastly preferable to docker commit.\nHere are some common text editors and their syntax highlighting modules you could use to create Dockerfiles: * If you use jEdit, I\u0026rsquo;ve put up a syntax highlighting module for Dockerfile you can use. * Sublime Text 2 * Atom * Vim * Emacs * TextMate * VS Code * Also see Docker meets the IDE\nInstructions\n .dockerignore FROM Sets the Base Image for subsequent instructions. MAINTAINER (deprecated - use LABEL instead) Set the Author field of the generated images. RUN execute any commands in a new layer on top of the current image and commit the results. CMD provide defaults for an executing container. EXPOSE informs Docker that the container listens on the specified network ports at runtime. NOTE: does not actually make ports accessible. ENV sets environment variable. ADD copies new files, directories or remote file to container. Invalidates caches. Avoid ADD and use COPY instead. COPY copies new files or directories to container. Note that this only copies as root, so you have to chown manually regardless of your USER / WORKDIR setting. See https://github.com/moby/moby/issues/30110 ENTRYPOINT configures a container that will run as an executable. VOLUME creates a mount point for externally mounted volumes or other containers. USER sets the user name for following RUN / CMD / ENTRYPOINT commands. WORKDIR sets the working directory. ARG defines a build-time variable. ONBUILD adds a trigger instruction when the image is used as the base for another build. STOPSIGNAL sets the system call signal that will be sent to the container to exit. LABEL apply key/value metadata to your images, containers, or daemons.  Examples\n Examples Best practices for writing Dockerfiles Michael Crosby has some more Dockerfiles best practices / take 2. Building Good Docker Images / Building Better Docker Images Managing Container Configuration with Metadata  Layers The versioned filesystem in Docker is based on layers. They\u0026rsquo;re like git commits or changesets for filesystems.\nVolumes Docker volumes are free-floating filesystems. They don\u0026rsquo;t have to be connected to a particular container. You should use volumes mounted from data-only containers for portability.\nLifecycle\n docker volume create docker volume rm  Info\n docker volume ls docker volume inspect  Volumes are useful in situations where you can\u0026rsquo;t use links (which are TCP/IP only). For instance, if you need to have two docker instances communicate by leaving stuff on the filesystem.\nYou can mount them in several docker containers at once, using docker run --volumes-from.\nBecause volumes are isolated filesystems, they are often used to store state from computations between transient containers. That is, you can have a stateless and transient container run from a recipe, blow it away, and then have a second instance of the transient container pick up from where the last one left off.\nSee advanced volumes for more details. Container42 is also helpful.\nYou can map MacOS host directories as docker volumes:\ndocker run -v /Users/wsargent/myapp/src:/src  You can use remote NFS volumes if you\u0026rsquo;re feeling brave.\nYou may also consider running data-only containers as described here to provide some data portability.\nLinks\nLinks are how Docker containers talk to each other through TCP/IP ports. Linking into Redis and Atlassian show worked examples. You can also resolve links by hostname.\nThis has been deprected to some extent by user-defined networks.\nNOTE: If you want containers to ONLY communicate with each other through links, start the docker daemon with -icc=false to disable inter process communication.\nIf you have a container with the name CONTAINER (specified by docker run --name CONTAINER) and in the Dockerfile, it has an exposed port:\nEXPOSE 1337  Then if we create another container called LINKED like so:\ndocker run -d --link CONTAINER:ALIAS --name LINKED user/wordpress  Then the exposed ports and aliases of CONTAINER will show up in LINKED with the following environment variables:\n$ALIAS_PORT_1337_TCP_PORT $ALIAS_PORT_1337_TCP_ADDR  And you can connect to it that way.\nTo delete links, use docker rm --link.\nGenerally, linking between docker services is a subset of \u0026ldquo;service discovery\u0026rdquo;, a big problem if you\u0026rsquo;re planning to use Docker at scale in production. Please read The Docker Ecosystem: Service Discovery and Distributed Configuration Stores for more info.\nExposing ports Exposing incoming ports through the host container is fiddly but doable.\nThis is done by mapping the container port to the host port (only using localhost interface) using -p:\ndocker run -p 127.0.0.1:$HOSTPORT:$CONTAINERPORT --name CONTAINER -t someimage  You can tell Docker that the container listens on the specified network ports at runtime by using EXPOSE:\nEXPOSE \u0026lt;CONTAINERPORT\u0026gt;  Note that EXPOSE does not expose the port itself \u0026ndash; only -p will do that. To expose the container\u0026rsquo;s port on your localhost\u0026rsquo;s port:\niptables -t nat -A DOCKER -p tcp --dport \u0026lt;LOCALHOSTPORT\u0026gt; -j DNAT --to-destination \u0026lt;CONTAINERIP\u0026gt;:\u0026lt;PORT\u0026gt;  If you\u0026rsquo;re running Docker in Virtualbox, you then need to forward the port there as well, using forwarded_port. Define a range of ports in your Vagrantfile like this so you can dynamically map them:\nVagrant.configure(VAGRANTFILE_API_VERSION) do |config| ... (49000..49900).each do |port| config.vm.network :forwarded_port, :host =\u0026gt; port, :guest =\u0026gt; port end ... end  If you forget what you mapped the port to on the host container, use docker port to show it:\ndocker port CONTAINER $CONTAINERPORT  Best Practices This is where general Docker best practices and war stories go:\n The Rabbit Hole of Using Docker in Automated Tests Bridget Kromhout has a useful blog post on running Docker in production at Dramafever. There\u0026rsquo;s also a best practices blog post from Lyst. A Docker Dev Environment in 24 Hours! Building a Development Environment With Docker Discourse in a Docker Container  Security This is where security tips about Docker go. The Docker security page goes into more detail.\nFirst things first: Docker runs as root. If you are in the docker group, you effectively have root access. If you expose the docker unix socket to a container, you are giving the container root access to the host.\nDocker should not be your only defense. You should secure and harden it.\nFor an understanding of what containers leave exposed, you should read is Understanding and Hardening Linux Containers by Aaron Grattafiori. This is a complete and comprehensive guide to the issues involved with containers, with a plethora of links and footnotes leading on to yet more useful content. The security tips following are useful if you\u0026rsquo;ve already hardened containers in the past, but are not a substitute for understanding.\nSecurity Tips\nFor greatest security, you want to run Docker inside a virtual machine. This is straight from the Docker Security Team Lead \u0026ndash; slides / notes. Then, run with AppArmor / seccomp / SELinux / grsec etc to limit the container permissions. See the Docker 1.10 security features for more details.\nDocker image ids are sensitive information and should not be exposed to the outside world. Treat them like passwords.\nSee the Docker Security Cheat Sheet by Thomas SjÃ¶gren: some good stuff about container hardening in there.\nince docker 1.11 you can easily limit the number of active processes running inside a container to prevent fork bombs. This requires a linux kernel \u0026gt;= 4.3 with CGROUP_PIDS=y to be in the kernel configuration.\ndocker run --pids-limit=64  Also available since docker 1.11 is the ability to prevent processes from gaining new privileges. This feature have been in the linux kernel since version 3.5. You can read more about it in this blog post.\ndocker run --security-opt=no-new-privileges  From the Docker Security Cheat Sheet (it\u0026rsquo;s in PDF which makes it hard to use, so copying below) by Container Solutions:\nTurn off interprocess communication with:\ndocker -d --icc=false --iptables  Set the container to be read-only:\ndocker run --read-only  Verify images with a hashsum:\ndocker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be  Set volumes to be read only:\ndocker run -v $(pwd)/secrets:/secrets:ro debian  Tips\n 15 Docker Tips in 5 minutes CodeFresh Everyday Hacks Docker  "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/docker-basics/",
	"title": "Ribbons",
	"tags": ["docker"],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/airbnb-knowledge-repo/",
	"title": "Airbnb Knowledge Repo",
	"tags": ["web development"],
	"description": "Some webdev stuff",
	"content": " The Knowledge Repo project is focused on facilitating the sharing of knowledge between data scientists and other technical roles using data formats and tools that make sense in these professions. It provides various data stores (and utilities to manage them) for \u0026ldquo;knowledge posts\u0026rdquo;, with a particular focus on notebooks (R Markdown and Jupyter / IPython Notebook) to better promote reproducible research.\n Source https://github.com/airbnb/knowledge-repo Tutorial: https://github.com/airbnb/knowledge-repo/issues/401  Activation  Docker-compose-relevante Dateien in einen entsprechend autorisierten Zielfolder kopieren, in dem docker-compose-Befehle (vor allem âbuildâ/âupâ/âdownâ) auszufÃ¼hren sind. Im Terminal zum Zielfolder navigieren, per docker-compose build Anwendung vorbereiten. Es wird ein git-Repository heruntergeladen (âgit cloneâ) und entsprechende Folder erzeugt. Im Terminal zum Zielfolder navigieren, per docker-compose up Anwendung starten. Anwendung im Webbrowser ansehen. (siehe SERVER_NAME in der Datei config_defaults.py SCHLIESSEN: STRG + C terminiert den Thread, hinterlÃ¤sst dabei kritische Informationen im Docker-Compose-System. Erst mit docker-compose down werden alle Informationen gelÃ¶scht und ein sauberer Neustart (docker-compose up) mÃ¶glich.  Knowledge repo in docker All of the below files should be placed in your root directory, starting the local server can be done through the commands aliased in the Makefile:\nmake run  Note: I was unable to get the deploy configuration running on my containers, especially with Auth/Logins enabled - if anyone has any success with this then please let me know!\nDockerfile FROM python:3\rCOPY . /app\rWORKDIR /app\rRUN pip install knowledge-repo[all]\rRUN pip install --upgrade requests psycopg2 requests_oauthlib flask_login flask_principal\rCMD bash /app/start.sh  start.sh This clones your git post store (delete if necessary) and starts the server based on the RUNTIME_CONTEXT environment variable passed in docker-compose.\n#!/usr/bin/env bash\r\recho\recho \u0026#34;Setting up server\u0026#34;\recho \u0026#34;--------\u0026#34;\recho\r# Exit script if any command returns a non-zero status\rset -e\rif [ ! -d \u0026#34;/app/\u0026lt;GITHUB-POST-REPO\u0026gt;\u0026#34; ]; then\recho \u0026#34;Cloning research repo \u0026#34;\rcd /app/\rif [ -z \u0026#34;$(ls -A \u0026lt;GITHUB-POST-REPO\u0026gt;)\u0026#34; ]; then\recho \u0026#34;clone here\u0026#34;\r#\tThis will need to be the PAT for the knowledge repo github account\r\tgit clone https://${GITHUB_PAT}@github.com/\u0026lt;ORG\u0026gt;/\u0026lt;GITHUB-POST-REPO\u0026gt;.git\rfi\rfi\recho Runtime context ${RUNTIME_CONTEXT}\recho\rcd /app/\rif [ \u0026#34;${RUNTIME_CONTEXT}\u0026#34; == \u0026#34;local\u0026#34; ]; then\recho Starting local server\recho ---\rpython scripts/knowledge_repo --repo ./\u0026lt;GITHUB-POST-REPO\u0026gt; --debug runserver --config ./server_config.py --port ${PORT}\relse\recho Starting remote server\recho ---\rpython scripts/knowledge_repo --repo ./\u0026lt;GITHUB-POST-REPO\u0026gt; runserver --config ./server_config.py --port ${PORT}\rfi docker-compose.yml This defines environment variables for your application e.g. github personal access token (PAT), sets what ports are mounted from your container externally and mounts the your app data volume into your container so any code changes can be immediately reflected with no rebuilds.\n*This file should be added to your gitignore for deployment\nversion: \u0026#39;3\u0026#39;\rservices:\rapp:\rbuild:\rargs:\r#This can be deleted for non-git backed repositories, it should be the PAT for your post-store account\r - GITHUB_PAT=${GITHUB_PAT}\rcontext: .\rports:\r- 80:80\rnetworks:\r- default\rvolumes:\r- .:/app\renvironment:\r# Fill in any Knowledge repo env variables here\r - PORT=80\r- SERVER_NAME=localhost\r- RUNTIME_CONTEXT=local  Makefile This aliases docker compose commands so you don\u0026rsquo;t have to remember them.\nbuild:\rdocker-compose build\rshell:\rdocker-compose run --rm app bash\rclean:\rdocker system prune -f\rdocker-compose stop\rdocker rmi knowledgerepo_app\rrun:\rdocker-compose up  "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/hugo_netlify/",
	"title": "Blogging with hugo netlify",
	"tags": ["web development"],
	"description": "Creating a personal blog with hugo netlify",
	"content": " Here is a great tutorial on how to host hugo on netlify\nOther examples using the exact same theme:\n Tomas Westlake: https://r-mageddon.netlify.com/ Sascha Wolfer: https://rcrastinate.rbind.io/  Creating the hugo site In order to create a new hugo site simply go:\nhugo new site [path] [flags] Create a new repository via git Init the git repo and push it to the guthub repo:\necho \u0026#34;# website2\u0026#34; \u0026gt;\u0026gt; README.md\rgit init\rgit add README.md\rgit commit -m \u0026#34;first commit\u0026#34;\rgit remote add origin https://github.com/thomaslaber/website2.git\rgit push -u origin master\r# Push an existing repository from the command line\r# Alternatively you could link it to an already existing git repo: \rgit remote add origin https://github.com/thomaslaber/website2.git\rgit push -u origin master Theme as git submodule This is the theme I decided to go for Mainroad. Now you could add a theme of your choice git simply cloning it. However, it is more elegant to add it as a submodule.\n Submodules allow you to include or embed one or more repositories as a sub-folder inside another repository.\n git submodule add https://github.com/vimux/mainroad themes/mainroad\rgit submodule init\rgit submodule update\r# This means it can be updated by running:\r\rgit submodule update --remote themes/mainroad Adapting the theme Now we simply copy the config.toml in order to immediately have a running config for the theme.\ncp themes/mainroad/exampleSite/config.toml . We also could copy the examplesite folder from the theme folder in order to have some sample content to display. However, for now we refrain from doing that. We start the hugo server by:\nhugo server -D Add custom CSS We do not want to change anything in the theme folder as it will be updated and thus overwritten at some point of time. Therefore, we have to persist all our changes in the\nInside the config file we assign the path to an css file which can be found in static/css:\n[params]\r custom_css = [\u0026#34;css/tl.css\u0026#34;] You can reference as many stylesheets as you want. Their paths need to be relative to the static folder. Inside the header partial you can include every custom stylesheet from above beside the original one:\n{{ range .Site.Params.custom_css -}}\r\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ . | absURL }}\u0026#34;\u0026gt;\r{{- end }} Changing colors Unfortunately, the mainroad theme does not come with a built-in color-theme-support. Therefore, we have to replace color codes manually: I chose to go from \u0026block;\u0026block;\u0026block; #e64946 \u0026block;\u0026block;\u0026block; to \u0026block;\u0026block;\u0026block; #191970 \u0026block;\u0026block;\u0026block;. This can easily be done by runnnig a search and replace in the style.css after it was copied to the static/css folder.\n Remember: No changes in the theme folder!\n Adding Particles background In order to set a simple but important optical highlight, I decided to include the particle.js. This is done by adding the scripts in the static/js folder.\n\u0026lt;div id=\u0026#34;particles-js\u0026#34;\u0026gt;\t\u0026lt;/div\u0026gt;\r\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script src=\u0026#34;{{ .Site.BaseURL }}js/particles.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;  #particles-js {\r/* position: absolute; */\rheight: 100px;\rbackground-image: linear-gradient(to bottom right, black, navy,#aaa);\r} Main menu A big upset was the possibility to add new menu items: It only works\n\u0026lt;li class=\u0026#34;menu__item\u0026#34;\u0026gt;\r\u0026lt;a class=\u0026#34;menu__link\u0026#34; href=\u0026#34;/categories/book/\u0026#34;\u0026gt;Books\u0026lt;/a\u0026gt;\r\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026#34;menu__item\u0026#34;\u0026gt;\r\u0026lt;a class=\u0026#34;menu__link\u0026#34; href=\u0026#34;/categories/project/\u0026#34;\u0026gt;Projects\u0026lt;/a\u0026gt;\r\u0026lt;/li\u0026gt; Adding highlight.js We are adding a few options to our config file (config.toml):\nhighlight = true\rhighlightStyle = \u0026#34;monokai-sublime\u0026#34;\rhighlightLanguages = [\u0026#34;r\u0026#34;, \u0026#34;sql\u0026#34;, \u0026#34;bash\u0026#34;, \u0026#34;css\u0026#34;] Using these parameter we are loading them in the \u0026lt;head\u0026gt; (baseof.html):\n{{ if .Site.Params.highlight | default false }}\r\u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r{{ range .Site.Params.highlightLanguages }} \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/{{ . }}.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {{ end }}\r\u0026lt;script\u0026gt;hljs.initHighlightingOnLoad();\u0026lt;/script\u0026gt;\r{{ end }} Adding a custom search function Following a tutorial we again start by adding some parameters to the config.toml configuration file.\n[outputs]\rhome = [ \u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;JSON\u0026#34;] Note: Make shure to locate the required index.json file in the layouts folder. Once the file exists, hugo is going to dump the index to file.It should look like:\n[{{ range $index, $page := .Site.Pages }}\r{{- if ne $page.Type \u0026#34;json\u0026#34; -}}\r{{- if and $index (gt $index 0) -}},{{- end }}\r{\r\u0026#34;uri\u0026#34;: \u0026#34;{{ $page.Permalink }}\u0026#34;,\r\u0026#34;title\u0026#34;: \u0026#34;{{ htmlEscape $page.Title}}\u0026#34;,\r\u0026#34;tags\u0026#34;: [{{ range $tindex, $tag := $page.Params.tags }}{{ if $tindex }}, {{ end }}\u0026#34;{{ $tag| htmlEscape }}\u0026#34;{{ end }}],\r\u0026#34;description\u0026#34;: \u0026#34;{{ htmlEscape .Description}}\u0026#34;,\r\u0026#34;content\u0026#34;: {{$page.Plain | jsonify}}\r}\r{{- end -}}\r{{- end -}}] Once this is done, hugo generates a lunrjs index.json at the root of your public folder. If you encounter some problems run: hugo --verbose and check messages and warnings.\nWe add another css file css/auto-complete.css to our \u0026lt;head\u0026gt;.\nFinally, we need to load lunr. Please note: as lunr.js is based on jquery, make sure jquery.js gets loaded first.\n\u0026lt;body\u0026gt;\r...\r\u0026lt;!-- custom search --\u0026gt;\r{{ if not .Site.Params.disableSearch }}\r\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;{{ .Site.BaseURL }}js/lunr.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;{{ .Site.BaseURL }}js/auto-complete.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt;\rvar baseurl = \u0026#34;{{ .Site.BaseURL }}\u0026#34;;\r\u0026lt;/script\u0026gt;\r\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;{{ .Site.BaseURL }}js/search.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r{{ end }}\r...\r\u0026lt;/body\u0026gt; and finally, we add a search entry box somewhere in your webpage layout:\n{{ if not .Site.Params.disableSearch }}\r\u0026lt;li class=\u0026#34;dropdown\u0026#34;\u0026gt;\r\u0026lt;a\u0026gt;\r\u0026lt;i class=\u0026#34;fa fa-search\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;\r\u0026lt;div class=\u0026#34;searchbox pull-right\u0026#34;\u0026gt;\r\u0026lt;input data-search-input id=\u0026#34;search-by\u0026#34; type=\u0026#34;text\u0026#34;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/a\u0026gt;\r\u0026lt;/li\u0026gt;\r{{ end }} Finally, we delete Ã in ÃÂ» in search.js at line 80.\nCustom sidebar I pushed the table of content in the sidebar and made it sticky using stickyjs.com.\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/coding-the-matrix/",
	"title": "Coding the Matrix",
	"tags": [""],
	"description": "",
	"content": " How to test the solutions\npython3 submit.py python_lab.py Lab 1: Introduction to Pythonâsets, lists, dictionaries, and comprehensions Python provides some simple data structures for grouping together multiple values, and integrates them with the rest of the language. These data structures are called collections.\nSets A set is an unordered collection in which each value occurs at most once. You can use curly braces to give an expression whose value is a set. Python prints sets using curly braces.\n\u0026gt;\u0026gt;\u0026gt; {2, 1, 3}\r{1, 2, 3} Set comprehensions Python provides for expressions called comprehensions that let you build collections out of other collections. We will be using comprehensions a lot because they are useful in constructing an expression whose value is a collection, and they mimic traditional mathematical notation. Hereâs an example:\n\u0026gt;\u0026gt;\u0026gt; {2*x for x in {1,2,3} }\r{2, 4, 6} Lists Python represents sequences of values using lists. In a list, order is significant and repeated elements are allowed. The notation for lists uses square brackets instead of curly braces. The empy list is represented by []. \u0026gt;\u0026gt;\u0026gt; [1,1+1,3,2,3]\r[1, 2, 3, 2, 3]\nSlices Slices: A slice of a list is a new list consisting of a consecutive subsequence of elements of the old list, namely those indexed by a range of integers. The range is specified by a colon-separated pair i : j consisting of the index i as the first element and j as one past the index of the last element. Thus mylist[1:3] is the list consisting of elements 1 and 2 of mylist.\nPrefixes: If the first element i of the pair is 0, it can be omitted, so mylist[:2] consists of the first 2 elements of mylist. This notation is useful for obtaining a prefix of a list.\nSuffixes: If the second element j of the pair is the length of the list, it can be omitted, so mylist[1:] consists of all elements of mylist except element 0.\nSlices that skip:You can use a colon-separated triple a:b:c if you want the slice to include every cth element. For example, here is how you can extract from L the list consisting of even-indexed elements and the list consisting of odd-indexed elements:\nTuples Like a list, a tuple is an ordered sequence of elements. However, tuples are immutable so they can be elements of sets. The notation for tuples is the same as that for lists except that ordinary parentheses are used instead of square brackets.\nZip Another collection that can be iterated over is a zip. A zip is constructed from other collections all of the same length. Each element of the zip is a tuple consisting of one element from each of the input collections. \u0026gt;\u0026gt;\u0026gt; list(zip([1,3,5],[2,4,6]))\r[(1, 2), (3, 4), (5, 6)]\nDictionaries We will often have occasion to use functions with finite domains. Python provides collections, called dic- tionaries, that are suitable for representing such functions. Conceptually, a dictionary is a set of key-value pairs. The syntax for specifying a dictionary in terms of its key-value pairs therefore resembles the syntax for setsâit uses curly bracesâexcept that instead of listing the elements of the set, one lists the key-value pairs. In this syntax, each key-value pair is written using colon notation: an expression for the key, followed by the colon, followed by an expression for the value:\n$$key : value$$\nThe identity function on a set D is the function with the following spec: - input: an element x of D - output: x That is, the identity function simply outputs its input.\nIF â¨expressionâ© if â¨conditionâ© else â¨expressionâ© Source orga.cat/posts/most-useful-git-commands\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/grpc-package/",
	"title": "How to install Fultz&#39; grpc package",
	"tags": ["grpc"],
	"description": "",
	"content": " Instructions Link to instructions\ngit clone https://github.com/grpc/grpc.git grpc.git\rcd grpc.git/\r# git checkout tags/release-0_11_1 # does not exist Now we have to initialize the submodules and this is where it becomes tricky:\ngit submodule update --init\rcd third_party/protobuf/\r./autogen.sh  Google changed some of its internal structures and now gmock is part of google test. Anyways, the URL in the autpgen.sh is not working anymore. There we need to manually extract gmock into protobuf:\ngmock.zip\nThere is another change in the\n./configure\rmake -j8\rsudo make install # sudo ldconfig # this command does not exist on a mac, so we simply skip it. Otherwise it would update all dependencies.\rcd - # brings us back to the root folder\rmake -j8\rsudo make install This last command should fail us again. We get an error message similar to this:\nIn file included from include/grpc++/channel.h:37: /Library/Developer/CommandLineTools/usr/include/c++/v1/memory:2285:5: error: delete called on 'grpc::CallOpGenericRecvMessageHelper::DeserializeFunc' that is abstract but has non-virtual destructor [-Werror,-Wdelete-non-virtual-dtor] delete __ptr; ^  We need to add the following line, i.e. a virtual deconstructor at line 273 in class CallOpGenericRecvMessageHelper in file include/grpc++/impl/call.h:\nvirtual ~DeserializeFunc() {}  Again, you can download the file here:\ncall.h\nAfter this we continue with the procedure:\n# sudo ldconfig\r\rR CMD INSTALL grpc\rR -e \u0026#34;grpc::grpc_version()\u0026#34; "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/most-useful-git-commands/",
	"title": "Most useful git commands",
	"tags": ["devops"],
	"description": "",
	"content": " Setup Set your details\ngit config --global user.name \u0026#34;John Doe\u0026#34;\rgit config --global user.email \u0026#34;john@example.com\u0026#34; Use --global to set the configuration for all projects. If git config is used without --global and run inside a project directory, the settings are set for the specific project.\nMake git ignore file modes\ncd project/\rgit config core.filemode false This option is useful if the file permissions are not important to us, for example when we are on Windows.\nSee your settings\ngit config --list Get help for a specific git command\ngit help clone Starting a repo Initialize a git repository for existing code cd existing-project/\rgit init Clone a remote repository git clone https://github.com/user/repository.git This creates a new directory with the name of the repository.\nClone a remote repository in the current directory\ngit clone https://github.com/user/repository.git . Remotes Update and merge your current branch with a remote\ncd repository/\rgit pull origin master Where origin is the remote repository, and master the remote branch. If you don\u0026rsquo;t want to merge your changes, use git fetch\nView remote urls\ngit remote -v Change origin url\ngit remote set-url origin http//github.com/repo.git Add remote\ngit remote add remote-name https://github.com/user/repo.git Check Differences See non-staged (non-added) changes to existing files\ngit diff Note that this does not track new files.\nSee staged, non-commited changes\ngit diff --cached See differences between local changes and master\ngit diff origin/master Note that origin/master is one local branch, a shorthand for refs/remotes/origin/master, which is the full name of the remote-tracking branch.\nSee differences between two commits\ngit diff COMMIT1_ID COMMIT2_ID See the files that changed between two commits\ngit diff --name-only COMMIT1_ID COMMIT2_ID See the files changed in a specific commit\ngit diff-tree --no-commit-id --name-only -r COMMIT_ID\r#or\rgit show --pretty=\u0026#34;format:\u0026#34; --name-only COMMIT_ID Source: http://stackoverflow.com/a/424142/1391963\nSee diff before push\ngit diff --cached origin/master See diff with only the changed lines (no context)\ngit diff --unified=0 See details (log message, text diff) of a commit\ngit show COMMIT_ID Count the number of commits\ngit rev-list HEAD --count\rgit rev-list COMMIT_ID --count Check the status of the working tree (current branch, changed files\u0026hellip;)\ngit status Commiting git add changed_file.txt\rgit add folder-with-changed-files/\rgit commit -m \u0026#34;Commiting changes\u0026#34; Rename/move and remove files\ngit rm removeme.txt tmp/crap.txt\rgit mv file_oldname.txt file_newname.txt\rgit commit -m \u0026#34;deleting 2 files, renaming 1\u0026#34; Change message of last commit\ngit commit --amend -m \u0026#34;New commit message\u0026#34; Push local commits to remote branch git push origin master Revert one commit, push it\ngit revert dd61ab21\rgit push origin master Revert to the moment before one commit #reset the index to the desired tree\rgit reset 56e05fced\r#move the branch pointer back to the previous HEAD\rgit reset --soft HEAD@{1}\rgit commit -m \u0026#34;Revert to 56e05fced\u0026#34;\r#Update working copy to reflect the new commit\rgit reset --hard Source: http://stackoverflow.com/q/1895059/1391963\nUndo last commit, preserving local changes\ngit reset --soft HEAD~1 Undo last commit, without preserving local changes\ngit reset --hard HEAD~1 Undo last commit, preserving local changes in index\ngit reset --mixed HEAD~1\r#or git reset HEAD~1 See also http://stackoverflow.com/q/927358/1391963\nUndo non-pushed commits\ngit reset origin/master Reset to remote state\ngit fetch origin\rgit reset --hard origin/master See local branches\ngit branch See all branches\ngit branch -a Logs See recent commit history\ngit log See commit history for the last two commits\ngit log -2 See commit history for the last two commits, with diff\ngit log -p -2 See commit history printed in single lines\ngit log --pretty=oneline git diff \u0026gt; patch-issue-1.patch **Add a file and create a patch** git add newfile\rgit diff --staged \u0026gt; patch-issue-2.patch **Add a file, make some changes, and create a patch** git add newfile\rgit diff HEAD \u0026gt; patch-issue-2.patch **Make a patch for a commit** git format-patch COMMIT_ID **Make patches for the last two commits** git format-patch HEAD~2 **Make patches for all non-pushed commits** git format-patch origin/master **Create patches that contain binary content** git format-patch --binary --full-index origin/master **Apply a patch** git apply -v patch-name.patch **Apply a patch created using format-patch** git am patch1.patch **Break up multiple changes into separate commits (or commit only part of a changed file)** git add --patch file.txt\r(press \u0026#39;y\u0026#39; for the chunks to add)\rgit commit -m \u0026#39;first part of the file\u0026#39;\r(repeat if desired) Sources: https://stackoverflow.com/q/4948494/1391963, https://stackoverflow.com/q/1085162/1391963 ## Tags **Create a tag** git tag 7.x-1.3 **Push a tag** git push origin 7.x-1.3 -- Branching Create a branch\ngit checkout master\rgit branch new-branch-name Here master is the starting point for the new branch. Note that with these two commands we don\u0026rsquo;t move to the new branch, as we are still in master and we would need to run git checkout new-branch-name. The same can be achieved using one single command:\ngit checkout -b new-branch-name Create a branch from a previous commit\ngit branch branchname sha1-of-commit or using a symbolic reference (e.g. last commit):\ngit branch branchname HEAD~1\r#or git checkout -b branchname sha1-of-commit Source: http://stackoverflow.com/a/2816728/1391963\nCheckout a branch\ngit checkout new-branch-name See commit history for just the current branch\ngit cherry -v master (master is the branch you want to compare)\nMerge branch commits\ngit checkout master\rgit merge branch-name Here we are merging all commits of branch-name to master.\nMerge a branch without committing\ngit merge branch-name --no-commit --no-ff See differences between the current state and a branch\ngit diff branch-name See differences in a file, between the current state and a branch\ngit diff branch-name path/to/file Delete a branch\ngit branch -d new-branch-name Push the new branch\ngit push origin new-branch-name Get all branches\ngit fetch origin Get the git root directory\ngit rev-parse --show-toplevel Source: http://stackoverflow.com/q/957928/1391963\nRemove from repository all locally deleted files\ngit rm $(git ls-files --deleted) Source: http://stackoverflow.com/a/5147119/1391963\nDelete all untracked files\ngit clean -f Including directories:\ngit clean -f -d Preventing sudden cardiac arrest:\ngit clean -n -f -d Source: http://stackoverflow.com/q/61212/1391963\nDelete all files from a git repository that have already been deleted from disk:\ngit ls-files --deleted -z | xargs -0 git rm Source (and alternatives): https://stackoverflow.com/a/5147119/1391963\nShow total file size difference between two commits\nShort answer: Git does not do that. Long answer: See http://stackoverflow.com/a/10847242/1391963\nUnstage (undo add) files:\ngit reset HEAD file.txt See closest tag\ngit describe --tags `git rev-list --tags --max-count=1` Source: http://stackoverflow.com/q/1404796/1391963. See also git-describe. Debug SSH connection issues\nGIT_SSH_COMMAND=\u0026ldquo;ssh -vvv\u0026rdquo; git clone \nHave git pull running every X seconds, with GNU Screen\nUse Ctrl+a Ctrl+d to detach the screen. See previous git commands executed\nhistory | grep git\nor\ngrep \u0026lsquo;^git\u0026rsquo; /root/.bash_history\nSee recently used branches (i.e. branches ordered by most recent commit)\ngit for-each-ref \u0026ndash;sort=-committerdate refs/heads/ | head\nSource: http://stackoverflow.com/q/5188320/1391963 Tar project files, excluding .git directory\ncd .. tar cJf project.tar.xz project/ \u0026ndash;exclude-vcs\nTar all locally modified files\ngit diff \u0026ndash;name-only | xargs tar -cf project.tar -T -\nLook for conflicts in your current files\ngrep -H -r \u0026ldquo;\u0026lt;\u0026lt;\u0026lt;\u0026rdquo; * grep -H -r \u0026ldquo;\u0026gt;\u0026gt;\u0026gt;\u0026rdquo; * grep -H -r \u0026lsquo;^=======$\u0026rsquo; *\nThere\u0026rsquo;s also git-grep. Apply a patch not using git:\npatch -p1 \u0026lt; file.patch\nSource orga.cat/posts/most-useful-git-commands\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/scrum-psm-i/",
	"title": "Scrum PSM I",
	"tags": ["devops"],
	"description": "",
	"content": " After getting scrum.org the PSM I I wanted to capture the relevant content.\nThe complete guido can be downloaded here: scrumguides.org\n1. What is Scrum? Scrum is a framework for developing and sustaining complex products. A framework in which complex adaptive problems can be addressed. It is lightweight, simple to understand and yet difficult to master. To simplify, Scrum is not a process or a technique - it is a framework within which you can use different processes and techniques. It has roles, events, artefacts and rules that bind them together. Each component has a specific purpose. Scrum takes an iterative and incremental approach - optimizing predictability and control risk.\nScrum has its foundation based on the Empirical Process Theory - where knowledge comes from experience and decisions are made based on what is known. There are three pillars that uphold every implementation of empirical process control. - Transparency - Inspection - Adaptation  1.1. Scrum Values The five core values that are reflective in the work of a Scrum Team.\n People personally commit to achieving the goal of the Scrum team. Scrum member have the Courage to do the right thing. Everyone\u0026rsquo;s focus is on the sprint and Scrum team goals. Everyone agrees to be Open about all the work and challenges. Scrum team members Respect each other of being capable and independent.  2. Scrum Team A self-organised and cross functional team - designed to optimize flexibility, creativity and productivity.\n Role Description Rules   Product Owner   Maximize the value of product and work of the Development Team. Sole person responsible for managing the product Backlog.     Product Owner is one person, not a committee. Only the Product Owner can make changes to product Backlog item\u0026rsquo;s priority. Only the Product Owner can cancel a sprint under the influence of stakeholders, Scrum Master and the Development Team.     Scrum Master   Responsible for making sure everyone understands Scrum and adheres. Facilitate Scrum events. Coach the team. Remove impediments. Help the organisation to adopt Scrum.     Scrum Master ensures that only helpful interactions are taking place with the Development Team and anyone outside. Scrum Master is a Servant-Leader.  \n  Development Team   Self-organised and accountable. No one tells the Development Team how to turn the Backlog item into increments of realisable product. Cross-functional team with all skills to create a Product Increment.     Development Team should not act on anyone else\u0026rsquo;s request. Team size should be between 3 and 9. Everyone\u0026rsquo;s title is Developer and there should not be any sub-teams. No one can instruct the Development Team to work on different set of requirements. The number of items from the Backlog for the sprint is solely up to the Development Team.    \n3. Scrum Events All events in Scrum are time boxed. Sprint duration cannot change once it's started. However, it can be cancelled before the time box is over. Only a Product Owner can cancel a Sprint if the organisation changes direction or the market or the technology conditions change. Events enable transparency and create an opportunity to inspect and adapt.  The Sprint is the heart of Scrum, a time box of one month or less during which a DONE, usable, and potential releasable product increment is created.\n Events Time\u0026nbsp;Box* Agenda Required   Sprint Planning 08 Hours  What items can be done? How will the work get done?  The Scrum   Daily Stand-ups 15\u0026nbsp;Minutes  What I did yesterday What will I do today Any Impediments  The Development team   Sprint Review 04 Hours  Product Owner starts with what items are done from the Backlog. Development team talks about what went well, what problem it ran into, how the problems were solved. Development team demonstrates the work it has DONE. Product Owner projects the likely completion dates. Collaborate on what to do next.  The Scrum Team and the Stakeholders   Sprint Retrospective 03 Hours  How did the last Sprint go with respect to - people, relationships, process and tools. Major items that went well and potential improvements. Plan to implement improvements in the next sprint.  The Scrum Team  \n*Time box mentioned above is for one month sprint. For short sprint, it\u0026rsquo;s usually shorter. Scrum activities - Backlog refining or grooming.\nThis is an on-going activity and should not take more than 10 % of the Development Team\u0026rsquo;s time where product Backlogs are groomed or refined. The Product Owner is responsible for prioritizing the product Backlog items and the Development Team is responsible for estimating them.\n4. Scrum Artefacts Scrum's artefacts reflect the three pillars of the Empirical Theory Process in the work or value to increase transparency and opportunities for inspection and an enhanced scope for adaptation.   Artefact Description Owner   Product Backlog  Product Backlog is an ordered list of everything that's needed to complete a product. It is the single source of a living list of requirement. Product Owner is responsible to maintain and prioritize the Backlog items. Product Backlog is dynamic and never complete. Sprint can start as soon as there are enough items in the Backlog. There is always only one product Backlog.  Product Owner   Sprint Backlog  Product Backlog is an ordered list of everything that's needed to complete a product. It is the single source of a living list of requirement. Product Owner is responsible to maintain and prioritize the Backlog items. Product Backlog is dynamic and never complete. Sprint can start as soon as there are enough items in the Backlog. There is always only one product Backlog.  Development\u0026nbsp;Team   Increment   An Increment is a sum of all completed product Backlog items and the items of the increments of all previous sprints.  e.g.\nIncrement 1 = Sprint 1 Increment 2 = Sprint 1 + Sprint 2\nIncrement 3 = Sprint 1 + Sprint 2 + Sprint 3.   Development Team   Monitoring progress towards a Goal (delivering the product)  The total work remaining to reach the goal can be summed. The product Owner compares the amount of work remaining against the previous sprint reviews to assess the progress.  Most commonly used techniques are burn-down and burn-up charts.   Product Owner   Monitoring Sprint Progress  The sum of remaining work to deliver an increment which is reviewed at the daily scrum. The sprint progress information can be represented by a burn-down chart.  Development Team   5. Progress Tracking Tools Burn-down charts: Burn-down chart shows the progress the Development Team is making and is a powerful tool for visualising progress and work remaining. Burn-down charts may be used for financial tracking, resource tracking etc. In respect to a sprint, a burn-down chart is represented as -\n vertical Axis - remaining work (total estimated hours) for the sprint or product Backlog horizontal Axis - time, in days or sprints  A burn-down chart enables everyone to view the status of a sprint at any time.\n6. Estimation Techniques There are number of estimation techniques used in Agile. Most widely used in planning is the poker technique to estimate items. Participants use cards to estimate an item. This exercise is repeated in iterations until everyone\u0026rsquo;s estimates are unanimous. Units used are hours, days or story points. Other techniques in practice are:\n The Bucket System Big/Uncertain/Small Dot voting T-shirt sizes Affinity mapping and more  7. Definitions  Done  A product Backlog item or an increment that is releasable is called DONE. Everyone in the Scrum team should have common understanding of DONE.\nDONE should include all the development practices before the item is released into production.  Velocity Average of items done per Sprint to deliver a product. e.g. It took 5 sprints to deliver a product. Sprint1 - 10 Units\nSprint2 - 12 Units\nSprint3 - 9 Units\nSprint4 - 11 Units\nSprint5 - 13 Units\nVelocity of the team in this example is 11 ((10 + 12 + 9 + 11 + 13)/5) units per Sprint.  Time box Fixed time-period, it is an agreed previous agreed duration which the team has been consistently delivering a task or completing a goal. Sprint Goal Description of what the Development Team agrees to achieve in a sprint.  8. Reference: https://www.scrum.org/resources/scrum-guide\nWhat I also found quite interesting are the number of people that took the certifications: https://www.scrum.org/professional-scrum-certifications/count\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_linear_regression/",
	"title": "Linear Regression",
	"tags": ["R", "python", "regression", "machine learning"],
	"description": "",
	"content": " Source https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\nIt is used to estimate real values (cost of houses, number of calls, total sales etc.) based on continuous variable(s). Here, we establish relationship between independent and dependent variables by fitting a best line. This best fit line is known as regression line and represented by a linear equation\n$$Y= a *X + b$$\nThe best way to understand linear regression is to relive this experience of childhood. Let us say, you ask a child in fifth grade to arrange people in his class by increasing order of weight, without asking them their weights! What do you think the child will do? They would likely look (visually analyze) at the height and build of people and arrange them using a combination of these visible parameters. This is linear regression in real life! The child has actually figured out that height and build would be correlated to the weight by a relationship, which looks like the equation above.\nIn this equation:\nY - Dependent Variable a - Slope X - Independent variable b - Intercept  These coefficients a and b are derived based on minimizing the sum of squared difference of distance between data points and regression line.\nLook at the below example. Here we have identified the best fit line having linear equation\n$$y=0.2811x+13.9$$\nNow using this equation, we can find the weight, knowing the height of a person.\nLinear Regression is of mainly two types: Simple Linear Regression and Multiple Linear Regression. Simple Linear Regression is characterized by one independent variable. And, Multiple Linear Regression(as the name suggests) is characterized by multiple (more than 1) independent variables. While finding best fit line, you can fit a polynomial or curvilinear regression. And these are known as polynomial or curvilinear regression.\nR Code #Load Train and Test datasets\r #Identify feature and response variable(s) and values must be numeric and numpy arrays\r x_train \u0026lt;- input_variables_values_training_datasets\ry_train \u0026lt;- target_variables_values_training_datasets\rx_test \u0026lt;- input_variables_values_test_datasets\rx \u0026lt;- cbind(x_train,y_train)\r# Train the model using the training sets and check score\r linear \u0026lt;- lm(y_train ~ ., data = x)\rsummary(linear)\r# Predict Output\r predicted \u0026lt;- predict(linear,x_test)  Python Code #Import Library\r #Import other necessary libraries like pandas, numpy...\r from sklearn import linear_model\r#Load Train and Test datasets\r #Identify feature and response variable(s) and values must be numeric and numpy arrays\r x_train = input_variables_values_training_datasets\ry_train = target_variables_values_training_datasets\rx_test = input_variables_values_test_datasets\r# Create linear regression object\r linear = linear_model.LinearRegression()\r# Train the model using the training sets and check score\r linear.fit(x_train, y_train)\rlinear.score(x_train, y_train)\r#Equation coefficient and Intercept\r print(\u0026#39;Coefficient: \\n\u0026#39;, linear.coef_)\rprint(\u0026#39;Intercept: \\n\u0026#39;, linear.intercept_)\r#Predict Output\r predicted = linear.predict(x_test) "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-02_logistic_regression/",
	"title": "Logistic Regression",
	"tags": ["R", "python", "machine learning", "regression"],
	"description": "",
	"content": "Donât get confused by its name! It is a classification not a regression algorithm. It is used to estimate discrete values (binary values like 0/1, yes/no, true/false ) based on given set of independent variable(s). In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function. Hence, it is also known as logit regression. Since, it predicts the probability, its output values lies between 0 and 1 (as expected).\nAgain, let us try and understand this through a simple example.\nLetâs say your friend gives you a puzzle to solve. There are only two outcome scenarios â either you solve it or you donât. Now imagine, that you are being given wide range of puzzles / quizzes in an attempt to understand which subjects you are good at. The outcome to this study would be something like this â if you are given a trignometry based tenth grade problem, you are 70% likely to solve it. On the other hand, if it is grade fifth history question, the probability of getting an answer is only 30%. This is what Logistic Regression provides you.\nComing to the math, the log odds of the outcome is modeled as a linear combination of the predictor variables.\nodds = p/ (1-p) = probability of event occurrence / probability of not event occurrence ln(odds) = ln(p/(1-p)) logit(p) = ln(p/(1-p)) = b0+b1X1+b2X2+b3X3\u0026hellip;.+bkXk\nAbove, p is the probability of presence of the characteristic of interest. It chooses parameters that maximize the likelihood of observing the sample values rather than that minimize the sum of squared errors (like in ordinary regression).\nNow, you may ask, why take a log? For the sake of simplicity, letâs just say that this is one of the best mathematical way to replicate a step function. I can go in more details, but that will beat the purpose of this article.\nLogistic_RegressionPython Code\n#Import Library\r from sklearn.linear_model import LogisticRegression\r#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\r # Create logistic regression object\r model = LogisticRegression()\r# Train the model using the training sets and check score\r model.fit(X, y)\rmodel.score(X, y)\r#Equation coefficient and Intercept\r print(\u0026#39;Coefficient: \\n\u0026#39;, model.coef_)\rprint(\u0026#39;Intercept: \\n\u0026#39;, model.intercept_)\r#Predict Output\r predicted= model.predict(x_test) R Code\nx \u0026lt;- cbind(x_train,y_train)\r# Train the model using the training sets and check score\r logistic \u0026lt;- glm(y_train ~ ., data = x,family=\u0026#39;binomial\u0026#39;)\rsummary(logistic)\r#Predict Output\r predicted= predict(logistic,x_test) Furthermore..\nThere are many different steps that could be tried in order to improve the model:\nincluding interaction terms removing features regularization techniques using a non-linear model  Source https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/machine-learning/2018-01_machine_learning/",
	"title": "Machine Learning Overview",
	"tags": ["R", "python", "regression", "machine learning"],
	"description": "",
	"content": " Broadly, there are three types of Machine Learning Algorithms..\n1. Supervised Learning How it works: This algorithm consist of a target or outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data. Examples of Supervised Learning: Regression, Decision Tree, Random Forest, KNN, Logistic Regression etc.\n2. Unsupervised Learning How it works: In this algorithm, we do not have any target or outcome variable to predict / estimate. It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention. Examples of Unsupervised Learning: Apriori algorithm, K-means.\n3. Reinforcement Learning: How it works: Using this algorithm, the machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions. Example of Reinforcement Learning: Markov Decision Process\nSource\nMeasurement metrics Some measures of model accuracy like mean absolute error (MAE), mean absolute percentage error (MAPE), symmetric mean absolute percentage error (SMAPE), mean squared error (MSE) and root mean squared error (RMSE).\nMean squared error:\n$$MSE = \\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}res_t^2$$\nRoot mean squared error:\n$$RMSE = \\displaystyle\\sqrt{\\frac{1}{n}\\sum_{t=1}^{n}res_t^2}$$\nMean absolute error:\n$$MAE = \\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}|res_t|$$\nMean absolute percentage error:\n$$MAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{res_t}{y_t}\\right|$$\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/book/applied-predictive-modelling/",
	"title": "Applied Predictive Modelling",
	"tags": ["data science"],
	"description": "",
	"content": " Source cran\nChapter 1 Introduction Prediction Versus Interpretation, Key Ingredients of Predictive Models; Terminology; Example Data Sets and Typical Data Scenarios; Overview; Notation (15 pages, 3 figures)\nPart I: General Strategies Chapter 2 A Short Tour of the Predictive Modeling Process Case Study: Predicting Fuel Economy; Themes; Summary (8 pages, 6 figures, R packages used)\nChapter 3 Data Pre-Processing Case Study: Cell Segmentation in High-Content Screening; Data Transformations for Individual Predictors; Data Transformations for Multiple Predictors; Dealing with Missing Values; Removing Variables; Adding Variables; Binning Variables; Computing; Exercises (32 pages, 11 figures, R packages used)\nChapter 4 Over-Fitting and Model Tuning The Problem of Over-Fitting; Model Tuning; Data Splitting; Resampling Techniques; Case Study: Credit Scoring; Choosing Final Tuning Parameters; Data Splitting Recommendations; Choosing Between Models; Computing; Exercises (29 pages, 13 figures, R packages used)\nPart II: Regression Models Chapter 5 Measuring Performance in Regression Models Quantitative Measures of Performance; The Variance-Bias Tradeoff; Computing (4 pages, 3 figures)\nChapter 6 Linear Regression and Its Cousins Case Study: Quantitative Structure-Activity Relationship Modeling; Linear Regression; Partial Least Squares; Penalized Models; Computing; Exercises (37 pages, 20 figures, R packages used)\nChapter 7 Non-Linear Regression Models Neural Networks; Multivariate Adaptive Regression Splines; Support Vector Machines; K-Nearest Neighbors; Computing; Exercises (28 pages, 10 figures, R packages used)\nChapter 8 Regression Trees and Rule-Based Models Basic Regression Trees; Regression Model Trees; Rule-Based Models; Bagged Trees; Random Forests; Boosting; Cubist; Computing; Exercises (46 pages, 24 figures, R packages used)\nChapter 9 A Summary of Solubility Models (3 pages, 3 figures)\nChapter 10 Case Study: Compressive Strength of Concrete Mixtures Model Building Strategy; Model Performance; Optimizing Compressive Strength; Computing (12 pages, 5 figures, R packages used)\nPart III: Classification Models Chapter 11 Measuring Performance in Classification Models Class Predictions; Evaluating Predicted Classes; Evaluating Class Probabilities; Computing (20 pages, 9 figures, R packages used)\nChapter 12 Discriminant Analysis and Other Linear Classification Models Case Study; Logistic Regression; Linear Discriminant Analysis; Partial Least Squares Discriminant Analysis; Penalized Models; Nearest Shrunken Centroids; Computing; Exercises (52 pages, 20 figures, R packages used)\nChapter 13 Non-Linear Classification Models Nonlinear Discriminant Analysis; Neural Networks; Flexible Discriminant Analysis; Support Vector Machines; K-Nearest Neighbors; Naive Bayes; Computing; Exercises (38 pages, 16 figures, R packages used)\nChapter 14 Classification Trees and Rule-Based Models Basic Regression Trees; Rule-Based Models; Bagged Trees; Random Forests; Boosting; C5.0; Wrap-Up; Computing (46 pages, 15 figures, R packages used)\nChapter 15 A Summary of Grant Application Models (3 pages, 2 figures)\nChapter 16 Remedies for Severe Class Imbalance Case Study: Predicting Caravan Policy Ownership; The Effect of Class Imbalance; Model Tuning; Alternate Cutoffs; Adjusting Prior Probabilities; Unequal Case Weights; Sampling Methods; Cost-Sensitive Training; Computing; Exercises (24 pages, 7 figures, R packages used)\nChapter 17 Case Study: Job Scheduling Data Splitting and Model Strategy; Results; Computing (13 pages, 6 figures, R packages used)\nPart IV: Other Considerations Chapter 18 Measuring Predictor Importance Numeric Outcomes; Categorical Outcomes; Other Approaches; Computing; Exercises (24 pages, 10 figures, R packages used)\nChapter 19 An Introduction to Feature Selection Consequences of Using Non-Informative Predictors; Approaches for Reducing the Number of Predictors; Wrappers Methods; Filter Methods; Selection Bias; Misuse of Feature Selection; Case Study: Predicting Cognitive Impairment; Computing; Exercises (34 pages, 7 figures, R packages used)\nChapter 20 Factors That Can Affect Model Performance Type III Errors; Measurment Error in the Outcome; Measurement Error in the Predictors; Discretizing Continuous Outcomes; When Should You Trust Your Modelâs Prediction?; The Impact of a Large Sample; Computing; Exercises (26 pages, 12 figures, R packages used)\nAppendix These are included in the sample pages on Spinger\u0026rsquo;s website.\nAppendix A A Summary of Various Models Appendix B An Introduction to R Startup and Getting Help; Packages; Creating Objects; Data Types and Basic Structures; Working with Rectangular Data Sets; Objects and Classes; R Functions; The Three Faces of =; The AppliedPredictiveModeling Package; The caret Package; Software Used in This Text (16 pages, 1 figure, R packages used)\nAppendix C Interesting Websites "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/book/online-reads/",
	"title": "Online Reads",
	"tags": ["data science"],
	"description": "",
	"content": " persÃ¶nlicher Blog: harlecin.netlify.com Hackernews: news.ycombinator.com R-Bloggers: r-bloggers.com Data Machina: getrevue.co/profile/datamachina Reddit: reddit.com/r/MachineLearning  "
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/the-happiness-hypothesis/",
	"title": "The Happiness Hypothesis",
	"tags": ["anekdote"],
	"description": "Amazing read",
	"content": " The Divided Self Human thinking depends on metaphor. We understand new or complex things in relation to things we already know. For example, it\u0026rsquo;s hard to think about life in general, but once you apply the metaphor \u0026ldquo;life is a journey,\u0026rdquo; the metaphor guides you to some conclusions: You should learn the terrain, pick a direction, find some good traveling companions, and enjoy the trip, because there may be nothing at the end of the road. It\u0026rsquo;s also hard to think about the mind, but once you pick a metaphor it will guide your thinking.\nBuddha, for example, compared the mind to a wild elephant:\n In days gone by this mind of mine used to stray wherever selfish desire or lust or pleasure would lead it. Today this mind does not stray and is under the harmony of control, even as a wild elephant is controlled by the trainer.\n To understand most important ideas in psychology, you need to understand how the mind is divided into parts that sometimes conflict. We assume that there is one person in each body, but in some ways we are each more like a committee whose members have been thrown together to do a job, but who often find themselves working at cross purposes. Our minds are divided in four ways. The fourth is the most important, for it corresponds most closely to the rider and the elephant; but the first three also contribute to our experiences of temptation, weakness, and internal conflict.\n1. First Division: Mind vs. Body We sometimes say that the body has a mind of its own, but the French philosopher Michel de Montaigne went a step further and suggested that each part of the body has its own emotions and its own agenda.\nMontaigne also noted the ways in which our facial expressions betray our secret thoughts; our hair stands on end; our hearts race; our tongues fail to speak; and our bowels and anal sphincters undergo \u0026ldquo;dilations and contractions proper to [themselves], independent of our wishes or even opposed to them.\u0026rdquo;\n2. Second Division: Left vs. Right The human brain has two separate hemispheres joined by a large bundle of nerves, the corpus callosum.\nThe corpus callosum is the largest single bundle of nerves in the entire body, so it must be doing something important. Indeed it is: It allows the two halves of the brain to communicate and coordinate their activity.\nThe brain divides its processing of the world into its two hemispheres-left and right. The left hemisphere takes in information from the right half of the world (that is, it receives nerve transmissions from the right arm and leg, the right ear, and the left half of each retina, which receives light from the right half of the visual field) and sends out commands to move the limbs on the right side of the body. The right hemisphere is in this respect the left\u0026rsquo;s mirror image, taking in information from the left half of the world and controlling movement on the left side of the body. Nobody knows why the signals cross over in this way in all vertebrates; they just do. But in other respects, the two hemispheres are specialized for different tasks. The left hemisphere is specialized for language processing and analytical tasks. In visual tasks, it is better at noticing details. The right hemisphere is better at processing patterns in space, including that all-important pattern, the face.\n3. Third Division: New vs. Old The brain started off with just three rooms, or clumps of neurons: a hindbrain (connected to the spinal column), a midbrain, and a forebrain (connected to the sensory organs at the front of the animal). Over time, as more complex bodies and behaviors evolved, the brain kept building out the front, away from the spinal column, expanding the forebrain more than any other part. The forebrain of the earliest mammals developed a new outer shell, which included the hypothalamus (specialized to coordinate basic drives and motivations), the hippocampus (specialized for memory), and the amygdala (specialized for emotional learning and responding). These structures are sometimes referred to as the limbic system (from Latin limbus, \u0026ldquo;border\u0026rdquo; or \u0026ldquo;margin\u0026rdquo;) because they wrap around the rest of the brain, forming a border.\nAs mammals grew in size and diversified in behavior (after the dinosaurs became extinct), the remodeling continued. In the more social mammals, particularly among primates, a new layer of neural tissue developed and spread to surround the old limbic system. This neocortex (Latin for \u0026ldquo;new covering\u0026rdquo;) is the gray matter characteristic of human brains. The front portion of the neocortex is particularly interesting, for parts of it do not appear to be dedicated to specific tasks (such as moving a finger or processing sound). Instead, it is available to make new associations and to engage in thinking, planning, and decision making-mental processes that can free an organism from responding only to an immediate situation.\nThis growth of the frontal cortex seems like a promising explanation for the divisions we experience in our minds. And it has taken over control, though not perfectly, from the more primitive limbic system-Plato\u0026rsquo;s bad horse, St. Paul\u0026rsquo;s flesh. We can call this explanation the Promethean script of human evolution, after the character in Greek mythology who stole fire from the gods and gave it to humans.\nThe Promethean script is pleasing in that it neatly raises us above all other animals, justifying our superiority by our rationality. At the same time, it captures our sense that we are not yet gods-that the fire of rationality is somehow new to us, and we have not yet fully mastered it.\nThere is, however, a flaw in the Promethean script: It assumes that reason was installed in the frontal cortex but that emotion stayed behind in the limbic system. In fact, the frontal cortex enabled a great expansion of emotionality in humans. The lower third of the prefrontal cortex is called the orbitofrontal cortex because it is the part of the brain just above the eyes (orbit is the Latin term for the eye socket). This region of the cortex has grown especially large in humans and other primates and is one of the most consistently active areas of the brain during emotional reactions.16 The orbitofrontal cortex plays a central role when you size up the reward and punishment possibilities of a situation; the neurons in this part of the cortex fire wildly when there is an immediate possibility of pleasure or pain, loss or gain.\nHuman rationality depends critically on sophisticated emotionality. It is only because our emotional brains works so well that our reasoning can work at all. The metaphor of a rider on an elephant fits Damasio\u0026rsquo;s findings more closely: Reason and emotion must both work together to create intelligent behavior, but emotion (a major part of the elephant) does most of the work. When the neocortex came along, it made the rider possible, but it made the elephant much smarter, too.\n4. Fourth Division: Controlled vs. Automatic After its long infatuation with information processing models and computer metaphors, psychologists began to realize that there are really two processing systems at work in the mind at all times: controlled processes and automatic processes.\nMost mental processes happen automatically, without the need for conscious attention or control. Most automatic processes are completely unconscious, although some of them show a part of themselves to consciousness.\nBargh contrasts automatic processes with controlled processes, the kind of thinking that takes some effort, that proceeds in steps and that always plays out on the center stage of consciousness. For example, at what time would you need to leave your house to catch a 6:26 flight to London? That\u0026rsquo;s something you have to think about consciously, first choosing a means of transport to the airport and then considering rush-hour traffic, weather, and the strictness of the shoe police at the airport. You can\u0026rsquo;t depart on a hunch. But if you drive to the airport, almost everything you do on the way will be automatic: breathing, blinking, shifting in your seat, daydreaming, keeping enough distance between you and the car in front of you, even scowling and cursing slower drivers.\nControlled processing is limited-we can think consciously about one thing at a time only-but automatic processes run in parallel and can handle many tasks at once. If the mind performs hundreds of operations each second, all but one of them must be handled automatically.\nControlled processing requires language. You can have bits and pieces of thought through images, but to plan something complex, to weigh the pros and cons of different paths, or to analyze the causes of past successes and failures, you need words. Nobody knows how long ago human beings developed language, but most estimates range from around 2 million years ago, when hominid brains became much bigger, to as recently as 40,000 years ago, the time of cave paintings and other artifacts that reveal unmistakably modern human minds. Whichever end of that range you favor, language, reasoning, and conscious planning arrived in the most recent eye-blink of evolution. They are like new software, Rider version 1.0. The language parts work well, but there are still a lot of bugs in the reasoning and planning programs. Automatic processes, on the other hand, have been through thousands of product cycles and are nearly perfect. This difference in maturity between automatic and controlled processes helps explain why we have inexpensive computers that can solve logic, math, and chess problems better than any human beings can (most of us struggle with these tasks), but none of our robots, no matter how costly, can walk through the woods as well as the average six-year-old child (our perceptual and motor systems are superb).\nOne use of language is that it partially freed humans from \u0026ldquo;stimulus control.\u0026rdquo; Behaviorists such as B. F. Skinner were able to explain much of the behavior of animals as a set of connections between stimuli and responses. The behaviorists thought that people were no different from other animals. In this view, St. Paul\u0026rsquo;s lament could be restated as: \u0026ldquo;My flesh is under stimulus control.\u0026rdquo; It is no accident that we find the carnal pleasures so rewarding. Our brains, like rat brains, are wired so that food and sex give us little bursts of dopamine, the neurotransmitter that is the brain\u0026rsquo;s way of making us enjoy the activities that are good for the survival of our genes.\nBut the behaviorists were not exactly right about people. The controlled system allows people to think about long-term goals and thereby escape the tyranny of the here-and-now, the automatic triggering of temptation by the sight of tempting objects. People can imagine alternatives that are not visually present; they can weigh long-term health risks against present pleasures, and they can learn in conversation about which choices will bring success and prestige. Unfortunately, the behaviorists were not entirely wrong about people, either. For although the controlled system does not conform to behaviorist principles, it also has relatively little power to cause behavior. The automatic system was shaped by natural selection to trigger quick and reliable action, and it includes parts of the brain that make us feel pleasure and pain (such as the orbitofrontal cortex) and that trigger survivalelated motivations (such as the hypothalamus). The automatic system has its finger on the dopamine release button. The controlled system, in contrast, is better seen as an advisor. It\u0026rsquo;s a rider placed on the elephant\u0026rsquo;s back to help the elephant make better choices. The rider can see farther into the future, and the rider can learn valuable information by talking to other riders or by reading maps, but the rider cannot order the elephant around against its will.\nIn sum, the rider is an advisor or servant; not a king, president, or charioteer with a firm grip on the reins. The elephant, in contrast, is everything else. The elephant includes the gut feelings, visceral reactions, emotions, and intuitions that comprise much of the automatic system. The elephant and the rider each have their own intelligence, and when they work together well they enable the unique brilliance of human beings. But they don\u0026rsquo;t always work together well. Here are three quirks of daily life that illustrate the sometimes complex relationship between the rider and the elephant.\nFailures Of Self Control An emotionally intelligent person has a skilled rider who knows how to distract and coax the elephant without having to engage in a direct contest of wills.\nIt\u0026rsquo;s hard for the controlled system to beat the automatic system by willpower alone; like a tired muscle, the former soon wears down and caves in, but the latter runs automatically, effortlessly, and endlessly. Once you understand the power of stimulus control, you can use it to your advantage by changing the stimuli in your environment and avoiding undesirable ones; or, if that\u0026rsquo;s not possible, by filling your consciousness with thoughts about their less tempting aspects.\nMental Intrusions Whenever I am on a cliff, a rooftop, or a high balcony, the imp of the perverse whispers in my ear, \u0026ldquo;Jump.\u0026rdquo; It\u0026rsquo;s not a command, it\u0026rsquo;s just a word that pops into my consciousness. When I\u0026rsquo;m at a dinner party sitting next to someone I respect, the imp works hard to suggest the most inappropriate things I could possibly say. Who or what is the imp? Dan Wegner, one of the most perverse and creative social psychologists, has dragged the imp into the lab and made it confess to being an aspect of automatic processing.\nIn Wegner\u0026rsquo;s studies, participants are asked to try hard not to think about something, such as a white bear, or food, or a stereotype. This is hard to do. More important, the moment one stops trying to suppress a thought, the thought comes flooding in and becomes even harder to banish. In other words, Wegner creates minor obsessions in his lab by instructing people not to obsess. Wegner explains this effect as an \u0026ldquo;ironic process\u0026rdquo; of mental control. When controlled processing tries to influence thought (\u0026ldquo;Don\u0026rsquo;t think about a white bear!\u0026rdquo;), it sets up an explicit goal. And whenever one pursues a goal, a part of the mind automatically monitors progress, so that it can order corrections or know when success has been achieved. When that goal is an action in the world (such as arriving at the airport on time), this feedback system works well. But when the goal is mental, it backfires. Automatic processes continually check: \u0026ldquo;Am I not thinking about a white bear?\u0026rdquo; As the act of monitoring for the absence of the thought introduces the thought, the person must try even harder to divert consciousness. Automatic and controlled processes end up working at cross purposes, firing each other up to ever greater exertions. But because controlled processes tire quickly, eventually the inexhaustible automatic processes run unopposed, conjuring up herds of white bears. Thus, the attempt to remove an unpleasant thought can guarantee it a place on your frequent-play list of mental ruminations.\nThese are not commands, just ideas that pop into my head. Freud based much of his theory of psychoanalysis on such mental intrusions and free associations, and he found they often have sexual or aggressive content. But Wegner\u0026rsquo;s research offers a simpler and more innocent explanation: Automatic processes generate thousands of thoughts and images every day, often through random association. The ones that get stuck are the ones that particularly shock us, the ones we try to suppress or deny. The reason we suppress them is not that we know, deep down, that they\u0026rsquo;re true (although some may be), but that they are scary or shameful. Yet once we have tried and failed to suppress them, they can become the sorts of obsessive thoughts that make us believe in Freudian notions of a dark and evil unconscious mind.\nThe Difficulty Of Winning An Argument Moral judgment is like aesthetic judgment. When you see a painting, you usually know instantly and automatically whether you like it. If someone asks you to explain your judgment, you confabulate. You don\u0026rsquo;t really know why you think something is beautiful, but your interpreter module (the rider) is skilled at making up reasons. Moral arguments are much the same: Two people feel strongly about an issue, their feelings come first, and their reasons are invented on the fly, to throw at each other. When you refute a person\u0026rsquo;s argument, does she generally change her mind and agree with you? Of course not, because the argument you defeated was not the cause of her position; it was made up after the judgment was already made.\nIf you listen closely to moral arguments, you can sometimes hear something surprising: that it is really the elephant holding the reins, guiding the rider. It is the elephant who decides what is good or bad, beautiful or ugly. Gut feelings, intuitions, and snap judgments happen constantly and automatically (as Malcolm Gladwell described in Blink), but only the rider can string sentences together and create arguments to give to other people. In moral arguments, the rider goes beyond being just an advisor to the elephant; he becomes a lawyer, fighting in the court of public opinion to persuade others of the elephant\u0026rsquo;s point of view.\nBecause we can see only one little corner of the mind\u0026rsquo;s vast operation, we are surprised when urges, wishes, and temptations emerge, seemingly from nowhere. We make pronouncements, vows, and resolutions, and then are surprised by our own powerlessness to carry them out. We sometimes fall into the view that we are fighting with our unconscious, our id, or our animal self. But really we are the whole thing. We are the rider, and we are the elephant. Both have their strengths and special skills.\n##Changing Your Mind\n The whole universe is change and life itself is but what you deem it. -MARCUS AURELIUS\n[quote]What we are today comes from our thoughts of yesterday, and our present thoughts build our life of tomorrow: our life is the creation of our mind. -BUDDHA\n The most important idea in pop psychology is contained in the two quotations above: Events in the world affect us only through our interpretations of them, so if we can control our interpretations, we can control our world.\nThe Like-O-Meter The most important words in the elephant\u0026rsquo;s language are \u0026ldquo;like\u0026rdquo; and \u0026ldquo;dislike,\u0026rdquo; or \u0026ldquo;approach\u0026rdquo; and \u0026ldquo;withdraw.\u0026rdquo; Even the simplest animal must make decisions at every moment: Left or right? Go or stop? Eat or don\u0026rsquo;t eat? Animals with brains complex enough to have emotions make these decisions effortlessly and automatically by having what is sometimes called a \u0026ldquo;like-o-meter\u0026rdquo; running in their heads at all times. If a monkey tasting a new fruit feels a sweet sensation, its like-o-meter registers \u0026ldquo;I like it\u0026rdquo;; the monkey feels pleasure and bites right in. If the taste is bitter, a flash of displeasure discourages further eating. There\u0026rsquo;s no need for a weighing of pros and cons, or for a reasoning system. Just flashes of pleasure and displeasure.\nWe humans have a like-o-meter too, and it\u0026rsquo;s always running. Its influence is subtle, but careful experiments show that you have a like-dislike reaction to everything you are experiencing, even if you\u0026rsquo;re not aware of the experience. For example, suppose you are a participant in an experiment on what is known as \u0026ldquo;affective priming.\u0026rdquo; You sit in front of a computer screen and stare at a dot in the center. Every few seconds, a word is flashed over the dot. All you have to do is tap a key with your left hand if the word means something good or likable (such as garden, hope, fun), or tap a key with your right hand if the word means something bad or dislikable (death, tyranny, boredom). It seems easy, but for some reason you find yourself hesitating for a split second on some of the words. Unbeknownst to you, the computer is also flashing up another word, right on the dot, just for a few hundredths of a second before putting up the target word you\u0026rsquo;re rating. Though these words are presented subliminally (below the level of your awareness), your intuitive system is so fast that it reads and reacts to them with a like-o-meter rating. If the subliminal word is fear, it would register negative on your like-o-meter, making you feel a tiny flash of displeasure; and then, a split second later, when you see the word boredom, you would more quickly say that boredom is bad. Your negative evaluation of boredom has been facilitated, or \u0026ldquo;primed,\u0026rdquo; by your tiny flash of negativity toward fear. If, however, the word following fear is garden, you would take longer to say that garden is good, because of the time it takes for your like-o-meter to shift from bad to good.\nNegativity Bias Clinical psychologists sometimes say that two kinds of people seek therapy: those who need tightening, and those who need loosening. But for every patient seeking help in becoming more organized, self-controlled, and responsible about her future, there is a waiting room full of people hoping to loosen up, lighten up, and worry less about the stupid things they said at yesterday\u0026rsquo;s staff meeting or about the rejection they are sure will follow tomorrow\u0026rsquo;s lunch date. For most people, the elephant sees too many things as bad and not enough as good.\nResponses to threats and unpleasantness are faster, stronger, and harder to inhibit than responses to opportunities and pleasures.\nThis principle, called \u0026ldquo;negativity bias,\u0026rdquo; shows up all over psychology. In marital interactions, it takes at least five good or constructive actions to make up for the damage done by one critical or destructive act. In financial transactions and gambles, the pleasure of gaining a certain amount of money is smaller than the pain of losing the same amount. In evaluating a person\u0026rsquo;s character, people estimate that it would take twenty-five acts of life-saving heroism to make up for one act of murder. When preparing a meal, food is easily contaminated (by a single cockroach antenna), but difficult to purify. Over and over again, psychologists find that the human mind reacts to bad things more quickly, strongly, and persistently than to equivalent good things. We can\u0026rsquo;t just will ourselves to see everything as good because our minds are wired to find and react to threats, violations, and setbacks.\nYour behavior is governed by opposing motivational systems: an approach system, which triggers positive emotions and makes you want to move toward certain things; and a withdrawal system, which triggers negative emotions and makes you want to pull back or avoid other things. Both systems are always active, monitoring the environment, and the two systems can produce opposing motives at the same time (as when you feel ambivalence), but their relative balance determines which way you move. (The \u0026ldquo;like-o-meter\u0026rdquo; is a metaphor for this balancing process and its subtle moment-by-moment fluctuations.) The balance can shift in an instant: You are drawn by curiosity to an accident scene, but then recoil in horror when you see the blood that you could not have been surprised to see. You want to talk to a stranger, but you find yourself suddenly paralyzed when you approach that person. The withdrawal system can quickly shoot up to full power, overtaking the slower (and generally weaker) approach system.\nOne reason the withdrawal system is so quick and compelling is that it gets first crack at all incoming information. All neural impulses from the eyes and ears go first to the thalamus, a kind of central switching station in the brain. From the thalamus, neural impulses are sent out to special sensory processing areas in the cortex; and from those areas, information is relayed to the frontal cortex, where it is integrated with other higher mental processes and your ongoing stream of consciousness. If at the end of this process you become aware of a hissing snake in front of you, you could decide to run away and then order your legs to start moving. But because neural impulses move only at about thirty meters per second, this fairly long path, including decision time, could easily take a second or two. It\u0026rsquo;s easy to see why a neural shortcut would be advantageous, and the amygdala is that shortcut. The amygdala, sitting just under the thalamus, dips into the river of unprocessed information flowing through the thalamus, and it responds to patterns that in the past were associated with danger. The amygdala has a direct connection to the part of the brainstem that activates the fight-or-flight response, and if the amygdala finds a pattern that was part of a previous fear episode (such as the sound of a hiss), it orders the body to red alert.\nThe elephant reacts before the rider even sees the snake on the path. Although you can tell yourself that you are not afraid of snakes, if your elephant fears them and rears up, you\u0026rsquo;ll still be thrown.\nOne final point about the amygdala: Not only does it reach down to the brainstem to trigger a response to danger but it reaches up to the frontal cortex to change your thinking. It shifts the entire brain over to a withdrawal orientation. There is a two-way street between emotions and conscious thoughts: Thoughts can cause emotions (as when you reflect on a foolish thing you said), but emotions can also cause thoughts, primarily by raising mental filters that bias subsequent information processing. A flash of fear makes you extra vigilant for additional threats; you look at the world through a filter that interprets ambiguous events as possible dangers. A flash of anger toward someone raises a filter through which you see everything the offending person says or does as a further insult or transgression. Feelings of sadness blind you to all pleasures and opportunities.\nThe Cortical Lottery When it comes to explaining personality, it\u0026rsquo;s always true that nature and nurture work together. But it\u0026rsquo;s also true that nature plays a bigger role than most people realize. Consider the identical twin sisters Daphne and Barbara.\nDaphne and Barbara came to be known as the \u0026ldquo;giggle twins.\u0026rdquo; Both have sunny personalities and a habit of bursting into laughter in mid-sentence. They won the cortical lottery-their brains were preconfigured to see good in the world. Other pairs of twins, however, were born to look on the dark side. In fact, happiness is one of the most highly heritable aspects of personality.\nA person\u0026rsquo;s average or typical level of happiness is that person\u0026rsquo;s \u0026ldquo;affective style.\u0026rdquo; (\u0026ldquo;Affect\u0026rdquo; refers to the felt or experienced part of emotion.) Your affective style reflects the everyday balance of power between your approach system and your withdrawal system, and this balance can be read right from your forehead. It has long been known from studies of brainwaves that most people show an asymmetry: more activity either in the right frontal cortex or in the left frontal cortex. In the late 1980s, Richard Davidson at the University of Wisconsin discovered that these asymmetries correlated with a person\u0026rsquo;s general tendencies to experience positive and negative emotions. People showing more of a certain kind of brainwave coming through the left side of the forehead reported feeling more happiness in their daily lives and less fear, anxiety, and shame than people exhibiting higher activity on the right side. Later research showed that these cortical \u0026ldquo;lefties\u0026rdquo; are less subject to depression and recover more quickly from negative experiences.\nScan Your Brain Which set of statements is more true of you?\nSet A:\nI'm always willing to try something new if I think it will be fun. If I see a chance to get something I want I move on it right away. When good things happen to me, it affects me strongly. I often act on the spur of the moment.  Set B:\nI worry about making mistakes. Criticism or scolding hurts me quite a bit. I feel worried when I think I have done poorly at something important. I have many fears compared to my friends.  People who endorse Set A over Set B have a more approach-oriented style and, on average, show greater cortical activity on the left side of the forehead. People who endorse Set B have a more withdrawal-oriented style and, on average, show greater cortical activity on the right side.\nHow To Change Your Mind You can change your affective style too-but again, you can\u0026rsquo;t do it by sheer force of will. You have to do something that will change your repertoire of available thoughts. Here are three of the best methods for doing so: meditation, cognitive therapy, and Prozac. All three are effective because they work on the elephant.\n#Meditation Suppose you read about a pill that you could take once a day to reduce anxiety and increase your contentment. Would you take it? Suppose further that the pill has a great variety of side effects, all of them good: increased self-esteem, empathy, and trust; it even improves memory. Suppose, finally, that the pill is all natural and costs nothing. Now would you take it?\nThe pill exists. It is meditation.\nIt sounds easy: Sit still (in most forms) and focus awareness only on your breathing, or on a word, or on an image, and let no other words, ideas, or images arise in consciousness. Meditation is, however, extraordinarily difficult at first, and confronting your repeated failures in the first weeks teaches the rider lessons in humility and patience. The goal of meditation is to change automatic thought processes, thereby taming the elephant. And the proof of taming is the breaking of attachments.\nCharles wants money and lives in a constant state of vigilance for chances to make it: He loses sleep over fines, losses, or transactions that he thinks did not get him the best possible deal. Once again, losses loom larger than gains, so even if Charles grows steadily wealthier, thoughts about money may on average give him more unhappiness than happiness.\nFor Buddha, attachments are like a game of roulette in which someone else spins the wheel and the game is rigged: The more you play, the more you lose. The only way to win is to step away from the table. And the only way to step away, to make yourself not react to the ups and downs of life, is to meditate and tame the mind. Although you give up the pleasures of winning, you also give up the larger pains of losing.\nThe discovery is that meditation tames and calms the elephant. Meditation done every day for several months can help you reduce substantially the frequency of fearful, negative, and grasping thoughts, thereby improving your affective style. As Buddha said: \u0026ldquo;When a man knows the solitude of silence, and feels the joy of quietness, he is then free from fear and sin.\u0026rdquo;\n#Cognitive Therapy Meditation is a characteristically Eastern solution to the problems of life. Even before Buddha, the Chinese philosopher Lao Tzu had said that the road to wisdom runs through calm inaction, desireless waiting. Western approaches to problems more typically involve pulling out a tool box and trying to fix what\u0026rsquo;s broken. The toolbox was thoroughly modernized in the 1960s by Aaron Beck.\nBeck, a psychiatrist at the University of Pennsylvania, had been trained in the Freudian approach in which \u0026ldquo;the child is father to the man.\u0026rdquo; Whatever ails you is caused by events in your childhood, and the only way to change yourself now is to dig through repressed memories, come up with a diagnosis, and work through your unresolved conflicts. For depressed patients, however, Beck found little evidence in the scientific literature or in his own clinical practice that this approach was working. The more space he gave them to run through their self-critical thoughts and memories of injustice, the worse they felt. But in the late 1960s, when Beck broke with standard practice and, questioned the legitimacy of his patients\u0026rsquo; irrational and self-critical thoughts, the patients often seemed to feel better.\nBeck took a chance. He mapped out the distorted thought processes characteristic of depressed people and trained his patients to catch and challenge these thoughts. Beck was scorned by his Freudian colleagues, who thought he was treating the symptoms of depression with Band-Aids while letting the disease rage underneath, but his courage and persistence paid off. He created cognitive therapy, one of the most effective treatments available for depression, anxiety, and many other problems.\nDepressed people are convinced in their hearts of three related beliefs, known as Beck\u0026rsquo;s \u0026ldquo;cognitive triad\u0026rdquo; of depression. These are: \u0026ldquo;I\u0026rsquo;m no good,\u0026rdquo; \u0026ldquo;My world is bleak,\u0026rdquo; and \u0026ldquo;My future is hopeless.\u0026rdquo; A depressed person\u0026rsquo;s mind is filled with automatic thoughts supporting these dysfunctional beliefs, particularly when things goes wrong. The thought distortions were so similar across patients that Beck gave them names. Consider the depressed father whose daughter falls down and bangs her head while he is watching her. He instantly flagellates himself with these thoughts: \u0026ldquo;I\u0026rsquo;m a terrible father\u0026rdquo; (this is called \u0026ldquo;personalization,\u0026rdquo; or seeing the event as a referendum on the self rather than as a minor medical issue); \u0026ldquo;Why do I always do such terrible things to my children?\u0026rdquo; (\u0026ldquo;overgeneralization\u0026rdquo; combined with dichotomous \u0026ldquo;always/never\u0026rdquo; thinking); \u0026ldquo;Now she\u0026rsquo;s going to have brain damage\u0026rdquo; (\u0026ldquo;magnification\u0026rdquo;); \u0026ldquo;Everyone will hate me\u0026rdquo; (\u0026ldquo;arbitrary inference,\u0026rdquo; or jumping to a conclusion without evidence).\nDepressed people are caught in a feedback loop in which distorted thoughts cause negative feelings, which then distort thinking further. Beck\u0026rsquo;s discovery is that you can break the cycle by changing the thoughts. A big part of cognitive therapy is training clients to catch their thoughts, write them down, name the distortions, and then find alternative and more accurate ways of thinking. Over many weeks, the client\u0026rsquo;s thoughts become more realistic, the feedback loop is broken, and the client\u0026rsquo;s anxiety or depression abates. Cognitive therapy works because it teaches the rider how to train the elephant rather than how to defeat it directly in an argument. On the first day of therapy, the rider doesn\u0026rsquo;t realize that the elephant is controlling him, that the elephant\u0026rsquo;s fears are driving his conscious thoughts. Over time, the client learns to use a set of tools; these include challenging automatic thoughts and engaging in simple tasks, such as going out to buy a newspaper rather than staying in bed all day ruminating. These tasks are often assigned as homework, to be done daily. (The elephant learns best from daily practice; a weekly meeting with a therapist is not enough.) With each reframing, and with each simple task accomplished, the client receives a little reward, a little flash of relief or pleasure. And each flash of pleasure is like a peanut given to an elephant as reinforcement for a new behavior.\nUnlike Freud, Beck tested his theories in controlled experiments. People who underwent cognitive therapy for depression got measurably better; they got better faster than people who were put on a waiting list for therapy; and, at least in some studies, they got better faster than those who received other therapies. When cognitive therapy is done very well it is as effective as drugs such as Prozac for the treatment of depression, and its enormous advantage over Prozac is that when cognitive therapy stops, the benefits usually continue because the elephant has been retrained. Prozac, in contrast, works only for as long as you take it.\nI don\u0026rsquo;t mean to suggest that cognitive behavioral therapy is the only psychotherapy that works. Most forms of psychotherapy work to some degree, and in some studies they all seem to work equally well. It comes down to a question of fit: Some people respond better to one therapy than another, and some psychological disorders are more effectively treated by one therapy than another. If you have frequent automatic negative thoughts about yourself, your world, or your future, and if these thoughts contribute to chronic feelings of anxiety or despair, then you might find a good fit with cognitive behavioral therapy.\n#Prozac Prozac is controversial for at least two reasons. First, it is a shortcut. In most studies, Prozac turns out to be just about as effective as cognitive therapy-sometimes a little more, sometimes a little less-but it\u0026rsquo;s so much easier than therapy. No daily homework or difficult new skills; no weekly therapy appointment. If you believe in the Protestant work ethic and the maxim \u0026ldquo;No pain, no gain,\u0026rdquo; then you might be disturbed by Prozac. Second, Prozac does more than just relieve symptoms; it sometimes changes personality.\nIt\u0026rsquo;s easy for those who did well in the cortical lottery to preach about the importance of hard work and the unnaturalness of chemical shortcuts. But for those who, through no fault of their own, ended up on the negative half of the affective style spectrum, Prozac is a way to compensate for the unfairness of the cortical lottery. Furthermore, it\u0026rsquo;s easy for those who believe that the body is a temple to say that cosmetic psychopharmacology is a kind of sacrilege. Something is indeed lost when psychiatrists no longer listen to their patients as people, but rather as a car mechanic would listen to an engine, looking only for clues about which knob to adjust next. But if the hippocampal theory of Prozac is correct, many people really do need a mechanical adjustment. It\u0026rsquo;s as though they had been driving for years with the emergency brake halfway engaged, and it might be worth a five-week experiment to see what happens to their lives when the brake is released. Framed in this way, Prozac for the \u0026ldquo;worried well\u0026rdquo; is no longer just cosmetic. It is more like giving contact lenses to a person with poor but functional eyesight who has learned ways of coping with her limitations. Far from being a betrayal of that person\u0026rsquo;s \u0026ldquo;true self,\u0026rdquo; contact lenses can be a reasonable shortcut to proper functioning.\nLife is what we deem it, and our lives are the creations of our minds. But these claims are not helpful until augmented by a theory of the divided self (such as the rider and the elephant) and an understanding of negativity bias and affective style. Once you know why change is so hard, you can drop the brute force method and take a more psychologically sophisticated approach to self-improvement. Buddha got it exactly right: You need a method for taming the elephant, for changing your mind gradually. Meditation, cognitive therapy, and Prozac are three effective means of doing so. Because each will be effective for some people and not for others, I believe that all three should be readily available and widely publicized. Life itself is but what you deem it, and you can-through meditation, cognitive therapy, and Prozac-redeem yourself.\nUltrasociality  [quote]Zigong asked: \u0026ldquo;Is there any single word that could guide one\u0026rsquo;s entire life?\u0026rdquo; The master said: \u0026ldquo;Should it not be reciprocity? What you do not wish for yourself, do not do to others.\u0026rdquo; -ANALECTS OF CONFUCIUS[/quote]\n[quote]That which is hateful to you, do not do to your fellow; this, in a few words, is the entire Torah; all the rest is but an elaboration of this one, central point. -RABBI HILLEL, 1ST CENT. BCE[/quote]\n Animals that live in large peaceful societies seem to violate the laws of evolution (such as competition and survival of the fittest), but only until you learn a bit more about evolution. Ultrasociality-living in large cooperative societies in which hundreds or thousands of individuals reap the benefits of an extensive division of labor-evolved independently at least four times in the animal kingdom: among hymenoptera (ants, bees, and wasps); termites; naked mole rats; and humans. In each case, a feature possessing potentially cooperation-enhancing properties already existed. For all the nonhuman ultrasocial species, that feature was the genetics of kin altruism. It\u0026rsquo;s obvious that animals will risk their lives for the safety of their own children: The only way to \u0026ldquo;win\u0026rdquo; at the game of evolution is to leave surviving copies of your genes. Yet not just your children carry copies of your genes. Your siblings are just as closely related to you (50 percent shared genes) as your children; your nephews and nieces share a quarter of your genes, and your cousins one eighth.\nBecause nearly all animals that live in cooperative groups live in groups of close relatives, most altruism in the animal kingdom reflects the simple axiom that shared genes equals shared interests. Here\u0026rsquo;s where the ancestors of bees, termites, and mole rats took the common mechanism of kin altruism, which makes many species sociable, and parlayed it6 into the foundation of their uncommon ultrasociality: They are all siblings.\nReciprocity Most interactions among animals (other than close kin) are zero-sum games: One animal\u0026rsquo;s gain is the other\u0026rsquo;s loss. But life is full of situations in which cooperation would expand the pie to be shared if only a way could be found to cooperate without being exploited. Animals that hunt are particularly vulnerable to the variability of success: They may find far more food than they can eat in one day, and then find no food at all for three weeks. Animals that can trade their surplus on a day of plenty for a loan on a day of need are much more likely to survive the vagaries of chance. Vampire bats, for example, will regurgitate blood from a successful night of bloodsucking into the mouth of an unsuccessful and genetically unrelated peer. Such behavior seems to violate the spirit of Darwinian competition, except that the bats keep track of who has helped them in the past, and in return they share primarily with those bats. Like the Godfather, bats play tit for tat, and so do other social animals, particularly those that live in relatively small, stable groups where individuals can recognize each other as individuals.\nBut if the response to noncooperation is just noncooperation on the next round, then tit for tat can unite groups of only a few hundred. In a large enough group, a cheating vampire bat can beg a meal from a different successful bat each night and, when they come to him pleading for a return favor, just wrap his wings around his head and pretend to be asleep. What are they going to do to him? Well, if these were people rather than bats, we know what they\u0026rsquo;d do: They\u0026rsquo;d beat the hell out of him. Vengeance and gratitude are moral sentiments that amplify and enforce tit for tat. Vengeful and grateful feelings appear to have evolved precisely because they are such useful tools for helping individuals create cooperative relationships, thereby reaping the gains from non-zero-sum games. A species equipped with vengeance and gratitude responses can support larger and more cooperative social groups because the payoff to cheaters is reduced by the costs they bear in making enemies. Conversely, the benefits of generosity are increased because one gains friends.\nTit for tat appears to be built into human nature as a set of moral emotions that make us want to return favor for favor, insult for insult, tooth for tooth, and eye for eye. Recent evidence suggests that there really could be an exchange organ in the brain if we loosen the meaning of \u0026ldquo;organ\u0026rdquo; and allow that functional systems in the brain are often composed of widely separated bits of neural tissue that work together to do a specific job.\nGratitude and vengefulness are big steps on the road that led to human ultrasociality, and it\u0026rsquo;s important to realize that they are two sides of one coin. It would be hard to evolve one without the other. An individual who had gratitude without vengefulness would be an easy mark for exploitation, and a vengeful and ungrateful individual would quickly alienate all potential cooperative partners.\nThe Importance of Gossip When I said that people would beat the hell out of an ingrate who failed to repay an important favor, I left out a qualification. For a first offense, they\u0026rsquo;d probably just gossip. They\u0026rsquo;d ruin his reputation. Gossip is another key piece in the puzzle of how humans became ultrasocial. It might also be the reason we have such large heads.\nThe only theory that explains why animals in general have particular brain sizes is the one that maps brain size onto social group size. Robin Dunbar has demonstrated that within a given group of vertebrate species-primates, carnivores, ungulates, birds, reptiles, or fish-the logarithm of the brain size is almost perfectly proportional to the logarithm of the social group size. In other words, all over the animal kingdom, brains grow to manage larger and larger groups. Social animals are smart animals.\nLanguage allows small groups of people to bond quickly and to learn from each other about the bonds of others. Dunbar notes that people do in fact use language primarily to talk about other people-to find out who is doing what to whom, who is coupling with whom, who is fighting with whom. And Dunbar points out that in our ultrasocial species, success is largely a matter of playing the social game well. It\u0026rsquo;s not what you know, it\u0026rsquo;s who you know. In short, Dunbar proposes that language evolved because it enabled gossip. Individuals who could share social information, using any primitive means of communication, had an advantage over those who could not. And once people began gossiping, there was a runaway competition to master the arts of social manipulation, relationship aggression, and reputation management, all of which require yet more brain power.\nGossip creates a non-zero-sum game because it costs us nothing to give each other information, yet we both benefit by receiving information.\nUsing Reciprocity Reciprocity is an all-purpose relationship tonic. Used properly, it strengthens, lengthens, and rejuvenates social ties. It works so well in part because the elephant is a natural mimic.\nThe Importance of Appearence If life itself is but what you deem it, then why not focus your efforts on persuading others to believe that you are a virtuous and trustworthy cooperator? Thus Niccolo Machiavelli, whose name has become synonymous with the cunning and amoral use of power, wrote five hundred years ago that \u0026ldquo;the great majority of mankind are satisfied with appearances, as though they were realities, and are often more influenced by the things that seem than by those that are.\u0026rdquo; The Machiavellian version of tit for tat, for example, is to do all you can to cultivate the reputation of a trustworthy yet vigilant partner, whatever the reality may be.\nFinding your Inner Lawyer In my studies of moral judgment, I have found that people are skilled at finding reasons to support their gut feelings: The rider acts like a lawyer whom the elephant has hired to represent it in the court of public opinion.\nOne of the reasons people are often contemptuous of lawyers is that they fight for a client\u0026rsquo;s interests, not for the truth. To be a good lawyer, it often helps to be a good liar. Although many lawyers won\u0026rsquo;t tell a direct lie, most will do what they can to hide inconvenient facts while weaving a plausible alternative story for the judge and jury, a story that they sometimes know is not true. Our inner lawyer works in the same way, but, somehow, we actually believe the stories he makes up.\nStudies of everyday reasoning show that the elephant is not an inquisitive client. When people are given difficult questions to think about-for example, whether the minimum wage should be raised-they generally lean one way or the other right away, and then put a call in to reasoning to see whether support for that position is forthcoming.\nMost people gave no real evidence for their positions, and most made no effort to look for evidence opposing their initial positions. David Perkins, a Harvard psychologist who has devoted his career to improving reasoning, found the same thing. He says that thinking generally uses the \u0026ldquo;makessense\u0026rdquo; stopping rule. We take a position, look for evidence that supports it, and if we find some evidence-enough so that our position \u0026ldquo;makes sense\u0026rdquo;-we stop thinking. But at least in a low-pressure situation such as this, if someone else brings up reasons and evidence on the other side, people can be induced to change their minds; they just don\u0026rsquo;t make an effort to do such thinking for themselves.\nPeople who are told that they have performed poorly on a test of social intelligence think extra hard to find reasons to discount the test; people who are asked to read a study showing that one of their habits-such as drinking coffee-is unhealthy think extra hard to find flaws in the study, flaws that people who don\u0026rsquo;t drink coffee don\u0026rsquo;t notice. Over and over again, studies show that people set out on a cognitive mission to bring back reasons to support their preferred belief or action. And because we are usually successful in this mission, we end up with the illusion of objectivity. We really believe that our position is rationally and objectively justified.\nHow to Win at the Social Life Game I don\u0026rsquo;t want to blame everything on the lawyer. The lawyer is, after all, the rider-your conscious, reasoning self; and he is taking orders from the elephant-your automatic and unconscious self. The two are in cahoots to win at the game of life by playing Machiavellian tit for tat, and both are in denial about it.\nTo win at this game you must present your best possible self to others. You must appear virtuous, whether or not you are, and you must gain the benefits of cooperation whether or not you deserve them. But everyone else is playing the same game, so you must also play defense-you must be wary of others\u0026rsquo; self-presentations, and of their efforts to claim more for themselves than they deserve. Social life is therefore always a game of social comparison. We must compare ourselves to other people, and our actions to their actions, and we must somehow spin those comparisons in our favor. The consistent finding of psychological research is that we are fairly accurate in our perceptions of others. It\u0026rsquo;s our self-perceptions that are distorted because we look at ourselves in a rose-colored mirror.\nWe judge others by their behavior, but we think we have special information about ourselves-we know what we are \u0026ldquo;really like\u0026rdquo; inside, so we can easily find ways to explain away our selfish acts and cling to the illusion that we are better than others.\nIf the only effect of these rampant esteem-inflating biases was to make people feel good about themselves, they would not be a problem. In fact, evidence shows that people who hold pervasive positive illusions about themselves, their abilities, and their future prospects are mentally healthier, happier, and better liked than people who lack such illusions. But such biases can make people feel that they deserve more than they do, thereby setting the stage for endless disputes with other people who feel equally over-entitled.\nNaive Realism Emily Pronin at Princeton and Lee Ross at Stanford trace this resistance to a phenomenon they call \u0026ldquo;naive realism\u0026rdquo;: Each of us thinks we see the world directly, as it really is. We further believe that the facts as we see them are there for all to see, therefore others should agree with us. If they don\u0026rsquo;t agree, it follows either that they have not yet been exposed to the relevant facts or else that they are blinded by their interests and ideologies.\nIt just seems plain as day, to the naive realist, that everyone is influenced by ideology and self-interest. Except for me. I see things as they are.\nIf I could nominate one candidate for \u0026ldquo;biggest obstacle to world peace and social harmony,\u0026rdquo; it would be naive realism because it is so easily ratcheted up from the individual to the group level: My group is right because we see things as they are. Those who disagree are obviously biased by their religion, their ideology, or their self-interest. Naive realism gives us a world full of good and evil, and this brings us to the most disturbing implication of the sages\u0026rsquo; advice about hypocrisy: Good and evil do not exist outside of our beliefs about them.\nThe Myth Of Pure Evil In Evil: Inside Human Cruelty and Aggression, Baumeister examined evil from the perspective of both victim and perpetrator. When taking the perpetrator\u0026rsquo;s perspective, he found that people who do things we see as evil, from spousal abuse all the way to genocide, rarely think they are doing anything wrong. They almost always see themselves as responding to attacks and provocations in ways that are justified. They often think that they themselves are victims.\nAlmost everywhere Baumeister looked in the research literature, he found that victims often shared some of the blame. Most murders result from an escalating cycle of provocation and retaliation; often, the corpse could just as easily have been the murderer. In half of all domestic disputes, both sides used violence.\nPeople usually have reasons for committing violence, and those reasons usually involve retaliation for a perceived injustice, or self-defense. This does not mean that both sides are equally to blame: Perpetrators often grossly overreact and misinterpret (using self-serving biases). But Baumeister\u0026rsquo;s point is that we have a deep need to understand violence and cruelty through what he calls \u0026ldquo;the myth of pure evil.\u0026rdquo; Of this myth\u0026rsquo;s many parts, the most important are that evildoers are pure in their evil motives (they have no motives for their actions beyond sadism and greed); victims are pure in their victimhood (they did nothing to bring about their victimization); and evil comes from outside and is associated with a group or force that attacks our group.\nThe myth of pure evil is the ultimate self-serving bias, the ultimate form of naive realism. And it is the ultimate cause of most longunning cycles of violence because both sides use it to lock themselves into a Manichaean struggle.\nIn another unsettling conclusion, Baumeister found that violence and cruelty have four main causes. The first two are obvious attributes of evil: greed/ambition (violence for direct personal gain, as in robbery) and sadism (pleasure in hurting people). But greed/ambition explains only a small portion of violence, and sadism explains almost none. Outside of children\u0026rsquo;s cartoons and horror films, people almost never hurt others for the sheer joy of hurting someone. The two biggest causes of evil are two that we think are good, and that we try to encourage in our children: high self-esteem and moral idealism. Having high self-esteem doesn\u0026rsquo;t directly cause violence, but when someone\u0026rsquo;s high esteem is unrealistic or narcissistic, it is easily threatened by reality; in reaction to those threats, people-particularly young men-often lash out violently.\nThreatened self-esteem accounts for a large portion of violence at the individual level, but to really get a mass atrocity going you need idealism-the belief that your violence is a means to a moral end. The major atrocities of the twentieth century were carried out largely either by men who thought they were creating a utopia or else by men who believed they were defending their homeland or tribe from attack. Idealism easily becomes dangerous because it brings with it, almost inevitably, the belief that the ends justify the means.\nFinding The Great Way In philosophy classes, I often came across the idea that the world is an illusion. I never really knew what that meant, although it sounded deep. But after two decades studying moral psychology, I think I finally get it. The anthropologist Clifford Geertz wrote that \u0026ldquo;man is an animal suspended in webs of significance that he himself has spun.\u0026rdquo; That is, the world we live in is not really one made of rocks, trees, and physical objects; it is a world of insults, opportunities, status symbols, betrayals, saints, and sinners. All of these are human creations which, though real in their own way, are not real in the way that rocks and trees are real. These human creations are like fairies in J. M. Barrie\u0026rsquo;s Peter Pan: They exist only if you believe in them. They are the Matrix (from the movie of that name); they are a consensual hallucination.\nSo what can you do about it? The first step is to see it as a game and stop taking it so seriously. The great lesson that comes out of ancient India is that life as we experience it is a game called \u0026ldquo;samsara.\u0026rdquo; It is a game in which each person plays out his \u0026ldquo;dharma,\u0026rdquo; his role or part in a giant play. In the game of samsara, good things happen to you, and you are happy. Then bad things happen, and you are sad or angry. And so it goes, until you die. Then you are reborn back into it, and it repeats. The message of the Bhagavad Gita (a central text of Hinduism) is that you can\u0026rsquo;t quit the game entirely; you have a role to play in the functioning of the universe, and you must play that role. But you should do it in the right way, without being attached to the \u0026ldquo;fruits\u0026rdquo; or outcomes of your action.\nBuddha went a step further. He, too, counseled indifference to the ups and downs of life, but he urged that we quit the game entirely. Buddhism is a set of practices for escaping samsara and the endless cycle of rebirth.\nJudgmentalism is indeed a disease of the mind: it leads to anger, torment, and conflict. But it is also the mind\u0026rsquo;s normal condition-the elephant is always evaluating, always saying \u0026ldquo;Like it\u0026rdquo; or \u0026ldquo;Don\u0026rsquo;t like it.\u0026rdquo; So how can you change your automatic reactions? You know by now that you can\u0026rsquo;t simply resolve to stop judging others or to stop being a hypocrite. But, as Buddha taught, the rider can gradually learn to tame the elephant, and meditation is one way to do so. Meditation has been shown to make people calmer, less reactive to the ups and downs and petty provocations of life. Meditation is the Eastern way of training yourself to take things philosophically.\nCognitive therapy works, too. In Feeling Good, a popular guide to cognitive therapy, David Burns has written a chapter on cognitive therapy for anger. He advises using many of the same techniques that Aaron Beck used for depression: Write down your thoughts, learn to recognize the distortions in your thoughts, and then think of a more appropriate thought. Burns focuses on the should statements we carry around-ideas about how the world should work, and about how people should treat us. Violations of these should statements are the major causes of anger and resentment. Burns also advises empathy: In a conflict, look at the world from your opponent\u0026rsquo;s point of view, and you\u0026rsquo;ll see that she is not entirely crazy.\nA better place to start is, as Jesus advised, with yourself and the log in your own eye. (Batson and Loewenstein both found that debiasing occurred only when subjects were forced to look at themselves.) And you will see the log only if you set out on a deliberate and effortful quest to look for it.\nWhen you first catch sight of a fault in yourself, you\u0026rsquo;ll likely hear frantic arguments from your inner lawyer excusing you and blaming others, but try not to listen. You are on a mission to find at least one thing that you did wrong. When you extract a splinter it hurts, briefly, but then you feel relief, even pleasure. When you find a fault in yourself it will hurt, briefly, but if you keep going and acknowledge the fault, you are likely to be rewarded with a flash of pleasure that is mixed, oddly, with a hint of pride. It is the pleasure of taking responsibility for your own behavior. It is the feeling of honor.\nFinding fault with yourself is also the key to overcoming the hypocrisy and judgmentalism that damage so many valuable relationships.\nThe Pursuit of Happiness  [quote]Do not seek to have events happen as you want them to, but instead want them to happen as they do happen, and your life will go well. -EPICTETUS[/quote]\n Buddhism and Stoicism teach that striving for external goods, or to make the world conform to your wishes, is always a striving after wind. Happiness can only be found within, by breaking attachments to external things and cultivating an attitude of acceptance. (Stoics and Buddhists can have relationships, jobs, and possessions, but, to avoid becoming upset upon losing them, they must not be emotionally attached to them.) This idea is of course an extension of Marcus Aurelius\u0026rsquo; quote: life itself is but what you deem it, and your mental state determines how you deem things.\nThe Progress Principle The pleasure of getting what you want is often fleeting. You dream about getting a promotion, being accepted into a prestigious school, or finishing a big project. You work every waking hour, perhaps imagining how happy you\u0026rsquo;d be if you could just achieve that goal. Then you succeed, and if you\u0026rsquo;re lucky you get an hour, maybe a day, of euphoria, particularly if your success was unexpected and there was a moment in which it was revealed (\u0026hellip; the envelope, please). More typically, however, you don\u0026rsquo;t get any euphoria. When success seems increasingly probable and some final event confirms what you already had begun to expect, the feeling is more one of relief-the pleasure of closure and release. In such circumstances, my first thought is seldom \u0026ldquo;Hooray! Fantastic!\u0026rdquo;; it is \u0026ldquo;Okay, what do I have to do now?\u0026rdquo;\nThe elephant works the same way: It feels pleasure whenever it takes a step in the right direction. The elephant learns whenever pleasure (or pain) follows immediately after behavior, but it has trouble connecting success on Friday with actions it took on Monday. Richard Davidson, the psychologist who brought us affective style and the approach circuits of the front left cortex, writes about two types of positive affect. The first he calls \u0026ldquo;pre-goal attainment positive affect,\u0026rdquo; which is the pleasurable feeling you get as you make progress toward a goal. The second is called \u0026ldquo;post-goal attainment positive affect,\u0026rdquo; which Davidson says arises once you have achieved something you want. You experience this latter feeling as contentment, as a short-lived feeling of release when the left prefrontal cortex reduces its activity after a goal has been achieved. In other words, when it comes to goal pursuit, it really is the journey that counts, not the destination. Set for yourself any goal you want. Most of the pleasure will be had along the way, with every step that takes you closer. The final moment of success is often no more thrilling than the relief of taking off a heavy backpack at the end of a long hike.\nWe can call this \u0026ldquo;the progress principle\u0026rdquo;: Pleasure comes more from making progress toward goals than from achieving them.\nThe Adaptation Principle If I gave you ten seconds to name the very best and very worst things that could ever happen to you, you might well come up with these: winning a 20-million-dollar lottery jackpot and becoming paralyzed from the neck down.\nOf course, it\u0026rsquo;s better to win the lottery than to break your neck, but not by as much as you\u0026rsquo;d think. Because whatever happens, you\u0026rsquo;re likely to adapt to it, but you don\u0026rsquo;t realize up front that you will. We are bad at \u0026ldquo;affective forecasting,\u0026rdquo; that is, predicting how we\u0026rsquo;ll feel in the future. We grossly overestimate the intensity and the duration of our emotional reactions. Within a year, lottery winners and paraplegics have both (on average) returned most of the way to their baseline levels of happiness.\nThis is the adaptation principle at work: People\u0026rsquo;s judgments about their present state are based on whether it is better or worse than the state to which they have become accustomed. Adaptation is, in part, just a property of neurons: Nerve cells respond vigorously to new stimuli, but gradually they \u0026ldquo;habituate,\u0026rdquo; firing less to stimuli that they have become used to. It is change that contains vital information, not steady states. Human beings, however, take adaptation to cognitive extremes. We don\u0026rsquo;t just habituate, we recalibrate. We create for ourselves a world of targets, and each time we hit one we replace it with another. After a string of successes we aim higher; after a massive setback, such as a broken neck, we aim lower. Instead of following Buddhist and Stoic advice to surrender attachments and let events happen, we surround ourselves with goals, hopes, and expectations, and then feel pleasure and pain in relation to our progress.\nWhen we combine the adaptation principle with the discovery that people\u0026rsquo;s average level of happiness is highly heritable, we come to a startling possibility: In the long run, it doesn\u0026rsquo;t much matter what happens to you. Good fortune or bad, you will always return to your happiness setpoint-your brain\u0026rsquo;s default level of happiness-which was determined largely by your genes.\nIf this idea is correct, then we are all stuck on what has been called the \u0026ldquo;hedonic treadmill.\u0026rdquo; On an exercise treadmill you can increase the speed all you want, but you stay in the same place. In life, you can work as hard as you want, and accumulate all the riches, fruit trees, and concubines you want, but you can\u0026rsquo;t get ahead. Because you can\u0026rsquo;t change your \u0026ldquo;natural and usual state of tranquility,\u0026rdquo; the riches you accumulate will just raise your expectations and leave you no better off than you were before. Yet, not realizing the futility of our efforts, we continue to strive, all the while doing things that help us win at the game of life. Always wanting more than we have, we run and run and run, like hamsters on a wheel.\nAn Early Happiness Hypothesis Buddha, Epictetus, and many other sages saw the futility of the rat race and urged people to quit. They proposed a particular happiness hypothesis: Happiness comes from within, and it cannot be found by making the world conform to your desires.\nBoth doctrines are based on an empirical claim, a happiness hypothesis that asserts that striving to obtain goods and goals in the external world cannot bring you more than momentary happiness. You must work on your internal world. If the hypothesis is true, it has profound implications for how we should live our lives, raise our children, and spend our money. But is it true? It all depends on what kind of externals we are talking about.\nThe second biggest finding in happiness research, after the strong influence of genes upon a person\u0026rsquo;s average level of happiness, is that most environmental and demographic factors influence happiness very little.\nA good marriage is one of the life-factors most strongly and consistently associated with happiness. Part of this apparent benefit comes from \u0026ldquo;reverse correlation\u0026rdquo;: Happiness causes marriage. Happy people marry sooner and stay married longer than people with a lower happiness setpoint, both because they are more appealing as dating partners and because they are easier to live with as spouses.\nWhite Americans are freed from many of the hassles and indignities that affect black Americans, yet, on average, they are only very slightly happier. Men have more freedom and power than women, yet they are not on average any happier. The young have so much more to look forward to than the elderly, yet ratings of life satisfaction actually rise slightly with age, up to age sixty-five, and, in some studies, well beyond. People are often surprised to hear that the old are happier than the young because the old have so many more health problems, yet people adapt to most chronic health problems. People who live in cold climates expect people who live in California to be happier, but they are wrong. People believe that attractive people are happier than unattractive people, but they, too, are wrong.\nThe most widely reported conclusion, from surveys done by psychologist Ed Diener, is that within any given country, at the lowest end of the income scale money does buy happiness: People who worry every day about paying for food and shelter report significantly less well-being than those who don\u0026rsquo;t. But once you are freed from basic needs and have entered the middle class, the relationship between wealth and happiness becomes smaller. The rich are happier on average than the middle class, but only by a little, and part of this relationship is reverse correlation: Happy people grow rich faster because, as in the marriage market, they are more appealing to others (such as bosses), and also because their frequent positive emotions help them to commit to projects, to work hard, and to invest in their futures. Wealth itself has only a small direct effect on happiness because it so effectively speeds up the hedonic treadmill.\nThe Happiness Formula In the 1990s, the two big findings of happiness research (strong relation to genes, weak relation to environment) hit the psychological community hard, because they applied not just to happiness but to most aspects of personality.\nAs psychologists wrestled with these ideas, however, and as biologists worked out the first sketch of the human genome, a more sophisticated understanding of nature and nurture began to emerge. Yes, genes explain far more about us than anyone had realized, but the genes themselves often turn out to be sensitive to environmental conditions. And yes, each person has a characteristic level of happiness, but it now looks as though it\u0026rsquo;s not so much a set point as a potential range or probability distribution. Whether you operate on the high or the low side of your potential range is determined by many factors that Buddha and Epictetus would have considered externals.\nThree psychologists, Sonja Lyubomirsky, Ken Sheldon, and David Schkade, reviewed the available evidence and realized that there are two fundamentally different kinds of externals: the conditions of your life and the voluntary activities that you undertake. Conditions include facts about your life that you can\u0026rsquo;t change (race, sex, age, disability) as well as things that you can (wealth, marital status, where you live). Conditions are constant over time, at least during a period in your life, and so they are the sorts of things that you are likely to adapt to. Voluntary activities, on the other hand, are the things that you choose to do, such as meditation, exercise, learning a new skill, or taking a vacation. Because such activities must be chosen, and because most of them take effort and attention, they can\u0026rsquo;t just disappear from your awareness the way conditions can. Voluntary activities, therefore, offer much greater promise for increasing happiness while avoiding adaptation effects.\nOne of the most important ideas in positive psychology is what Lyubomirsky, Sheldon, Schkade, and Seligman call the \u0026ldquo;happiness formula:\u0026rdquo; H = S + C + V\nThe level of happiness that you actually experience (H) is determined by your biological set point (S) plus the conditions of your life \u0026copy; plus the voluntary activities (V) you do.\nIt turns out that there really are some external conditions \u0026copy; that matter. There are some changes you can make in your life that are not fully subject to the adaptation principle, and that might make you lastingly happier. It may be worth striving to achieve them.\n#Noise. Research shows that people who must adapt to new and chronic sources of noise (such as when a new highway is built) never fully adapt, and even studies that find some adaptation still find evidence of impairment on cognitive tasks. Noise, especially noise that is variable or intermittent, interferes with concentration and increases stress. It\u0026rsquo;s worth striving to remove sources of noise in your life.\n#Commuting. Many people choose to move farther away from their jobs in search of a larger house. But although people quickly adapt to having more space, they don\u0026rsquo;t fully adapt to the longer commute, particularly if it involves driving in heavy traffic. Even after years of commuting, those whose commutes are traffic-filled still arrive at work with higher levels of stress hormones. (Driving under ideal conditions is, however, often enjoyable and relaxing.) It\u0026rsquo;s worth striving to improve your commute.\n#Lack of control. One of the active ingredients of noise and traffic, the aspect that helps them get under your skin, is that you can\u0026rsquo;t control them. Changing an institution\u0026rsquo;s environment to increase the sense of control among its workers, students, patients, or other users was one of the most effective possible ways to increase their sense of engagement, energy, and happiness.\n#Shame. Overall, attractive people are not happier than unattractive ones. Yet, surprisingly, some improvements in a person\u0026rsquo;s appearance do lead to lasting increases in happiness. People who undergo plastic surgery report (on average) high levels of satisfaction with the process, and they even report increases in the quality of their lives and decreases in psychiatric symptoms (such as depression and anxiety) in the years after the operation.\n#Relationships. The condition that is usually said to trump all others in importance is the strength and number of a person\u0026rsquo;s relationships. Good relationships make people happy, and happy people enjoy more and better relationships than unhappy people.\nThere are many other ways in which you can increase your happiness by getting the conditions of your life right, particularly in relationships, work, and the degree of control you have over stressors. So in the happiness formula, C is real and some externals matter. Some things are worth striving for, and positive psychology can help identify them.\nFinding Flow Not all action, however, will work. Chasing after wealth and prestige, for example, will usually backfire. People who report the greatest interest in attaining money, fame, or beauty are consistently found to be less happy, and even less healthy, than those who pursue less materialistic goals. So what is the right kind of activity? What is V in the happiness formula?\nThe tool that helped psychologists answer that question is the \u0026ldquo;experience sampling method,\u0026rdquo; invented by Mihalyi Csikszentmihalyi (pronounced \u0026ldquo;cheeks sent me high\u0026rdquo;), the Hungarian-born cofounder of positive psychology.\nCsikszentmihalyi\u0026rsquo;s big discovery is that there is a state many people value even more than chocolate after sex. It is the state of total immersion in a task that is challenging yet closely matched to one\u0026rsquo;s abilities. It is what people sometimes call \u0026ldquo;being in the zone.\u0026rdquo; Csikszentmihalyi called it \u0026ldquo;flow\u0026rdquo; because it often feels like effortless movement: Flow happens, and you go with it.\nThe keys to flow: There\u0026rsquo;s a clear challenge that fully engages your attention; you have the skills to meet the challenge; and you get immediate feedback about how you are doing at each step (the progress principle). You get flash after flash of positive feeling with each turn negotiated, each high note correctly sung, or each brushstroke that falls into the right place. In the flow experience, elephant and rider are in perfect harmony. The elephant (automatic processes) is doing most of the work, running smoothly through the forest, while the rider (conscious thought) is completely absorbed in looking out for problems and opportunities, helping wherever he can.\nDrawing on Csikszentmihalyi\u0026rsquo;s work, Seligman proposes a fundamental distinction between pleasures and gratifications. Pleasures are \u0026ldquo;delights that have clear sensory and strong emotional components,\u0026rdquo; such as may be derived from food, sex, backrubs, and cool breezes. Gratifications are activities that engage you fully, draw on your strengths, and allow you to lose self-consciousness. Gratifications can lead to flow. Seligman proposes that V (voluntary activities) is largely a matter of arranging your day and your environment to increase both pleasures and gratifications. Pleasures must be spaced to maintain their potency. Here\u0026rsquo;s where the rider has an important role to play: Because the elephant has a tendency to overindulge, the rider needs to encourage it to get up and move on to another activity.\nPleasures should be both savored and varied.\nOne reason for the widespread philosophical wariness of sensual pleasure is that it gives no lasting benefit. Pleasure feels good in the moment, but sensual memories fade quickly, and the person is no wiser or stronger afterwards. But gratifications are different. Gratifications ask more of us; they challenge us and make us extend ourselves. Gratifications often come from accomplishing something, learning something, or improving something. When we enter a state of flow, hard work becomes effortless. We want to keep exerting ourselves, honing our skills, using our strengths. Seligman suggests that the key to finding your own gratifications is to know your own strengths.\nSo V (voluntary activity) is real, and it\u0026rsquo;s not just about detachment. You can increase your happiness if you use your strengths, particularly in the service of strengthening connections-helping friends, expressing gratitude to benefactors.\nMisguided Pursuits In his more recent book, Luxury Fever, Frank used the same approach to understand another kind of irrationality: the vigor with which people pursue many goals that work against their own happiness. Frank wants to know why people are so devoted to spending money on luxuries and other goods, to which they adapt completely, rather than on things that would make them lastingly happier. People would be happier, and in the long run wealthier, if they bought basic, functional appliances, automobiles, and wristwatches, and invested the money they saved for future consumption.\nFrank\u0026rsquo;s explanation is simple: Conspicuous and inconspicuous consumption follow different psychological rules. Conspicuous consumption refers to things that are visible to others and that are taken as markers of a person\u0026rsquo;s relative success. Conspicuous consumption is a zero-sum game: Each person\u0026rsquo;s move up devalues the possessions of others.\nInconspicuous consumption, on the other hand, refers to goods and activities that are valued for themselves, that are usually consumed more privately, and that are not bought for the purpose of achieving status. Because Americans, at least, gain no prestige from taking the longest vacations or having the shortest commutes, these inconspicuous consumables are not subject to an arms race.\nStop trying to keep up with the Joneses. Stop wasting your money on conspicuous consumption. As a first step, work less, earn less, accumulate less, and \u0026ldquo;consume\u0026rdquo; more family time, vacations, and other enjoyable activities.\nThe Happiness Hypothesis Reconsidered Many Western thinkers have looked at the same afflictions as Buddha-sickness, aging, and mortality-and come to a very different conclusion from his: Through passionate attachments to people, goals, and pleasures, life must be lived to the fullest. I once heard a talk by the philosopher Robert Solomon, who directly challenged the philosophy of nonattachment as an affront to human nature. The life of cerebral reflection and emotional indifference (apatheia) advocated by many Greek and Roman philosophers and that of calm nonstriving advocated by Buddha are lives designed to avoid passion, and a life without passion is not a human life. Yes, attachments bring pain, but they also bring our greatest joys, and there is value in the very variation that the philosophers are trying to avoid.\nBuddha, Lao Tzu, and other sages of the East discovered a path to peace and tranquility, the path of letting go. They told us how to follow the path using meditation and stillness. Millions of people in the West have followed, and although few, if any, have reached Nirvana, many have found some degree of peace, happiness, and spiritual growth. So I do not mean to question the value or relevance of Buddhism in the modern world, or the importance of working on yourself in an effort to find happiness. Rather, I would like to suggest that the happiness hypothesis be extended-for now-into a yin-yang formulation: Happiness comes from within, and happiness comes from without.\nLove and Attachments  [quote]No one can live happily who has regard to himself alone and transforms everything into a question of his own utility; you must live for your neighbour, if you would live for yourself. -SENECA[/quote]\n[quote]No man is an island, entire of itself; every man is a piece of the continent, a part of the main. -JOHN DONNE[/quote]\n The heroes of this story are two psychologists who rejected the central tenets of their training: Harry Harlow and John Bowlby. These two men knew that something was missing in behaviorism and in psychoanalysis, respectively. Against great odds they changed their fields, they humanized the treatment of children, and they made it possible for science to greatly improve upon the wisdom of the ancients.\nLove Conquers Fears Bowlby\u0026rsquo;s grand synthesis is called attachment theory. It borrows from the science of cybernetics-the study of how mechanical and biological systems can regulate themselves to achieve preset goals while the environment around and inside them changes. Bowlby\u0026rsquo;s first metaphor was the simplest cybernetic system of all-a thermostat that turns on a heater when the temperature drops below a set point.\nAttachment theory begins with the idea that two basic goals guide children\u0026rsquo;s behavior: safety and exploration. A child who stays safe survives; a child who explores and plays develops the skills and intelligence needed for adult life. (This is why all mammal babies play; and the larger their frontal cortex, the more they need to play). These two needs are often opposed, however, so they are regulated by a kind of thermostat that monitors the level of ambient safety. When the safety level is adequate, the child plays and explores. But as soon as it drops too low, it\u0026rsquo;s as though a switch were thrown and suddenly safety needs become paramount. The child stops playing and moves toward mom. If mom is unreachable, the child cries, and with increasing desperation; when mom returns, the child seeks touch, or some other reassurance, before the system can reset and play can resume. This is an instance of the \u0026ldquo;design\u0026rdquo; principle: opposing systems push against each other to reach a balance point.\nWhen children are separated from their attachment figures for a long time, as in a hospital stay, they quickly descend into passivity and despair. When they are denied a stable and enduring attachment relationship (raised, for example, by a succession of foster parents or nurses), they are likely to be damaged for life, Bowlby said. They might become the aloof loners or hopeless clingers that Bowlby had seen in his volunteer work. Bowlby\u0026rsquo;s theory directly contradicted Watson as well as the Freuds (Sigmund and Anna): If you want your children to grow up to be healthy and independent, you should hold them, hug them, cuddle them, and love them. Give them a secure base and they will explore and then conquer the world on their own.\nDoes adult romantic love really grow out of the same psychological system that attaches children to their mothers? To find out, Hazan traced the process by which childhood attachment changes with age. Bowlby had been specific about the four defining features of attachment relationships:\n proximity maintenance (the child wants and strives to be near the parent) separation distress (self-explanatory) safe haven (the child, when frightened or distressed, comes to the parent for comfort) secure base (the child uses the parent as a base from which to launch exploration and personal growth)  Evidence that romantic partners become true attachment figures, like parents, comes from a review of research on how people cope with the death of a spouse, or a long separation. The review found that adults experience the same sequence Bowlby had observed in children placed in hospitals: initial anxiety and panic, followed by lethargy and depression, followed by recovery through emotional detachment. Furthermore, the review found that contact with close friends was of little help in blunting the pain, but renewed contact with one\u0026rsquo;s parents was much more effective.\nOnce you think about it, the similarities between romantic relationships and parent-infant relationships are obvious. Lovers in the first rush of love spend endless hours in face-to-face mutual gaze, holding each other, nuzzling and cuddling, kissing, using baby voices, and enjoying the same release of the hormone oxytocin that binds mothers and babies to each other in a kind of addiction. Oxytocin prepares female mammals to give birth (triggering uterine contractions and milk release), but it also affects their brains, fostering nurturant behaviors and reducing feelings of stress when mothers are in contact with their children.\nWhen oxytocin floods the brain (male or female) while two people are in skin-to-skin contact, the effect is soothing and calming, and it strengthens the bond between them. For adults, the biggest rush of oxytocin-other than giving birth and nursing-comes from sex. Sexual activity, especially if it includes cuddling, extended touching, and orgasm, turns on many of the same circuits that are used to bond infants and parents. It\u0026rsquo;s no wonder that childhood attachment styles persist in adulthood: The whole attachment system persists.\nLove and the Swelled Head Adult love relationships are therefore built out of two ancient and interlocking systems: an attachment system that bonds child to mother and a caregiving system that bonds mother to child. The \u0026ldquo;mating system\u0026rdquo; is completely separate from the other two systems, and it involves distinctive brain areas and hormones.\nThe Differences between Passionate and Companionate Love Take one ancient attachment system, mix with an equal measureof caregiving system, throw in a modified mating system and voila, that\u0026rsquo;s romantic love.\nAs I see it, the modern myth of true love involves these beliefs: True love is passionate love that never fades; if you are in true love, you should marry that person; if love ends, you should leave that person because it was not true love; and if you can find the right person, you will have true love forever. You might not believe this myth yourself, particularly if you are older than thirty; but many young people in Western nations are raised on it, and it acts as an ideal that they unconsciously carry with them even if they scoff at it.\nBut if true love is defined as eternal passion, it is biologically impossible. To see this, and to save the dignity of love, you have to understand the difference between two kinds of love: passionate and companionate. According to the love researchers Ellen Berscheid and Elaine Walster, passionate love is a \u0026ldquo;wildly emotional state in which tender and sexual feelings, elation and pain, anxiety and relief, altruism and jealousy coexist in a confusion of feelings.\u0026rdquo; Passionate love is the love you fall into.\nBerscheid and Walster define companionate love, in contrast, as \u0026ldquo;the affection we feel for those with whom our lives are deeply intertwined.\u0026rdquo; Companionate love grows slowly over the years as lovers apply their attachment and caregiving systems to each other, and as they begin to rely upon, care for, and trust each other. If the metaphor for passionate love is fire, the metaphor for companionate love is vines growing, intertwining, and gradually binding two people together.\nSo if passionate love is a drug-literally a drug-it has to wear off eventually.\nPassionate love does not turn into companionate love. Passionate love and companionate love are two separate processes, and they have different time courses. Their diverging paths produce two danger points, two places where many people make grave mistakes. In the figure below, I\u0026rsquo;ve drawn out how the intensity of passionate and companionate love might vary in one person\u0026rsquo;s relationship over the course of six months. Passionate love ignites, it burns, and it can reach its maximum temperature within days. During its weeks or months of madness, lovers can\u0026rsquo;t help but think about marriage, and often they talk about it, too. Sometimes they even accept Hephaestus\u0026rsquo;s offer and commit to marriage. This is often a mistake. Nobody can think straight when high on passionate love. The rider is as besotted as the elephant.\nThe other danger point is the day the drug weakens its grip. Passionate love doesn\u0026rsquo;t end on that day, but the crazy and obsessional high period does. The rider regains his senses and can, for the first time, assess where the elephant has taken them. Breakups often happen at this point, and for many couples that\u0026rsquo;s a good thing.\nBut sometimes breaking up is premature, because if the lovers had stuck it out, if they had given companionate love a chance to grow, they might have found true love. True love exists, I believe, but it is not-cannot be-passion that lasts forever. True love, the love that undergirds strong marriages, is simply strong companionate love, with some added passion, between two people who are firmly committed to each other.\nIf we change the time scale from six months to sixty years, as in the next figure, it is passionate love that seems trivial-a flash in the pan-while companionate love can last a lifetime.\nWhy Do Philosophers Hate Love? If you are in passionate love and want to celebrate your passion, read poetry. If your ardor has calmed and you want to understand your evolving relationship, read psychology. But if you have just ended a relationship and would like to believe you are better off without love, read philosophy.\nThere are several reasons why real human love might make philosophers uncomfortable. First, passionate love is notorious for making people illogical and irrational, and Western philosophers have long thought that morality is grounded in rationality. Love is a kind of insanity, and many people have, while crazed with passion, ruined their lives and those of others.\nI think, however, that at least two less benevolent motivations are at work. First, there may be a kind of hypocritical self-interest in which the older generation says, \u0026ldquo;Do as we say, not as we did.\u0026rdquo; Buddha and St. Augustine, for example, drank their fill of passionate love as young men and came out only much later as opponents of sexual attachments. Moral codes are designed to keep order within society; they urge us to rein in our desires and play our assigned roles. Romantic love is notorious for making young people give less than a damn about the rules and conventions of their society, about caste lines, or about feuds between Capulets and Montagues. So the sages\u0026rsquo; constant attempts to redefine love as something spiritual and prosocial sound to me like the moralism of parents who, having enjoyed a variety of love affairs when they were young, now try to explain to their daughter why she should save herself for marriage.\nA second motivation is the fear of death. The extensive regulation of sex in many cultures, the attempt to link love to God and then to cut away the sex, is part of an elaborate defense against the gnawing fear of mortality.\nIf this is true, if the sages have a variety of unstated reasons for warning us away from passionate love and attachments of many kinds, perhaps we should be selective in heeding their advice. Perhaps we need to look at our own lives, lived in a world very different from theirs, and also at the evidence about whether attachments are good or bad for us.\nFreedom Can Be Dangerous to Your Health In the late nineteenth century, one of the founders of sociology, Emile Durkheim, performed a scholarly miracle. He gathered data from across Europe to study the factors that affect the suicide rate. His findings can be summarized in one word: constraints. No matter how he parsed the data, people who had fewer social constraints, bonds, and obligations were more likely to kill themselves. Durkheim concluded that people need obligations and constraints to provide structure and meaning to their lives:\nA hundred years of further studies have confirmed Durkheim\u0026rsquo;s diagnosis. If you want to predict how happy someone is, or how long she will live (and if you are not allowed to ask about her genes or personality), you should find out about her social relationships. Having strong social relationships strengthens the immune system, extends life (more than does quitting smoking), speeds recovery from surgery, and reduces the risks of depression and anxiety disorders.\nAn ideology of extreme personal freedom can be dangerous because it encourages people to leave homes, jobs, cities, and marriages in search of personal and professional fulfillment, thereby breaking the relationships that were probably their best hope for such fulfillment.\nJohn Donne was right: No man, woman, or child is an island. Aristophanes was right: We need others to complete us. We are an ultrasocial species, full of emotions finely tuned for loving, befriending, helping, sharing, and otherwise intertwining our lives with others. Attachments and relationships can bring us pain: As a character in Jean-Paul Sartre\u0026rsquo;s play No Exit said, \u0026ldquo;Hell is other people.\u0026rdquo; But so is heaven.\nThe Adversity Hypothesis  [quote]What doesn\u0026rsquo;t kill me makes me stronger. -NIETSZCHE[/quote]\n The \u0026ldquo;adversity hypothesis,\u0026rdquo; which says that people need adversity, setbacks, and perhaps even trauma to reach the highest levels of strength, fulfillment, and personal development.\nFifty years of research on stress shows that stressors are generally bad for people, contributing to depression, anxiety disorders, and heart disease. So let\u0026rsquo;s be cautious about accepting the adversity hypothesis.\nPost Traumatic Growth For decades, research in health psychology focused on stress and its damaging effects. A major concern in this research literature has always been resilience-the ways people cope with adversity, fend off damage, and \u0026ldquo;bounce back\u0026rdquo; to normal functioning. But it\u0026rsquo;s only in the last fifteen years that researchers have gone beyond resilience and begun to focus on the benefits of severe stress. These benefits are sometimes referred to collectively as \u0026ldquo;posttraumatic growth,\u0026rdquo; in direct contrast to posttraumatic stress disorder.\nThis large body of research shows that although traumas, crises, and tragedies come in a thousand forms, people benefit from them in three primary ways-the\nThe first benefit is that rising to a challenge reveals your hidden abilities, and seeing these abilities changes your self-concept. None of us knows what we are really capable of enduring.\nOne of the most common lessons people draw from bereavement or trauma is that they are much stronger than they realized, and this new appreciation of their strength then gives them confidence to face future challenges. And they are not just confabulating a silver lining to wrap around a dark cloud; people who have suffered through battle, rape, concentration camps, or traumatic personal losses often seem to be inoculated 7 against future stress: They recover more quickly, in part because they know they can cope. Religious leaders have often pointed to exactly this benefit of suffering. As Paul said in his Letter to the Romans (5:3-4): \u0026ldquo;Suffering produces endurance, and endurance produces character, and character produces hope.\u0026rdquo;\nThe second class of benefit concerns relationships. Adversity is a filter. When a person is diagnosed with cancer, or a couple loses a child, some friends and family members rise to the occasion and look for any way they can to express support or to be helpful. Others turn away, perhaps unsure of what to say or unable to overcome their own discomfort with the situation. But adversity doesn\u0026rsquo;t just separate the fair-weather friends from the true; it strengthens relationships and it opens people\u0026rsquo;s hearts to one another. We often develop love for those we care for, and we usually feel love and gratitude toward those who cared for us in a time of need.\nThis change in ways of relating points to the third common benefit: Trauma changes priorities and philosophies toward the present (\u0026ldquo;Live each day to the fullest\u0026rdquo;) and toward other people.\nThe Adversity Hypothesis Versions The adversity hypothesis has a weak and a strong version. In the weak version, adversity can lead to growth, strength, joy, and self-improvement, by the three mechanisms of posttraumatic growth described above. The weak version is well-supported by research, but it has few clear implications for how we should live our lives. The strong version of the hypothesis is more unsettling: It states that people must endure adversity to grow, and that the highest levels of growth and development are only open to those who have faced and overcome great adversity. If the strong version of the hypothesis is valid, it has profound implications for how we should live our lives and structure our societies. It means that we should take more chances and suffer more defeats.\nBut is the strong version valid? People often say that they have been profoundly changed by adversity, yet researchers have so far collected little evidence of adversity-induced personality change beyond such reports. People\u0026rsquo;s scores on personality tests are fairly stable over the course of a few years, even for people who report that they have changed a great deal in the interim.\nThese studies might, however, have been looking for change in the wrong place. Psychologists often approach personality by measuring basic traits such as the \u0026ldquo;big five\u0026rdquo;: neuroticism, extroversion, openness to new experiences, agreeableness (warmth/niceness), and conscientiousness. These traits are facts about the elephant, about a person\u0026rsquo;s automatic reactions to various situations.\nPsychologist Dan McAdams has suggested that personality really has three levels, and too much attention has been paid to the lowest level, the basic traits. A second level of personality, \u0026ldquo;characteristic adaptations,\u0026rdquo; includes personal goals, defense and coping mechanisms, values, beliefs, and life-stage concerns (such as those of parenthood or retirement) that people develop to succeed in their particular roles and niches. In this middle level, the person\u0026rsquo;s basic traits are made to mesh with facts about the person\u0026rsquo;s environment and stage of life. When those facts change-as after losing a spouse-the person\u0026rsquo;s characteristic adaptations change.\nThe third level of personality is that of the \u0026ldquo;life story.\u0026rdquo; Although the lowest level of personality is mostly about the elephant, the life story is written primarily by the rider. You create your story in consciousness as you interpret your own behavior, and as you listen to other people\u0026rsquo;s thoughts about you.\nFrom this three-level perspective, it becomes clear why adversity might be necessary for optimal human development. Most of the life goals that people pursue at the level of \u0026ldquo;characteristic adaptations\u0026rdquo; can be sorted-as the psychologist Robert Emmons has found-into four categories: work and achievement, relationships and intimacy, religion and spirituality, and generativity (leaving a legacy and contributing something to society). Although it is generally good for you to pursue goals, not all goals are equal. People who strive primarily for achievement and wealth are, Emmons finds, less happy, on average, than those whose strivings focus on the other three categories. The reason takes us back to happiness traps and conspicuous consumption: Because human beings were shaped by evolutionary processes to pursue success, not happiness, people enthusiastically pursue goals that will help them win prestige in zero-sum competitions. Success in these competitions feels good but gives no lasting pleasure, and it raises the bar for future success.\nAdversity may be necessary for growth because it forces you to stop speeding along the road of life, allowing you to notice the paths that were branching off all along, and to think about where you really want to end up.\nMcAdams\u0026rsquo;s ideas are profoundly important for understanding posttraumatic growth. His three levels of personality allow us to think about coherence among the levels. What happens when the three levels of personality don\u0026rsquo;t match up?\nThe psychologists Ken Sheldon and Tim Kasser have found that people who are mentally healthy and happy have a higher degree of \u0026ldquo;vertical coherence\u0026rdquo; among their goals-that is, higher-level (long term) goals and lower-level (immediate) goals all fit together well so that pursuing one\u0026rsquo;s short-term goals advances the pursuit of long-term goals.\nWhen people report having grown after coping with adversity, they could be trying to describe a new sense of inner coherence. This coherence might not be visible to one\u0026rsquo;s friends, but it feels like growth, strength, maturity, and wisdom from the inside.\nHow to Benefit from Adversity Psychologists have devoted a great deal of effort to figuring out who benefits from trauma and who is crushed. The answer compounds the already great unfairness of life: Optimists are more likely to benefit than pessimists. Optimists are, for the most part, people who won the cortical lottery: They have a high happiness setpoint, they habitually look on the bright side, and they easily find silver linings. Life has a way of making the rich get richer and the happy get happier.\nWhen a crisis strikes, people cope in three primary ways: active coping (taking direct action to fix the problem), reappraisal (doing the work within-getting one\u0026rsquo;s own thoughts right and looking for silver linings), and avoidance coping (working to blunt one\u0026rsquo;s emotional reactions by denying or avoiding the events, or by drinking, drugs, and other distractions). People who have a basic-level trait of optimism (McAdams\u0026rsquo;s level 1) tend to develop a coping style (McAdams\u0026rsquo;s level 2) that alternates between active coping and reappraisal. Because optimists expect their efforts to pay off, they go right to work fixing the problem. But if they fail, they expect that things usually work out for the best, and so they can\u0026rsquo;t help but look for possible benefits. When they find them, they write a new chapter in their life story (McAdams\u0026rsquo;s level 3), a story of continual overcoming and growth. In contrast, people who have a relatively negative affective style (complete with more activity in the front right cortex than the front left) live in a world filled with many more threats and have less confidence that they can deal with them. They develop a coping style that relies more heavily on avoidance and other defense mechanisms. They work harder to manage their pain than to fix their problems, so their problems often get worse. Drawing the lesson that the world is unjust and uncontrollable, and that things often work out for the worst, they weave this lesson into their life story where it contaminates the narrative.\nAnyone, therefore, can benefit from adversity, although a pessimist will have to take some extra steps, some conscious, rider-initiated steps, to guide the elephant gently in the right direction. The first step is to do what you can, before adversity strikes, to change your cognitive style. If you are a pessimist, consider meditation, cognitive therapy, or even Prozac.\nThe second step is to cherish and build your social support network. Having one or two good attachment relationships helps adults as well as children (and rhesus monkeys) to face threats. Trusted friends who are good listeners can be a great aid to making sense and finding meaning. Third, religious faith and practice can aid growth, both by directly fostering sense making (religions provide stories and interpretive schemes for losses and crises) and by increasing social support (religious people have relationships through their religious communities, and many have a relationship with God).\nAnd finally, no matter how well or poorly prepared you are when trouble strikes, at some point in the months afterwards, pull out a piece of paper and start writing. Write about what happened, how you feel about it, and why you feel that way. Before you conclude your last session, be sure you have done your best to answer these two questions: Why did this happen? What good might I derive from it?\nThe Limits of Adversity There is, however, a time limit on first adversity. Elder says that life starts to \u0026ldquo;crystallize\u0026rdquo; by the late twenties. Even young men who had not been doing well before serving in World War II often turned their lives around afterward, but people who faced their first real life test after the age of thirty (for example, combat in that war, or financial ruin in the Great Depression) were less resilient and less likely to grow from their experiences. So adversity may be most beneficial for people in their late teens and into their twenties.\nThe Growth of Wisdom Marcel Proust said:\n [quote]We do not receive wisdom, we must discover it for ourselves, after a journey through the wilderness which no one else can make for us, which no one can spare us, for our wisdom is the point of view from which we come at last to regard the world.[/quote]\n Recent research on wisdom proves Proust correct. Knowledge comes in two major forms: explicit and tacit. Explicit knowledge is all the facts you know and can consciously report, independent of context. Wherever I am, I know that the capital of Bulgaria is Sofia. Explicit knowledge is taught directly in schools. The rider gathers it up and files it away, ready for use in later reasoning. But wisdom is based-according to Robert Sternberg, a leading wisdom researcher-on \u0026ldquo;tacit knowledge.\u0026rdquo; Tacit knowledge is procedural (it\u0026rsquo;s \u0026ldquo;knowing how\u0026rdquo; rather than \u0026ldquo;knowing that\u0026rdquo;), it is acquired without direct help from others, and it is related to goals that a person values. Tacit knowledge resides in the elephant. It\u0026rsquo;s the skills that the elephant acquires, gradually, from life experience. It depends on context: There is no universal set of best practices for ending a romantic relationship, consoling a friend, or resolving a moral disagreement.\nPosttraumatic growth usually involves, therefore, the growth of wisdom.\nThe strong version of the adversity hypothesis might be true, but only if we add caveats: For adversity to be maximally beneficial, it should happen at the right time (young adulthood), to the right people (those with the social and psychological resources to rise to challenges and find benefits), and to the right degree (not so severe as to cause PTSD).\nThe Virtue Hypothesis  [quote]Set your heart on doing good. Do it over and over again, and you will be filled with joy. A fool is happy until his mischief turns against him. And a good man may suffer until his goodness flowers. -BUDDHA[/quote]\n The \u0026ldquo;virtue hypothesis,\u0026rdquo; is the same claim made by Epicurus and the Buddha in the epigraphs that open this chapter: Cultivating virtue will make you happy. There are plenty of reasons to doubt the virtue hypothesis.\nPerhaps the virtue hypothesis will turn out to be true only in a cynical, Machiavellian way: Cultivating the appearance of virtue will make you successful, and therefore happy, regardless of your true character.\nThe Virtues Of The Ancients Every culture is concerned about the moral development of its children, and in every culture that left us more than a few pages of writing, we find texts that reveal its approach to morality. Specific rules and prohibitions vary, but the broad outlines of these approaches have a lot in common. Most cultures wrote about virtues that should be cultivated, and many of those virtues were and still are valued across most cultures (for example, honesty, justice, courage, benevolence, selfestraint, and respect for authority). Most approaches then specified actions that were good and bad with respect to those virtues. Most approaches were practical, striving to inculcate virtues that would benefit the person who cultivates them.\nAn additional common feature is that these ancient texts rely heavily on maxims and role models rather than proofs and logic. Maxims are carefully phrased to produce a flash of insight and approval. Role models are presented to elicit admiration and awe. When moral instruction triggers emotions, it speaks to the elephant as well as the rider.\nA third feature of many ancient texts is that they emphasize practice and habit rather than factual knowledge. Confucius compared moral development to learning how to play music; both require the study of texts, observance of role models, and many years of practice to develop \u0026ldquo;virtuosity.\u0026rdquo; Aristotle used a similar metaphor:\n [quote]Men become builders by building houses, and harpists by playing the harp. Similarly, we grow just by the practice of just actions, self-controlled by exercising our self-control, and courageous by performing acts of courage.[/quote]\n The Virtues Of Positive Psychology In 1998, Martin Seligman founded positive psychology when he asserted that psychology had lost its way. Psychology had become obsessed with pathology and the dark side of human nature, blind to all that was good and noble in people.\nWhen Seligman launched positive psychology, one of his first goals was to create a diagnostic manual for the strengths and virtues. He and another psychologist, Chris Peterson of the University of Michigan, set out to construct a list of the strengths and virtues, one that might be valid for any human culture. I argued with them that the list did not have to be valid for all cultures to be useful; they should focus just on large-scale industrial societies.\nAs a first step, Peterson and Seligman surveyed every list of virtues they could find, from the holy books of major religions down to the Boy Scout Oath (\u0026ldquo;trustworthy, loyal, helpful, friendly \u0026hellip; \u0026ldquo;). They made large tables of virtues and tried to see which ones were common across lists. Although no specific virtue made every list, six broad virtues, or families of related virtues, appeared on nearly all lists: wisdom, courage, humanity, justice, temperance, and transcendence (the ability to forge connections to something larger than the self).\nBut the real value of the list of six is that it serves as an organizing framework for more specific strengths of character. Peterson and Seligman define character strengths as specific ways of displaying, practicing, and cultivating the virtues. Several paths lead to each virtue. People, as well as cultures, vary in the degree to which they value each path. This is the real power of the classification: It points to specific means of growth toward widely valued ends without insisting that any one way is mandatory for all people at all times. The classification is a tool for diagnosing people\u0026rsquo;s diverse strengths and for helping them find ways to cultivate excellence.\nPeterson and Seligman suggest that there are twenty-four principle character strengths, each leading to one of the six higher-level virtues.\n Wisdom: Curiosity Love of learning Judgment Ingenuity Emotional intelligence Perspective Courage: Valor Perseverance Integrity Humanity: Kindness Loving Justice: Citizenship Fairness Leadership Temperance: Self-control Prudence Humility Transcendence: Appreciation of beauty and excellence Gratitude Hope Spirituality Forgiveness Humor Zest  The genius of Peterson and Seligman\u0026rsquo;s classification is to get the conversation going, to propose a specific list of strengths and virtues, and then let the scientific and therapeutic communities work out the details.\nVirtue sounds like hard work, and often is. But when virtues are re-conceived as excellences, each of which can be achieved by the practice of several strengths of character, and when the practice of these strengths is often intrinsically rewarding, suddenly the work sounds more like Csikszentmihalyi\u0026rsquo;s flow and less like toil. It\u0026rsquo;s work that-like Seligman\u0026rsquo;s description of gratifications-engages you fully, draws on your strengths, and allows you to lose self-consciousness and immerse yourself in what you are doing.\nThe Future Of Virtue Should we in the West try to return to a more virtue-based morality?\nMy colleague at the University of Virginia, the sociologist James Hunter, traces out how America lost its older ideas about virtue and character. Before the Industrial Revolution, Americans honored the virtues of \u0026ldquo;producers\u0026rdquo;-hard work, selfestraint, sacrifice for the future, and sacrifice for the common good. But during the twentieth century, as people became wealthier and the producer society turned gradually into the mass consumption society, an alternative vision of the self arose-a vision centered on the idea of individual preferences and personal fulfillment. The intrinsically moral term \u0026ldquo;character\u0026rdquo; fell out of favor and was replaced by the amoral term \u0026ldquo;personality.\u0026rdquo;\nHunter points to a second cause of character\u0026rsquo;s death: inclusiveness. The first American colonists created enclaves of ethnic, religious, and moral homogeneity, but the history of America ever since has been one of increasing diversity. In response, educators have struggled to identify the ever-shrinking set of moral ideas everyone could agree upon.\nWe have paid a price for our inclusiveness, but we have bought ourselves a more humane society, with greater opportunity for racial minorities, women, gay people, the handicapped, and others-that is, for most people. And even if some people think the price was too steep, we can\u0026rsquo;t go back, either to a pre-consumer society or to ethnically homogeneous enclaves.\nBeing neither a sociologist nor an expert in education policy, I will not try to design a radical new approach to moral education. Instead, I will present one finding from my own research on diversity.\nGiven how easy it is to divide people into hostile groups based on trivial differences, I wondered whether celebrating diversity might also encourage division, whereas celebrating commonality would help people form cohesive groups and communities. I quickly realized that there are two main kinds of diversity-demographic and moral. Demographic diversity is about socio-demographic categories such as race, ethnicity, sex, sexual orientation, age, and handicapped status. Calling for demographic diversity is in large measure calling for justice, for the inclusion of previously excluded groups. Moral diversity, on the other hand, is essentially what Durkheim described as anomie: a lack of consensus on moral norms and values. Once you make this distinction, you see that nobody can coherently even want moral diversity. If you are pro-choice on the issue of abortion, would you prefer that there be a wide variety of opinions and no dominant one? Or would you prefer that everyone agree with you and the laws of the land reflect that agreement? If you prefer diversity on an issue, the issue is not a moral issue for you; it is a matter of personal taste.\nThe Divinity Dimension Imagine yourself happily moving around your two-dimensional social world, a flat land where the X axis is closeness and the Y axis is hierarchy (see figure 9.1). Then one day, you see a person do something extraordinary, or you have an overwhelming experience of natural beauty, and you feel lifted \u0026ldquo;up.\u0026rdquo; But it\u0026rsquo;s not the \u0026ldquo;up\u0026rdquo; of hierarchy, it\u0026rsquo;s some other kind of elevation.\nMy claim is that the human mind perceives a third dimension, a specifically moral dimension that I will call \u0026ldquo;divinity.\u0026rdquo; My research on the moral emotions has led me to conclude that the human mind simply does perceive divinity and sacredness, whether or not God exists.\nThe Ethic Of Divinity After graduate school, I spent two years working with Richard Shweder, a psychological anthropologist at the University of Chicago who is the leading thinker in the field of cultural psychology. Shweder does much of his research in the Indian city of Bhubaneswar, in the state of Orissa, on the Bay of Bengal.\nShweder\u0026rsquo;s research on morality 14 in Bhubaneswar and elsewhere shows that when people think about morality, their moral concepts cluster into three groups, which he calls the ethic of autonomy, the ethic of community, and the ethic of divinity. When people think and act using the ethic of autonomy, their goal is to protect individuals from harm and grant them the maximum degree of autonomy, which they can use to pursue their own goals. When people use the ethic of community, their goal is to protect the integrity of groups, families, companies, or nations, and they value virtues such as obedience, loyalty, and wise leadership. When people use the ethic of divinity, their goal is to protect from degradation the divinity that exists in each person, and they value living in a pure and holy way, free from moral pollutants such as lust, greed, and hatred. Cultures vary in their relative reliance on these three ethics, which correspond, roughly, to the X, Y, and Z axes of the figure above.\nShortly after moving to the University of Virginia in 1995, I was writing yet another article about how social disgust is triggered when we see people moving \u0026ldquo;down\u0026rdquo; on the vertical dimension of divinity. Suddenly it occurred to me that I had never really thought about the emotional reaction to seeing people move \u0026ldquo;up.\u0026rdquo; I had referred in passing to the feeling of being \u0026ldquo;uplifted,\u0026rdquo; but had never even wondered whether \u0026ldquo;uplift\u0026rdquo; is a real, honest-to-goodness emotion.\nThe Causes of Movement to the Third Dimension Virtue is not the only cause of movement on the third dimension. The vastness and beauty of nature similarly stirs the soul.\nSomething about the vastness and beauty of nature makes the self feel small and insignificant, and anything that shrinks the self creates an opportunity for spiritual experience. I wrote about the divided self-the many ways in which people feel as though they have multiple selves or intelligences that sometimes conflict. This division is often explained by positing a soul-a higher, noble, spiritual self, which is tied down to a body-a lower, base, carnal self. The soul escapes the body only at death; but before then, spiritual practices, great sermons, and awe at nature can give the soul a taste of the freedom to come.\nThere are many other ways of getting such a foretaste. People often refer to viewing great art, hearing a symphony, or listening to an inspiring speaker as (crypto) religious experiences.\nMaslow said:\n [quote]Education must be seen as at least partially an effort to produce the good human being, to foster the good life and the good society.[/quote] The Satanic Self\n The self is one of the great paradoxes of human evolution. Like the fire stolen by Prometheus, it made us powerful but exacted a cost. In The Curse of the Self, the social psychologist Mark Leary points out that many other animals can think, but none, so far as we know, spend much time thinking about themselves.\nLeary suggests that this ability to create a self gave our ancestors many useful skills, such as long-term planning, conscious decision making and self-control, and the ability to see other people\u0026rsquo;s perspectives.\nBut by giving each one of us an inner world, a world full of simulations, social comparisons, and reputational concerns, the self also gave each one of us a personal tormenter. We all now live amid a whirlpool of inner chatter, much of which is negative (threats loom larger than opportunities), and most of which is useless.\nLeary\u0026rsquo;s analysis shows why the self is a problem for all major religions: The self is the main obstacle to spiritual advancement, in three ways. First, the constant stream of trivial concerns and egocentric thoughts keeps people locked in the material and profane world, unable to perceive sacredness and divinity. This is why Eastern religions rely heavily on meditation, an effective means of quieting the chatter of the self. Second, spiritual transformation is essentially the transformation of the self, weakening it, pruning it back-in some sense, killing it-and often the self objects.\nAnd third, following a spiritual path is invariably hard work, requiring years of meditation, prayer, self-control, and sometimes self-denial. In a sense, the self is Satan, or, at least, Satan\u0026rsquo;s portal. For all these reasons, the self is a problem for the ethic of divinity. The big greedy self is like a brick holding down the soul.\nThe Effect of the Flattening of Life Although I have begun to see the richness that divinity adds to human experience, I do not entirely lament the \u0026ldquo;flattening\u0026rdquo; of life in the West over the last few hundred years. An unfortunate tendency of three-dimensional societies is that they often include one or more groups that get pushed down on the third dimension and then treated badly, or worse. Look at the conditions of \u0026ldquo;untouchables\u0026rdquo; in India until recently, or at the plight of Jews in medieval Europe and in purity-obsessed Nazi Germany, or at the humiliation of African Americans in the segregated South. The American religious right now seems to be trying to push homosexuals down in a similar way. Liberalism and the ethic of autonomy are great protectors against such injustices. I believe it is dangerous for the ethic of divinity to supersede the ethic of autonomy in the governance of a diverse modern democracy. However, I also believe that life in a society that entirely ignored the ethic of divinity would be ugly and unsatisfying.\nWhy Modern Philosophy Seemed Sterile It lacked a deep understanding of human nature. The ancient philosophers were often good psychologists, as I have shown in this book, but when modern philosophy began to devote itself to the study of logic and rationality, it gradually lost interest in psychology and lost touch with the passionate, contextualized nature of human life. It is impossible to analyze \u0026ldquo;the meaning of life\u0026rdquo; in the abstract, or in general, or for some mythical and perfectly rational being. Only by knowing the kinds of beings that we actually are, with the complex mental and emotional architecture that we happen to possess, can anyone even begin to ask about what would count as a meaningful life.\nThe Holy Question The question \u0026ldquo;What is the meaning of life\u0026rdquo; might be called the Holy Question, in analogy to the Holy Grail: Its pursuit is noble and everyone should want to find an answer, yet few people expect that one can be found.\nOne thing philosophy did teach me is how to analyze questions, how to clarify exactly what is being asked before giving an answer. The Holy Question cries out for clarification. Whenever we ask \u0026ldquo;What is the meaning of X?\u0026rdquo; what kind of answer could possibly satisfy us?\nThe most common kind of meaning is definitional. We are not asking about the word \u0026ldquo;life,\u0026rdquo; we\u0026rsquo;re asking about life itself.\nA second kind of meaning is about symbolism or substitution. Life does not symbolize, stand for, or point to anything. It is life itself that we want to understand.\nA third way in which we ask about meaning is as a plea for help in making sense of something, usually with reference to people\u0026rsquo;s intentions and beliefs. Suppose you walk into a movie half an hour late and have to leave half an hour before the end. Later that night you are talking with a friend who saw the whole film and you ask, \u0026ldquo;What did it mean when the guy with the curly hair winked at that kid?\u0026rdquo; You are aware that the act had some significance for the plot of the movie, and you suspect that you need to know certain facts to understand that act. Perhaps a prior relationship between the two characters had been revealed in the opening scenes? To ask, \u0026ldquo;What was the meaning of the wink?\u0026rdquo; really means, \u0026ldquo;What do I need to know to understand that wink?\u0026rdquo; Now we\u0026rsquo;re making progress, for life is much like a movie we walk into well after its opening scene, and we will have to step out long before most of the story lines reach their conclusions. We are acutely aware that we need to know a great deal if we are to understand the few confusing minutes that we do watch. Of course, we don\u0026rsquo;t know exactly what it is that we don\u0026rsquo;t know, so we can\u0026rsquo;t frame the question well. We ask, \u0026ldquo;What is the meaning of life?\u0026rdquo; not expecting a direct answer (such as \u0026ldquo;forty-two\u0026rdquo;), but rather hoping for some enlightenment, something to give us an \u0026ldquo;aha!\u0026rdquo; experience in which, suddenly, things that we had not before understood or recognized as important begin to make sense (as they did for the square taken to the third dimension).\nOnce the Holy Question has been re-framed to mean \u0026ldquo;Tell me something enlightening about life,\u0026rdquo; the answer must involve the kinds of revelations that human beings find enlightening. There appear to be two specific sub-questions to which people want answers, and for which they find answers enlightening. The first can be called the question of the purpose of life: \u0026ldquo;What is the purpose for which human beings were placed on Earth? Why are we here?\u0026rdquo; There are two major classes of answers to this question: Either you believe in a god/spirit/intelligence who had some idea, desire, or intention in creating the world or you believe in a purely material world in which it and you were not created for any reason; it all just happened as matter and energy interacted according to the laws of nature (which, once life got started, included the principles of Darwinian evolution).\nThe second sub-question is the question of purpose within life: \u0026ldquo;How ought I to live? What should I do to have a good, happy, fulfilling, and meaningful life?\u0026rdquo; When people ask the Holy Question, one of the things they are hoping for is a set of principles or goals that can guide their actions and give their choices meaning or value.\nThe two questions can, however, be separated. The first asks about life from the outside; it looks at people, the Earth, and the stars as objects-\u0026ldquo;Why do they all exist?\u0026rdquo;-and is properly addressed by theologians, physicists, and biologists. The second question is about life from the inside, as a subject-\u0026ldquo;How can I find a sense of meaning and purpose?\u0026rdquo;-and is properly addressed by theologians, philosophers, and psychologists. The second question is really empirical-a question of fact that can be examined by scientific means. Why do some people live lives full of zest, commitment, and meaning, but others feel that their lives are empty and pointless?\nThe Conditions of Human Flourishing If people are like plants, what are the conditions we need to flourish? In the happiness formula, H(appiness) = S(etpoint) + C(onditions) + V(oluntary activities), what exactly is C? The biggest part of C is love. No man, woman, or child is an island. We are ultrasocial creatures, and we can\u0026rsquo;t be happy without having friends and secure attachments to other people. The second most important part of C is having and pursuing the right goals, in order to create states of flow and engagement. In the modern world, people can find goals and flow in many settings, but most people find most of their flow at work.\nLove and work are, for people, obvious analogues to water and sunshine for plants. Which is earned mostly through one\u0026rsquo;s work. Even before Freud, Leo Tolstoy wrote: \u0026ldquo;One can live magnificently in this world, if one knows how to work and how to love, to work for the person one loves and to love one\u0026rsquo;s work.\u0026rdquo;\nIn 1959, the Harvard psychologist Robert White concluded, after surveying research in behaviorism and psychoanalysis, that both theories had missed what Harlow had noticed: the overwhelming evidence that people and many other mammals have a basic drive to make things happen.\nPsychologists have referred to this basic need as a need for competence, industry, or mastery. White called it the \u0026ldquo;effectance motive,\u0026rdquo; which he defined as the need or drive to develop competence through interacting with and controlling one\u0026rsquo;s environment.\nThe effectance motive helps explain the progress principle: We get more pleasure from making progress toward our goals than we do from achieving them because, as Shakespeare said, \u0026ldquo;Joy\u0026rsquo;s soul lies in the doing.\u0026rdquo;\nMore recent research finds that most people approach their work in one of three ways: as a job, a career, or a calling. If you see your work as a job, you do it only for the money, you look at the clock frequently while dreaming about the weekend ahead, and you probably pursue hobbies, which satisfy your effectance needs more thoroughly than does your work. If you see your work as a career, you have larger goals of advancement, promotion, and prestige. The pursuit of these goals often energizes you, and you sometimes take work home with you because you want to get the job done properly. Yet, at times, you wonder why you work so hard. You might occasionally see your work as a rat race where people are competing for the sake of competing. If you see your work as a calling, however, you find your work intrinsically fulfilling-you are not doing it to achieve something else. You see your work as contributing to the greater good or as playing a role in some larger enterprise the worth of which seems obvious to you. You have frequent experiences of flow during the work day, and you neither look forward to \u0026ldquo;quitting time\u0026rdquo; nor feel the desire to shout, \u0026ldquo;Thank God it\u0026rsquo;s Friday!\u0026rdquo; You would continue to work, perhaps even without pay, if you suddenly became very wealthy.\nThe optimistic conclusion coming out of research in positive psychology is that most people can get more satisfaction from their work. The first step is to know your strengths. Take the strengths test and then choose work that allows you to use your strengths every day, thereby giving yourself at least scattered moments of flow.\nWork at its best, then, is about connection, engagement, and commitment. As the poet Kahlil Gibran said, \u0026ldquo;Work is love made visible.\u0026rdquo;\nLove and work are crucial for human happiness because, when done well, they draw us out of ourselves and into connection with people and projects beyond ourselves. Happiness comes from getting these connections right. Happiness comes not just from within, as Buddha and Epictetus supposed, or even from a combination of internal and external factors. The correct version of the happiness hypothesis, is that happiness comes from between.\nVital Engagement The man who found flow, Mihalyi Csikszentmihalyi, thinks big. Not content to study moments of flow (by beeping people several times a day), he wanted to know what role flow plays in life as a whole, particularly in the lives of creative people. He and his students have interviewed hundreds of successful painters, dancers, poets, novelists, physicists, biologists, and psychologists-all people who seem to have crafted lives for themselves built around a consuming passion.\nHis interviews showed that every path is unique, yet most of them led in the same direction: from initial interest and enjoyment, with moments of flow, through a relationship to people, practices, and values that deepened over many years, thereby enabling even longer periods of flow. Csikszentmihalyi and his students, particularly Jeanne Nakamura, have studied the end state of this deepening process and called it \u0026ldquo;vital engagement,\u0026rdquo; which they define as \u0026ldquo;a relationship to the world that is characterized both by experiences of flow (enjoyed absorption) and by meaning (subjective significance).\u0026rdquo;\nVital engagement does not reside in the person or in the environment; it exists in the relationship between the two.\nGetting the right relationship between you and your work is not entirely up to you. Some occupations come ready-made for vital engagement; others make it difficult.\nCross-Level Coherence The word \u0026ldquo;coherence\u0026rdquo; literally means holding or sticking together, but it is usually used to refer to a system, an idea, or a worldview whose parts fit together in a consistent and efficient way.\nWhenever a system can be analyzed at multiple levels, a special kind of coherence occurs when the levels mesh and mutually interlock. We saw this cross-level coherence in the analysis of personality: If your lower-level traits match up with your coping mechanisms, which in turn are consistent with your life story, your personality is well integrated and you can get on with the business of living. When these levels do not cohere, you are likely to be torn by internal contradictions and neurotic conflicts.34 You might need adversity to knock yourself into alignment. And if you do achieve coherence, the moment when things come together may be one of the most profound of your life. Like the moviegoer who later finds out what she missed in the first half hour, your life will suddenly make more sense. Finding coherence across levels feels like enlightenment, and it is crucial for answering the question of purpose within life.\nHere is one of the most profound ideas to come from the ongoing synthesis: People gain a sense of meaning when their lives cohere across the three levels of their existence.\nHarmony And Purpose Reading Wilson\u0026rsquo;s Darwin\u0026rsquo;s Cathedral is like taking a journey to Spaceland. You can look down on the vast tapestry of human cultures and see why things are woven in the way that they are. Wilson says his own private hell would be to be locked forever into a room full of people discussing the hypocrisies of religion, for example, that many religions preach love, compassion, and virtue yet sometimes cause war, hatred, and terrorism. From Wilson\u0026rsquo;s higher perspective, there is no contradiction. Group selection creates interlocking genetic and cultural adaptations that enhance peace, harmony, and cooperation within the group for the express purpose of increasing the group\u0026rsquo;s ability to compete with other groups. Group selection does not end conflict; it just pushes it up to the next level of social organization. Atrocities committed in the name of religion are almost always committed against out-group members, or against the most dangerous people of all: apostates (who try to leave the group) and traitors (who undermine the group).\nA second puzzle that Wilson can solve is why mysticism, everywhere and always, is about transcending the self and merging with something larger than the self.\nFrom Wilson\u0026rsquo;s perspective, mystical experience is an \u0026ldquo;off\u0026rdquo; button for the self. When the self is turned off, people become just a cell in the larger body, a bee in the larger hive. It is no wonder that the after effects of mystical experience are predictable; people usually feel a stronger commitment to God or to helping others, often by bringing them to God.\nThe Meaning Of Life What can you do to have a good, happy, fulfilling, and meaningful life? What is the answer to the question of purpose within life? I believe the answer can be found only by understanding the kind of creature that we are, divided in the many ways we are divided. We were shaped by individual selection to be selfish creatures who struggle for resources, pleasure, and prestige, and we were shaped by group selection to be hive creatures who long to lose ourselves in something larger. We are social creatures who need love and attachments, and we are industrious creatures with needs for effectance, able to enter a state of vital engagement with our work. We are the rider and we are the elephant, and our mental health depends on the two working together, each drawing on the others\u0026rsquo; strengths. I don\u0026rsquo;t believe there is an inspiring answer to the question, \u0026ldquo;What is the purpose of life?\u0026rdquo; Yet by drawing on ancient wisdom and modern science, we can find compelling answers to the question of purpose within life. The final version of the happiness hypothesis is that happiness comes from between. Happiness is not something that you can find, acquire, or achieve directly. You have to get the conditions right and then wait. Some of those conditions are within you, such as coherence among the parts and levels of your personality. Other conditions require relationships to things beyond you: Just as plants need sun, water, and good soil to thrive, people need love, work, and a connection to something larger. It is worth striving to get the right relationships between yourself and others, between yourself and your work, and between yourself and something larger than yourself. If you get these relationships right, a sense of purpose and meaning will emerge.\nWhere to Look for Wisdom An important dictum of cultural psychology is that each culture develops expertise in some aspects of human existence, but no culture can be expert in all aspects. The same goes for the two ends of the political spectrum.\nA good place to look for wisdom, therefore, is where you least expect to find it: in the minds of your opponents. You already know the ideas common on your own side. If you can take off the blinders of the myth of pure evil, you might see some good ideas for the first time.\nBy drawing on wisdom that is balanced-ancient and new, Eastern and Western, even liberal and conservative-we can choose directions in life that will lead to satisfaction, happiness, and a sense of meaning. We can\u0026rsquo;t simply select a destination and then walk there directly-the rider does not have that much authority. But by drawing on humanity\u0026rsquo;s greatest ideas and best science, we can train the elephant, know our possibilities as well as our limits, and live wisely.\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/jeff-bezos-api-mandate/",
	"title": "Jeff Bezos&#39; API Mandate",
	"tags": ["anekdote"],
	"description": "How Amazon bypassed Microsoft, Google and everybody else in the cloud business",
	"content": "The best article I\u0026rsquo;ve ever read about architecture and the management of IT.\nUPDATE\nThis post was intended to be shared privately and was accidentally made public. Thanks to +Steve Yegge for allowing us to keep it out there. It\u0026rsquo;s the sort of writing people do when they think nobody is watching: honest, clear, and frank.\nThe world would be a better place if more people wrote this sort of internal memoranda, and even better if they were allowed to write it for the outside world.\nHopefully Steve will not experience any negative repercussions from Google about this. On the contrary, he deserves a promotion.\nUPDATE #2\nThis post has received a lot of attention. For anyone here who arrived from The Greater Internet - I stand ready to remove this post if asked. As I mentioned before, I was given permission to keep it up.\nGoogle\u0026rsquo;s openness to allow us to keep this message posted on its own social network is, in my opinion, a far greater asset than any SaS platform. In the end, a company\u0026rsquo;s greatest asset is its culture, and here, Google is one of the strongest companies on the planet. Originally shared by Steve Yegge Stevey\u0026rsquo;s Google Platforms Rant\nI was at Amazon for about six and a half years, and now I\u0026rsquo;ve been at Google for that long. One thing that struck me immediately about the two companies \u0026ndash; an impression that has been reinforced almost daily \u0026ndash; is that Amazon does everything wrong, and Google does everything right. Sure, it\u0026rsquo;s a sweeping generalization, but a surprisingly accurate one. It\u0026rsquo;s pretty crazy. There are probably a hundred or even two hundred different ways you can compare the two companies, and Google is superior in all but three of them, if I recall correctly. I actually did a spreadsheet at one point but Legal wouldn\u0026rsquo;t let me show it to anyone, even though recruiting loved it.\nI mean, just to give you a very brief taste: Amazon\u0026rsquo;s recruiting process is fundamentally flawed by having teams hire for themselves, so their hiring bar is incredibly inconsistent across teams, despite various efforts they\u0026rsquo;ve made to level it out. And their operations are a mess; they don\u0026rsquo;t really have SREs and they make engineers pretty much do everything, which leaves almost no time for coding - though again this varies by group, so it\u0026rsquo;s luck of the draw. They don\u0026rsquo;t give a single shit about charity or helping the needy or community contributions or anything like that. Never comes up there, except maybe to laugh about it. Their facilities are dirt-smeared cube farms without a dime spent on decor or common meeting areas. Their pay and benefits suck, although much less so lately due to local competition from Google and Facebook. But they don\u0026rsquo;t have any of our perks or extras \u0026ndash; they just try to match the offer-letter numbers, and that\u0026rsquo;s the end of it. Their code base is a disaster, with no engineering standards whatsoever except what individual teams choose to put in place.\nTo be fair, they do have a nice versioned-library system that we really ought to emulate, and a nice publish-subscribe system that we also have no equivalent for. But for the most part they just have a bunch of crappy tools that read and write state machine information into relational databases. We wouldn\u0026rsquo;t take most of it even if it were free.\nI think the pubsub system and their library-shelf system were two out of the grand total of three things Amazon does better than google.\nI guess you could make an argument that their bias for launching early and iterating like mad is also something they do well, but you can argue it either way. They prioritize launching early over everything else, including retention and engineering discipline and a bunch of other stuff that turns out to matter in the long run. So even though it\u0026rsquo;s given them some competitive advantages in the marketplace, it\u0026rsquo;s created enough other problems to make it something less than a slam-dunk.\nBut there\u0026rsquo;s one thing they do really really well that pretty much makes up for ALL of their political, philosophical and technical screw-ups.\nJeff Bezos is an infamous micro-manager. He micro-manages every single pixel of Amazon\u0026rsquo;s retail site. He hired Larry Tesler, Apple\u0026rsquo;s Chief Scientist and probably the very most famous and respected human-computer interaction expert in the entire world, and then ignored every goddamn thing Larry said for three years until Larry finally \u0026ndash; wisely \u0026ndash; left the company. Larry would do these big usability studies and demonstrate beyond any shred of doubt that nobody can understand that frigging website, but Bezos just couldn\u0026rsquo;t let go of those pixels, all those millions of semantics-packed pixels on the landing page. They were like millions of his own precious children. So they\u0026rsquo;re all still there, and Larry is not.\nMicro-managing isn\u0026rsquo;t that third thing that Amazon does better than us, by the way. I mean, yeah, they micro-manage really well, but I wouldn\u0026rsquo;t list it as a strength or anything. I\u0026rsquo;m just trying to set the context here, to help you understand what happened. We\u0026rsquo;re talking about a guy who in all seriousness has said on many public occasions that people should be paying him to work at Amazon. He hands out little yellow stickies with his name on them, reminding people \u0026ldquo;who runs the company\u0026rdquo; when they disagree with him. The guy is a regular\u0026hellip; well, Steve Jobs, I guess. Except without the fashion or design sense. Bezos is super smart; don\u0026rsquo;t get me wrong. He just makes ordinary control freaks look like stoned hippies.\nSo one day Jeff Bezos issued a mandate. He\u0026rsquo;s doing that all the time, of course, and people scramble like ants being pounded with a rubber mallet whenever it happens. But on one occasion \u0026ndash; back around 2002 I think, plus or minus a year \u0026ndash; he issued a mandate that was so out there, so huge and eye-bulgingly ponderous, that it made all of his other mandates look like unsolicited peer bonuses.\nHis Big Mandate went something along these lines:\n1) All teams will henceforth expose their data and functionality through service interfaces.\n2) Teams must communicate with each other through these interfaces.\n3) There will be no other form of interprocess communication allowed: no direct linking, no direct reads of another team\u0026rsquo;s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network.\n4) It doesn\u0026rsquo;t matter what technology they use. HTTP, Corba, Pubsub, custom protocols \u0026ndash; doesn\u0026rsquo;t matter. Bezos doesn\u0026rsquo;t care.\n5) All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions.\n6) Anyone who doesn\u0026rsquo;t do this will be fired.\n7) Thank you; have a nice day!\nHa, ha! You 150-odd ex-Amazon folks here will of course realize immediately that #7 was a little joke I threw in, because Bezos most definitely does not give a shit about your day.\n#6, however, was quite real, so people went to work. Bezos assigned a couple of Chief Bulldogs to oversee the effort and ensure forward progress, headed up by Uber-Chief Bear Bulldog Rick Dalzell. Rick is an ex-Armgy Ranger, West Point Academy graduate, ex-boxer, ex-Chief Torturer slash CIO at Wal*Mart, and is a big genial scary man who used the word \u0026ldquo;hardened interface\u0026rdquo; a lot. Rick was a walking, talking hardened interface himself, so needless to say, everyone made LOTS of forward progress and made sure Rick knew about it.\nOver the next couple of years, Amazon transformed internally into a service-oriented architecture. They learned a tremendous amount while effecting this transformation. There was lots of existing documentation and lore about SOAs, but at Amazon\u0026rsquo;s vast scale it was about as useful as telling Indiana Jones to look both ways before crossing the street. Amazon\u0026rsquo;s dev staff made a lot of discoveries along the way. A teeny tiny sampling of these discoveries included:\n pager escalation gets way harder, because a ticket might bounce through 20 service calls before the real owner is identified. If each bounce goes through a team with a 15-minute response time, it can be hours before the right team finally finds out, unless you build a lot of scaffolding and metrics and reporting.\n every single one of your peer teams suddenly becomes a potential DOS attacker. Nobody can make any real forward progress until very serious quotas and throttling are put in place in every single service.\n monitoring and QA are the same thing. You\u0026rsquo;d never think so until you try doing a big SOA. But when your service says \u0026ldquo;oh yes, I\u0026rsquo;m fine\u0026rdquo;, it may well be the case that the only thing still functioning in the server is the little component that knows how to say \u0026ldquo;I\u0026rsquo;m fine, roger roger, over and out\u0026rdquo; in a cheery droid voice. In order to tell whether the service is actually responding, you have to make individual calls. The problem continues recursively until your monitoring is doing comprehensive semantics checking of your entire range of services and data, at which point it\u0026rsquo;s indistinguishable from automated QA. So they\u0026rsquo;re a continuum.\n if you have hundreds of services, and your code MUST communicate with other groups\u0026rsquo; code via these services, then you won\u0026rsquo;t be able to find any of them without a service-discovery mechanism. And you can\u0026rsquo;t have that without a service registration mechanism, which itself is another service. So Amazon has a universal service registry where you can find out reflectively (programmatically) about every service, what its APIs are, and also whether it is currently up, and where.\n debugging problems with someone else\u0026rsquo;s code gets a LOT harder, and is basically impossible unless there is a universal standard way to run every service in a debuggable sandbox.\n  That\u0026rsquo;s just a very small sample. There are dozens, maybe hundreds of individual learnings like these that Amazon had to discover organically. There were a lot of wacky ones around externalizing services, but not as many as you might think. Organizing into services taught teams not to trust each other in most of the same ways they\u0026rsquo;re not supposed to trust external developers.\nThis effort was still underway when I left to join Google in mid-2005, but it was pretty far advanced. From the time Bezos issued his edict through the time I left, Amazon had transformed culturally into a company that thinks about everything in a services-first fashion. It is now fundamental to how they approach all designs, including internal designs for stuff that might never see the light of day externally.\nAt this point they don\u0026rsquo;t even do it out of fear of being fired. I mean, they\u0026rsquo;re still afraid of that; it\u0026rsquo;s pretty much part of daily life there, working for the Dread Pirate Bezos and all. But they do services because they\u0026rsquo;ve come to understand that it\u0026rsquo;s the Right Thing. There are without question pros and cons to the SOA approach, and some of the cons are pretty long. But overall it\u0026rsquo;s the right thing because SOA-driven design enables Platforms.\nThat\u0026rsquo;s what Bezos was up to with his edict, of course. He didn\u0026rsquo;t (and doesn\u0026rsquo;t) care even a tiny bit about the well-being of the teams, nor about what technologies they use, nor in fact any detail whatsoever about how they go about their business unless they happen to be screwing up. But Bezos realized long before the vast majority of Amazonians that Amazon needs to be a platform.\nYou wouldn\u0026rsquo;t really think that an online bookstore needs to be an extensible, programmable platform. Would you?\nWell, the first big thing Bezos realized is that the infrastructure they\u0026rsquo;d built for selling and shipping books and sundry could be transformed an excellent repurposable computing platform. So now they have the Amazon Elastic Compute Cloud, and the Amazon Elastic MapReduce, and the Amazon Relational Database Service, and a whole passel\u0026rsquo; o\u0026rsquo; other services browsable at aws.amazon.com. These services host the backends for some pretty successful companies, reddit being my personal favorite of the bunch.\nThe other big realization he had was that he can\u0026rsquo;t always build the right thing. I think Larry Tesler might have struck some kind of chord in Bezos when he said his mom couldn\u0026rsquo;t use the goddamn website. It\u0026rsquo;s not even super clear whose mom he was talking about, and doesn\u0026rsquo;t really matter, because nobody\u0026rsquo;s mom can use the goddamn website. In fact I myself find the website disturbingly daunting, and I worked there for over half a decade. I\u0026rsquo;ve just learned to kinda defocus my eyes and concentrate on the million or so pixels near the center of the page above the fold.\nI\u0026rsquo;m not really sure how Bezos came to this realization \u0026ndash; the insight that he can\u0026rsquo;t build one product and have it be right for everyone. But it doesn\u0026rsquo;t matter, because he gets it. There\u0026rsquo;s actually a formal name for this phenomenon. It\u0026rsquo;s called Accessibility, and it\u0026rsquo;s the most important thing in the computing world.\nThe. Most. Important. Thing.\nIf you\u0026rsquo;re sorta thinking, \u0026ldquo;huh? You mean like, blind and deaf people Accessibility?\u0026rdquo; then you\u0026rsquo;re not alone, because I\u0026rsquo;ve come to understand that there are lots and LOTS of people just like you: people for whom this idea does not have the right Accessibility, so it hasn\u0026rsquo;t been able to get through to you yet. It\u0026rsquo;s not your fault for not understanding, any more than it would be your fault for being blind or deaf or motion-restricted or living with any other disability. When software \u0026ndash; or idea-ware for that matter \u0026ndash; fails to be accessible to anyone for any reason, it is the fault of the software or of the messaging of the idea. It is an Accessibility failure.\nLike anything else big and important in life, Accessibility has an evil twin who, jilted by the unbalanced affection displayed by their parents in their youth, has grown into an equally powerful Arch-Nemesis (yes, there\u0026rsquo;s more than one nemesis to accessibility) named Security. And boy howdy are the two ever at odds.\nBut I\u0026rsquo;ll argue that Accessibility is actually more important than Security because dialing Accessibility to zero means you have no product at all, whereas dialing Security to zero can still get you a reasonably successful product such as the Playstation Network.\nSo yeah. In case you hadn\u0026rsquo;t noticed, I could actually write a book on this topic. A fat one, filled with amusing anecdotes about ants and rubber mallets at companies I\u0026rsquo;ve worked at. But I will never get this little rant published, and you\u0026rsquo;ll never get it read, unless I start to wrap up.\nThat one last thing that Google doesn\u0026rsquo;t do well is Platforms. We don\u0026rsquo;t understand platforms. We don\u0026rsquo;t \u0026ldquo;get\u0026rdquo; platforms. Some of you do, but you are the minority. This has become painfully clear to me over the past six years. I was kind of hoping that competitive pressure from Microsoft and Amazon and more recently Facebook would make us wake up collectively and start doing universal services. Not in some sort of ad-hoc, half-assed way, but in more or less the same way Amazon did it: all at once, for real, no cheating, and treating it as our top priority from now on.\nBut no. No, it\u0026rsquo;s like our tenth or eleventh priority. Or fifteenth, I don\u0026rsquo;t know. It\u0026rsquo;s pretty low. There are a few teams who treat the idea very seriously, but most teams either don\u0026rsquo;t think about it all, ever, or only a small percentage of them think about it in a very small way.\nIt\u0026rsquo;s a big stretch even to get most teams to offer a stubby service to get programmatic access to their data and computations. Most of them think they\u0026rsquo;re building products. And a stubby service is a pretty pathetic service. Go back and look at that partial list of learnings from Amazon, and tell me which ones Stubby gives you out of the box. As far as I\u0026rsquo;m concerned, it\u0026rsquo;s none of them. Stubby\u0026rsquo;s great, but it\u0026rsquo;s like parts when you need a car.\nA product is useless without a platform, or more precisely and accurately, a platform-less product will always be replaced by an equivalent platform-ized product.\nGoogle+ is a prime example of our complete failure to understand platforms from the very highest levels of executive leadership (hi Larry, Sergey, Eric, Vic, howdy howdy) down to the very lowest leaf workers (hey yo). We all don\u0026rsquo;t get it. The Golden Rule of platforms is that you Eat Your Own Dogfood. The Google+ platform is a pathetic afterthought. We had no API at all at launch, and last I checked, we had one measly API call. One of the team members marched in and told me about it when they launched, and I asked: \u0026ldquo;So is it the Stalker API?\u0026rdquo; She got all glum and said \u0026ldquo;Yeah.\u0026rdquo; I mean, I was joking, but no\u0026hellip; the only API call we offer is to get someone\u0026rsquo;s stream. So I guess the joke was on me.\nMicrosoft has known about the Dogfood rule for at least twenty years. It\u0026rsquo;s been part of their culture for a whole generation now. You don\u0026rsquo;t eat People Food and give your developers Dog Food. Doing that is simply robbing your long-term platform value for short-term successes. Platforms are all about long-term thinking.\nGoogle+ is a knee-jerk reaction, a study in short-term thinking, predicated on the incorrect notion that Facebook is successful because they built a great product. But that\u0026rsquo;s not why they are successful. Facebook is successful because they built an entire constellation of products by allowing other people to do the work. So Facebook is different for everyone. Some people spend all their time on Mafia Wars. Some spend all their time on Farmville. There are hundreds or maybe thousands of different high-quality time sinks available, so there\u0026rsquo;s something there for everyone.\nOur Google+ team took a look at the aftermarket and said: \u0026ldquo;Gosh, it looks like we need some games. Let\u0026rsquo;s go contract someone to, um, write some games for us.\u0026rdquo; Do you begin to see how incredibly wrong that thinking is now? The problem is that we are trying to predict what people want and deliver it for them.\nYou can\u0026rsquo;t do that. Not really. Not reliably. There have been precious few people in the world, over the entire history of computing, who have been able to do it reliably. Steve Jobs was one of them. We don\u0026rsquo;t have a Steve Jobs here. I\u0026rsquo;m sorry, but we don\u0026rsquo;t.\nLarry Tesler may have convinced Bezos that he was no Steve Jobs, but Bezos realized that he didn\u0026rsquo;t need to be a Steve Jobs in order to provide everyone with the right products: interfaces and workflows that they liked and felt at ease with. He just needed to enable third-party developers to do it, and it would happen automatically.\nI apologize to those (many) of you for whom all this stuff I\u0026rsquo;m saying is incredibly obvious, because yeah. It\u0026rsquo;s incredibly frigging obvious. Except we\u0026rsquo;re not doing it. We don\u0026rsquo;t get Platforms, and we don\u0026rsquo;t get Accessibility. The two are basically the same thing, because platforms solve accessibility. A platform is accessibility.\nSo yeah, Microsoft gets it. And you know as well as I do how surprising that is, because they don\u0026rsquo;t \u0026ldquo;get\u0026rdquo; much of anything, really. But they understand platforms as a purely accidental outgrowth of having started life in the business of providing platforms. So they have thirty-plus years of learning in this space. And if you go to msdn.com, and spend some time browsing, and you\u0026rsquo;ve never seen it before, prepare to be amazed. Because it\u0026rsquo;s staggeringly huge. They have thousands, and thousands, and THOUSANDS of API calls. They have a HUGE platform. Too big in fact, because they can\u0026rsquo;t design for squat, but at least they\u0026rsquo;re doing it.\nAmazon gets it. Amazon\u0026rsquo;s AWS (aws.amazon.com) is incredible. Just go look at it. Click around. It\u0026rsquo;s embarrassing. We don\u0026rsquo;t have any of that stuff.\nApple gets it, obviously. They\u0026rsquo;ve made some fundamentally non-open choices, particularly around their mobile platform. But they understand accessibility and they understand the power of third-party development and they eat their dogfood. And you know what? They make pretty good dogfood. Their APIs are a hell of a lot cleaner than Microsoft\u0026rsquo;s, and have been since time immemorial.\nFacebook gets it. That\u0026rsquo;s what really worries me. That\u0026rsquo;s what got me off my lazy butt to write this thing. I hate blogging. I hate\u0026hellip; plussing, or whatever it\u0026rsquo;s called when you do a massive rant in Google+ even though it\u0026rsquo;s a terrible venue for it but you do it anyway because in the end you really do want Google to be successful. And I do! I mean, Facebook wants me there, and it\u0026rsquo;d be pretty easy to just go. But Google is home, so I\u0026rsquo;m insisting that we have this little family intervention, uncomfortable as it might be.\nAfter you\u0026rsquo;ve marveled at the platform offerings of Microsoft and Amazon, and Facebook I guess (I didn\u0026rsquo;t look because I didn\u0026rsquo;t want to get too depressed), head over to developers.google.com and browse a little. Pretty big difference, eh? It\u0026rsquo;s like what your fifth-grade nephew might mock up if he were doing an assignment to demonstrate what a big powerful platform company might be building if all they had, resource-wise, was one fifth grader.\nPlease don\u0026rsquo;t get me wrong here \u0026ndash; I know for a fact that the dev-rel team has had to FIGHT to get even this much available externally. They\u0026rsquo;re kicking ass as far as I\u0026rsquo;m concerned, because they DO get platforms, and they are struggling heroically to try to create one in an environment that is at best platform-apathetic, and at worst often openly hostile to the idea.\nI\u0026rsquo;m just frankly describing what developers.google.com looks like to an outsider. It looks childish. Where\u0026rsquo;s the Maps APIs in there for Christ\u0026rsquo;s sake? Some of the things in there are labs projects. And the APIs for everything I clicked were\u0026hellip; they were paltry. They were obviously dog food. Not even good organic stuff. Compared to our internal APIs it\u0026rsquo;s all snouts and horse hooves.\nAnd also don\u0026rsquo;t get me wrong about Google+. They\u0026rsquo;re far from the only offenders. This is a cultural thing. What we have going on internally is basically a war, with the underdog minority Platformers fighting a more or less losing battle against the Mighty Funded Confident Producters.\nAny teams that have successfully internalized the notion that they should be externally programmable platforms from the ground up are underdogs \u0026ndash; Maps and Docs come to mind, and I know GMail is making overtures in that direction. But it\u0026rsquo;s hard for them to get funding for it because it\u0026rsquo;s not part of our culture. Maestro\u0026rsquo;s funding is a feeble thing compared to the gargantuan Microsoft Office programming platform: it\u0026rsquo;s a fluffy rabbit versus a T-Rex. The Docs team knows they\u0026rsquo;ll never be competitive with Office until they can match its scripting facilities, but they\u0026rsquo;re not getting any resource love. I mean, I assume they\u0026rsquo;re not, given that Apps Script only works in Spreadsheet right now, and it doesn\u0026rsquo;t even have keyboard shortcuts as part of its API. That team looks pretty unloved to me.\nIronically enough, Wave was a great platform, may they rest in peace. But making something a platform is not going to make you an instant success. A platform needs a killer app. Facebook \u0026ndash; that is, the stock service they offer with walls and friends and such \u0026ndash; is the killer app for the Facebook Platform. And it is a very serious mistake to conclude that the Facebook App could have been anywhere near as successful without the Facebook Platform.\nYou know how people are always saying Google is arrogant? I\u0026rsquo;m a Googler, so I get as irritated as you do when people say that. We\u0026rsquo;re not arrogant, by and large. We\u0026rsquo;re, like, 99% Arrogance-Free. I did start this post \u0026ndash; if you\u0026rsquo;ll reach back into distant memory \u0026ndash; by describing Google as \u0026ldquo;doing everything right\u0026rdquo;. We do mean well, and for the most part when people say we\u0026rsquo;re arrogant it\u0026rsquo;s because we didn\u0026rsquo;t hire them, or they\u0026rsquo;re unhappy with our policies, or something along those lines. They\u0026rsquo;re inferring arrogance because it makes them feel better.\nBut when we take the stance that we know how to design the perfect product for everyone, and believe you me, I hear that a lot, then we\u0026rsquo;re being fools. You can attribute it to arrogance, or naivete, or whatever \u0026ndash; it doesn\u0026rsquo;t matter in the end, because it\u0026rsquo;s foolishness. There IS no perfect product for everyone.\nAnd so we wind up with a browser that doesn\u0026rsquo;t let you set the default font size. Talk about an affront to Accessibility. I mean, as I get older I\u0026rsquo;m actually going blind. For real. I\u0026rsquo;ve been nearsighted all my life, and once you hit 40 years old you stop being able to see things up close. So font selection becomes this life-or-death thing: it can lock you out of the product completely. But the Chrome team is flat-out arrogant here: they want to build a zero-configuration product, and they\u0026rsquo;re quite brazen about it, and Fuck You if you\u0026rsquo;re blind or deaf or whatever. Hit Ctrl-+ on every single page visit for the rest of your life.\nIt\u0026rsquo;s not just them. It\u0026rsquo;s everyone. The problem is that we\u0026rsquo;re a Product Company through and through. We built a successful product with broad appeal \u0026ndash; our search, that is \u0026ndash; and that wild success has biased us.\nAmazon was a product company too, so it took an out-of-band force to make Bezos understand the need for a platform. That force was their evaporating margins; he was cornered and had to think of a way out. But all he had was a bunch of engineers and all these computers\u0026hellip; if only they could be monetized somehow\u0026hellip; you can see how he arrived at AWS, in hindsight.\nMicrosoft started out as a platform, so they\u0026rsquo;ve just had lots of practice at it.\nFacebook, though: they worry me. I\u0026rsquo;m no expert, but I\u0026rsquo;m pretty sure they started off as a Product and they rode that success pretty far. So I\u0026rsquo;m not sure exactly how they made the transition to a platform. It was a relatively long time ago, since they had to be a platform before (now very old) things like Mafia Wars could come along.\nMaybe they just looked at us and asked: \u0026ldquo;How can we beat Google? What are they missing?\u0026rdquo;\nThe problem we face is pretty huge, because it will take a dramatic cultural change in order for us to start catching up. We don\u0026rsquo;t do internal service-oriented platforms, and we just as equally don\u0026rsquo;t do external ones. This means that the \u0026ldquo;not getting it\u0026rdquo; is endemic across the company: the PMs don\u0026rsquo;t get it, the engineers don\u0026rsquo;t get it, the product teams don\u0026rsquo;t get it, nobody gets it. Even if individuals do, even if YOU do, it doesn\u0026rsquo;t matter one bit unless we\u0026rsquo;re treating it as an all-hands-on-deck emergency. We can\u0026rsquo;t keep launching products and pretending we\u0026rsquo;ll turn them into magical beautiful extensible platforms later. We\u0026rsquo;ve tried that and it\u0026rsquo;s not working.\nThe Golden Rule of Platforms, \u0026ldquo;Eat Your Own Dogfood\u0026rdquo;, can be rephrased as \u0026ldquo;Start with a Platform, and Then Use it for Everything.\u0026rdquo; You can\u0026rsquo;t just bolt it on later. Certainly not easily at any rate \u0026ndash; ask anyone who worked on platformizing MS Office. Or anyone who worked on platformizing Amazon. If you delay it, it\u0026rsquo;ll be ten times as much work as just doing it correctly up front. You can\u0026rsquo;t cheat. You can\u0026rsquo;t have secret back doors for internal apps to get special priority access, not for ANY reason. You need to solve the hard problems up front.\nI\u0026rsquo;m not saying it\u0026rsquo;s too late for us, but the longer we wait, the closer we get to being Too Late.\nI honestly don\u0026rsquo;t know how to wrap this up. I\u0026rsquo;ve said pretty much everything I came here to say today. This post has been six years in the making. I\u0026rsquo;m sorry if I wasn\u0026rsquo;t gentle enough, or if I misrepresented some product or team or person, or if we\u0026rsquo;re actually doing LOTS of platform stuff and it just so happens that I and everyone I ever talk to has just never heard about it. I\u0026rsquo;m sorry.\nBut we\u0026rsquo;ve gotta start doing this right.\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/book/conways-law/",
	"title": "Conway&#39;s Law",
	"tags": ["architecture"],
	"description": "",
	"content": "Many organizations have become adept at identifying what they need from software development projects, based on a keen understanding of their business goals. Even so, theyâre often surprised to find out that the end results donât achieve the transformative impact they were expecting. Their mistake? Overlooking the importance of Conwayâs Law.\nIn 1967, Melvin Conway coined a phrase at the end of his publication âHow do committees invent?â that was subsequently made popular by Fred Brooks in his book The Mythical Man-Month, where he dubbed it \u0026lsquo;Conwayâs Law\u0026rsquo;, which states:\n Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations - Conway, 1967.\n Although this is not a scientific law, it is a valid proposition for many environments. We often see its effects in our workplace and in other companies that develop software. Organizational structure reflected in systems So what does this mean in practice? What happens when organizational structure is reflected in the systems it produces? Well, take an invoicing department: that means thereâll be an invoicing system for sure; if there are a notifications areas, thereâll be notification systems; the finance department has a finance system, and so on. These systems will integrate with each other in a way that mirrors the way these organizational departments communicate.\nConwayâs Law also plays a role in the time it takes to construct each of these systems. Thatâs because the architecture of these products will reflect the communication structure of the teams that are part of that process.\nAs a result, if the technology department is organized around technical capabilities, with a work group focused on the user interface, another group to the database, a third to the infrastructure, one to the process management, another to the implementation of business logic on the server side (figure 1), the architecture of the resulting systems (figure 2) will be very similar to these communication structures.\nFigure 1: Technical organization of teams\nFigure 2: Architecture driven by technical capabilities\nSystems are dynamic, there will always be changes, and these are often caused by changes to the business definitions. If an organizational structure is driven by technical capabilities, every change in the business definitions will require work from all the technical areas of the organization, budget and time assignment.\nThis is one of the reasons why some organizations try to group requirements to \u0026lsquo;optimize\u0026rsquo; time and resources, lengthening the development process until all the necessary work can be âjustifiedâ. Often, the end result is just dissatisfaction with the technology department.\nOn the other hand, we can find organizations that favor multidisciplinary or cross-functional teams formed by different roles and guided by the business capabilities (figure 3). Here, changes produced by new business definitions are executed from beginning to end by just one team. This avoids processes overhead, and produces differentâand often more distributedâarchitectures (figure 4) with greater capacity to evolve. Organization of teams driven by business capabilities\nFigure 3: Organization of teams driven by business capabilities\n{:height=\u0026ldquo;36px\u0026rdquo; width=\u0026ldquo;36px\u0026rdquo;}\nFigure 4: Business-driven architecture\nIn the end, software is the product of an intellectual and collaborative process that will reflect the ideas of the people involved in this process and the communication structures between teams. That means, accounting for Conwayâs Law should be front of mind, when it comes to structuring teams.\nOrganizations have different needs in terms of software architecture and usually they know what is the expected architecture that will allow them to achieve their business goals. However, they forget the implications of people structure, what we can learn here is that we need to set up our teams aligned with the architecture we are expecting.\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/webdevelopers/",
	"title": "Web Development @webdevelopers.at",
	"tags": ["web development"],
	"description": "Some webdev stuff",
	"content": "Testing\n"
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/anekdote/",
	"title": "Anekdote",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/categories/book/",
	"title": "Book",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/book/",
	"title": "Books",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/data-science/",
	"title": "Data Science",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/devops/",
	"title": "Devops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/docker/",
	"title": "Docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/grpc/",
	"title": "Grpc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/machine-learning/",
	"title": "Machine Learning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/categories/machine-learning/",
	"title": "Machine Learning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/machine-learning/",
	"title": "Machine learnings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/categories/post/",
	"title": "Post",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/post/",
	"title": "Posts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/categories/project/",
	"title": "Project",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/project/",
	"title": "Projects",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/r/",
	"title": "R",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/regression/",
	"title": "Regression",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/visualization/",
	"title": "Visualization",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/",
	"title": "Web Archive",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://elastic-fermat-3dc26c.netlify.com/tags/web-development/",
	"title": "Web Development",
	"tags": [],
	"description": "",
	"content": ""
}]